Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f9bcf4b8f28>, tc2=<function tc2 at 0x7f9bcf4c9048>, tc3=<function tc3 at 0x7f9bcf4c9158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 69.0141
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7655c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7655c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e51d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7075c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7077f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7075c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7075c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6822e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6822e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f550> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6824a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6824a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7171d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6824a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 300
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7079b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7079b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d1d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ad68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7591d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7591d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7594e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 500
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759eb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c58d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b9da2f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b840710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8405af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b840123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4eb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d198> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 6
Completed Iteration #9
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.7042253521126725 13
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 1.408450704225345 14
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 2.1126760563380174 15
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 2.1126760563380174 16
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7dde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 2.1126760563380174 17
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d4a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d3c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738fd0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 2.81690140845069 18
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 2.81690140845069 19
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 2.81690140845069 20
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73be80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 3.5211267605633623 11
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 3.5211267605633623 21
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d3c8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738fd0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 3.5211267605633623 22
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 3.5211267605633623 23
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 4.225352112676035 14
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 4.225352112676035 24
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 4.225352112676035 15
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 4.225352112676035 25
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73be80> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 4.225352112676035 26
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 4.929577464788707 17
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 4.929577464788707 27
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 5.63380281690138 18
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 5.63380281690138 28
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 5.63380281690138 19
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 5.63380281690138 29
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 5.63380281690138 20
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 5.63380281690138 30
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 5.63380281690138 21
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 5.63380281690138 31
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79afd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 6.338028169014052 22
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 6.338028169014052 32
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 6.338028169014052 23
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 6.338028169014052 33
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ac88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738828> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738390> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 7.0422535211267245 24
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 7.0422535211267245 34
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 7.746478873239397 25
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 7.746478873239397 35
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79afd0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 8.45070422535207 26
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 8.45070422535207 36
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 8.45070422535207 27
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 8.45070422535207 37
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d400> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 8.45070422535207 28
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 8.45070422535207 38
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 9.154929577464742 29
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 9.154929577464742 39
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738390> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 7.746478873239397 17
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 9.154929577464742 30
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 9.154929577464742 40
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738390> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 7.746478873239397 18
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 9.154929577464742 31
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 9.154929577464742 41
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738fd0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 9.154929577464742 32
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 9.154929577464742 42
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aef0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ac88> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738828> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738390> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 7.746478873239397 20
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 9.154929577464742 33
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 9.154929577464742 43
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738390> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 7.746478873239397 21
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 9.154929577464742 34
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 9.154929577464742 44
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 6.338028169014052 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 8.45070422535207 22
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 9.859154929577414 35
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 9.859154929577414 45
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 9.154929577464742 23
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 10.563380281690087 36
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 10.563380281690087 46
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b840123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 9.154929577464742 24
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 10.563380281690087 37
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 10.563380281690087 47
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738390> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 9.154929577464742 25
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 10.563380281690087 38
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 10.563380281690087 48
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc2e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7380f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73be80> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 9.859154929577414 26
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 11.26760563380276 39
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 11.26760563380276 49
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 9.859154929577414 27
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 11.26760563380276 40
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 11.26760563380276 50
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 9.859154929577414 28
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 11.26760563380276 41
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 11.26760563380276 51
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79af60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 8.45070422535207 17
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 10.563380281690087 29
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 11.971830985915432 42
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 11.971830985915432 52
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->6->16
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d400> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 9.154929577464742 18
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 11.26760563380276 30
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 12.676056338028104 43
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 12.676056338028104 53
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738978> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 11.26760563380276 31
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 12.676056338028104 44
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 12.676056338028104 54
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 11.971830985915432 32
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 13.380281690140777 45
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 13.380281690140777 55
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73be80> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 9.859154929577414 21
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 11.971830985915432 33
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 13.380281690140777 46
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 13.380281690140777 56
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a53c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d4a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d3c8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738fd0> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 10.563380281690087 22
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 12.676056338028104 34
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 14.084507042253449 47
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 14.084507042253449 57
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dc88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9668> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a20> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d400> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 11.26760563380276 23
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 13.380281690140777 35
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 14.788732394366122 48
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 14.788732394366122 58
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 11.971830985915432 24
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 14.084507042253449 36
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 15.492957746478794 49
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 15.492957746478794 59
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f080> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 11.971830985915432 25
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 14.084507042253449 37
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 15.492957746478794 50
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 15.492957746478794 60
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a20> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d400> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 12.676056338028104 26
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 14.788732394366122 38
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 16.197183098591466 51
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 16.197183098591466 61
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717a58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7175c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79af60> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 13.380281690140777 27
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 15.492957746478794 39
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 16.90140845070414 52
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 16.90140845070414 62
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc128> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 14.084507042253449 28
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 16.197183098591466 40
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 17.60563380281681 53
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 17.60563380281681 63
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682cc0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc128> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 14.788732394366122 29
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 16.90140845070414 41
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 18.309859154929484 54
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 18.309859154929484 64
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dc88> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d400> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9668> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a20> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d400> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 14.788732394366122 30
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 16.90140845070414 42
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 18.309859154929484 55
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 18.309859154929484 65
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->6->16->5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738710> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 15.492957746478794 31
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 17.60563380281681 43
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 19.014084507042156 56
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 19.014084507042156 66
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9ef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 16.197183098591466 32
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 18.309859154929484 44
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 19.71830985915483 57
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 19.71830985915483 67
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 16.90140845070414 33
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 19.014084507042156 45
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 20.4225352112675 58
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 20.4225352112675 68
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682ef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 17.60563380281681 34
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 19.71830985915483 46
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 21.126760563380174 59
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 21.126760563380174 69
Completed Iteration #5
Best Reward: 0.7042253521126725
coverage_call_count 700
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5978> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 17.60563380281681 35
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 19.71830985915483 47
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 21.126760563380174 60
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 21.126760563380174 70
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 18.309859154929484 36
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 20.4225352112675 48
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 21.830985915492846 61
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 21.830985915492846 71
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5320> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738710> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 18.309859154929484 37
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 20.4225352112675 49
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 21.830985915492846 62
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 21.830985915492846 72
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5978> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 6.338028169014052 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 19.014084507042156 38
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 21.126760563380174 50
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 22.53521126760552 63
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 22.53521126760552 73
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bc50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717780> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 19.71830985915483 39
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 21.830985915492846 51
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 23.23943661971819 64
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 23.23943661971819 74
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717780> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 20.4225352112675 40
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 22.53521126760552 52
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 23.943661971830863 65
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 23.943661971830863 75
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->6->16->5->4
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717ef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 21.126760563380174 41
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 23.23943661971819 53
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 24.647887323943536 66
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 24.647887323943536 76
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 21.830985915492846 42
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 23.943661971830863 54
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 25.35211267605621 67
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 25.35211267605621 77
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 22.53521126760552 43
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 24.647887323943536 55
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 26.05633802816888 68
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 26.05633802816888 78
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5978> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 8.45070422535207 16
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 22.53521126760552 44
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 24.647887323943536 56
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 26.05633802816888 69
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 26.05633802816888 79
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738710> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 23.23943661971819 45
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 25.35211267605621 57
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 26.760563380281553 70
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 26.760563380281553 80
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682ef0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 9.154929577464742 18
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 23.23943661971819 46
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 25.35211267605621 58
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 26.760563380281553 71
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 26.760563380281553 81
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682ef0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 9.859154929577414 19
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 23.943661971830863 47
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 26.05633802816888 59
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 27.464788732394226 72
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 27.464788732394226 82
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6bea58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717ef0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 10.563380281690087 20
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 13.380281690140777 24
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 24.647887323943536 48
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 26.760563380281553 60
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 28.169014084506898 73
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 28.169014084506898 83
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->6->16->5->4->0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 11.26760563380276 21
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 25.35211267605621 49
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 27.464788732394226 61
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 28.87323943661957 74
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 28.87323943661957 84
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f8d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d96d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 26.05633802816888 50
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 28.169014084506898 62
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 29.577464788732243 75
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 29.577464788732243 85
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7711d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764d30> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 26.760563380281553 51
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 28.87323943661957 63
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 30.281690140844916 76
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 30.281690140844916 86
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 13.380281690140777 24
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 16.197183098591466 28
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 27.464788732394226 52
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 29.577464788732243 64
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 30.985915492957588 77
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 30.985915492957588 87
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7176d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9d30> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 16.90140845070414 29
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 28.169014084506898 53
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 30.281690140844916 65
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 31.69014084507026 78
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 31.69014084507026 88
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7070f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 17.60563380281681 30
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 28.87323943661957 54
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 30.985915492957588 66
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 32.39436619718293 79
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 32.39436619718293 89
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9ef0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 14.788732394366122 27
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 17.60563380281681 31
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 28.87323943661957 55
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 30.985915492957588 67
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 32.39436619718293 80
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 32.39436619718293 90
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9ef0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 15.492957746478794 28
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 18.309859154929484 32
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 29.577464788732243 56
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 31.69014084507026 68
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 33.098591549295605 81
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 33.098591549295605 91
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 15.492957746478794 29
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 18.309859154929484 33
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 29.577464788732243 57
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 31.69014084507026 69
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 33.098591549295605 82
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 33.098591549295605 92
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764d30> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 16.197183098591466 30
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 19.014084507042156 34
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 30.281690140844916 58
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 32.39436619718293 70
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 33.80281690140828 83
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 33.80281690140828 93
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771e80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 16.90140845070414 31
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 19.71830985915483 35
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 30.985915492957588 59
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 33.098591549295605 71
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 34.50704225352095 84
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 34.50704225352095 94
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7170f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 17.60563380281681 32
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 20.4225352112675 36
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 31.69014084507026 60
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 33.80281690140828 72
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 35.21126760563362 85
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 35.21126760563362 95
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719e8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764d30> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 17.60563380281681 33
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 20.4225352112675 37
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 31.69014084507026 61
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 33.80281690140828 73
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 35.21126760563362 86
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 35.21126760563362 96
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->6->16->5->4->0->10
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e7f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7176d8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be908> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9d30> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 18.309859154929484 34
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 21.126760563380174 38
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 32.39436619718293 62
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 34.50704225352095 74
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 35.915492957746295 87
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 35.915492957746295 97
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717d30> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 19.014084507042156 35
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 21.830985915492846 39
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 33.098591549295605 63
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 35.21126760563362 75
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 36.61971830985897 88
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 36.61971830985897 98
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7655f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e7f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7176d8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be908> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9d30> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 19.71830985915483 36
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 22.53521126760552 40
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 33.80281690140828 64
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 35.915492957746295 76
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 37.32394366197164 89
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 37.32394366197164 99
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 20.4225352112675 37
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 23.23943661971819 41
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 34.50704225352095 65
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 36.61971830985897 77
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 38.02816901408431 90
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 38.02816901408431 100
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d470> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 21.126760563380174 38
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 23.943661971830863 42
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 35.21126760563362 66
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 37.32394366197164 78
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 38.732394366196985 91
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 38.732394366196985 101
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9d30> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 21.830985915492846 39
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 24.647887323943536 43
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 35.915492957746295 67
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 38.02816901408431 79
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 39.43661971830966 92
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 39.43661971830966 102
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->6->16->5->4->0->10->6
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759b70> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 24.647887323943536 44
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 35.915492957746295 68
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 38.02816901408431 80
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 39.43661971830966 93
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 39.43661971830966 103
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717208> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771710> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d470> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 22.53521126760552 41
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 25.35211267605621 45
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 36.61971830985897 69
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 38.732394366196985 81
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 40.14084507042233 94
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 40.14084507042233 104
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
coverage_call_count 800
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765e48> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717d30> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 16.197183098591466 28
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 23.23943661971819 42
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 26.05633802816888 46
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 37.32394366197164 70
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 39.43661971830966 82
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 40.845070422535 95
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 40.845070422535 105
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d96d8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 16.90140845070414 29
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 23.943661971830863 43
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 26.760563380281553 47
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 38.02816901408431 71
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 40.14084507042233 83
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 41.549295774647675 96
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 41.549295774647675 106
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ea90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759b70> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 17.60563380281681 30
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 24.647887323943536 44
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 27.464788732394226 48
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 38.732394366196985 72
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 40.845070422535 84
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 42.25352112676035 97
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 42.25352112676035 107
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707978> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717208> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771710> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d470> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 18.309859154929484 31
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 25.35211267605621 45
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 28.169014084506898 49
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 39.43661971830966 73
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 41.549295774647675 85
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 42.95774647887302 98
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 42.95774647887302 108
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c52b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d96d8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 13.380281690140777 21
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 19.014084507042156 32
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 26.05633802816888 46
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 28.87323943661957 50
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 40.14084507042233 74
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 42.25352112676035 86
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 43.66197183098569 99
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 43.66197183098569 109
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 14.084507042253449 22
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 19.71830985915483 33
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 26.760563380281553 47
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 29.577464788732243 51
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 40.845070422535 75
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 42.95774647887302 87
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 44.366197183098365 100
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 44.366197183098365 110
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 14.788732394366122 23
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 20.4225352112675 34
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 27.464788732394226 48
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 30.281690140844916 52
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 41.549295774647675 76
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 43.66197183098569 88
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 45.07042253521104 101
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 45.07042253521104 111
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7641d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f16a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765e48> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717d30> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 15.492957746478794 24
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 21.126760563380174 35
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 28.169014084506898 49
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 30.985915492957588 53
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 42.25352112676035 77
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 44.366197183098365 89
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 45.77464788732371 102
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 45.77464788732371 112
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ee10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e5c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f8d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d96d8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5860> 16.197183098591466 25
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcfd0> 21.830985915492846 36
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a588> 28.87323943661957 50
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738550> 31.69014084507026 54
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 42.95774647887302 78
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 45.07042253521104 90
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f4e0> 46.47887323943638 103
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 46.47887323943638 113
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->6->16->5->4->0->10->6->29
Best Reward: 0.7042253521126725
iteration: 23
found coverage increase 0.7042253521126725
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b67f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b67f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11efd0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cf8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0769b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b39e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b39e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e86d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e86d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024818d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b33c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b33c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024accf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024acc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024acc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024acc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 1100
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b828> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024aceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b240> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0739e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0739e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be10> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f867b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f867b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f864e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f864e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f869e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f866a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f866a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f753c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f753c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f753c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f757b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f087f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f084a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f083c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f083c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f083c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f866d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 1400
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed93c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e852b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef77b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef77b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e852b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed92e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecde10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd5c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f756d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f753c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e856a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85b38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2be80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b390> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ea20> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7655f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68ff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68ff28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7590f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 1700
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7590f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fe48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f278> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9bebda0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7717f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f088d0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6bee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9bebda0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6bee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 1800
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c55c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b84012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6822e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 6
Completed Iteration #8
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7387b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c56d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b9da2f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 2000
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7078d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b84012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7078d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7389e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d5f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.7042253521126725 7
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.7042253521126725 8
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.7042253521126725 9
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 1.408450704225345 10
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 1.408450704225345 11
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 1.408450704225345 12
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f16a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 2.1126760563380174 13
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 2.1126760563380174 14
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 2.1126760563380174 15
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 2.81690140845069 16
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 2.81690140845069 17
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 2.81690140845069 18
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 2.81690140845069 19
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a5f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d94e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 3.5211267605633623 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 3.5211267605633623 20
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f3c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 4.225352112676035 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 4.225352112676035 21
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f3c8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 4.929577464788707 22
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559c50> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559d30> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f3c8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 4.929577464788707 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 4.929577464788707 23
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 4.929577464788707 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 4.929577464788707 24
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 5.63380281690138 16
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 5.63380281690138 25
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b84012390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 6.338028169014052 17
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 6.338028169014052 26
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c91d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559be0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 7.0422535211267245 27
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d35c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9358> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 7.746478873239397 28
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aef0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9358> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 8.45070422535207 20
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 8.45070422535207 29
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 8.45070422535207 21
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 8.45070422535207 30
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcc50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a5f8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d94e0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 9.154929577464742 22
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 9.154929577464742 31
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b3c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559d30> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f3c8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 9.859154929577414 23
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 9.859154929577414 32
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc50> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559be0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 10.563380281690087 24
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 10.563380281690087 33
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fce80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b9e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f3c8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 11.26760563380276 25
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 11.26760563380276 34
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a5f8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d94e0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 11.26760563380276 26
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 11.26760563380276 35
Completed Iteration #0
Best Reward: 0.7042253521126725
coverage_call_count 2100
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 11.971830985915432 27
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 11.971830985915432 36
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d94e0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 12.676056338028104 28
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 12.676056338028104 37
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79af60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 13.380281690140777 29
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 13.380281690140777 38
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 14.084507042253449 30
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 14.084507042253449 39
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 14.788732394366122 31
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 14.788732394366122 40
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a54e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcc50> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a5f8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d94e0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 15.492957746478794 32
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 15.492957746478794 41
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5f28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 16.197183098591466 33
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 16.197183098591466 42
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 16.90140845070414 34
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 16.90140845070414 43
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->6->4
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 17.60563380281681 35
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 17.60563380281681 44
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79af60> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 17.60563380281681 36
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 17.60563380281681 45
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5d68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1be0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 18.309859154929484 37
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 18.309859154929484 46
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 19.014084507042156 38
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 19.014084507042156 47
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5dd8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 19.71830985915483 39
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 19.71830985915483 48
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d93c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 20.4225352112675 40
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 20.4225352112675 49
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707cf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3470> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b278> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5dd8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 21.126760563380174 41
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 21.126760563380174 50
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d93c8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 21.126760563380174 42
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 21.126760563380174 51
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bc88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 21.830985915492846 43
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 21.830985915492846 52
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed91d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 22.53521126760552 44
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 22.53521126760552 53
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 23.23943661971819 45
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 23.23943661971819 54
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed91d0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 23.23943661971819 46
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 23.23943661971819 55
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcc0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 23.943661971830863 47
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 23.943661971830863 56
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3470> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b278> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5dd8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 24.647887323943536 48
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 24.647887323943536 57
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 16.197183098591466 28
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 25.35211267605621 49
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 25.35211267605621 58
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 16.90140845070414 29
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 26.05633802816888 50
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 26.05633802816888 59
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1be0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 16.90140845070414 30
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 26.05633802816888 51
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 26.05633802816888 60
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->6->4->8
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd2e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bc88> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 17.60563380281681 31
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 26.760563380281553 52
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 26.760563380281553 61
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be48> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcc0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 17.60563380281681 32
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 26.760563380281553 53
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 26.760563380281553 62
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bf28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 13.380281690140777 25
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 18.309859154929484 33
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 27.464788732394226 54
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 27.464788732394226 63
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bf60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcc0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 14.084507042253449 26
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 19.014084507042156 34
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 28.169014084506898 55
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 28.169014084506898 64
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcc0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 14.788732394366122 27
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 19.71830985915483 35
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 28.87323943661957 56
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 28.87323943661957 65
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcc0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 15.492957746478794 28
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 20.4225352112675 36
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 29.577464788732243 57
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 29.577464788732243 66
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8d68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7908> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcc0> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 16.197183098591466 29
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 21.126760563380174 37
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 30.281690140844916 58
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 30.281690140844916 67
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecde80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 16.90140845070414 30
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 21.830985915492846 38
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 30.985915492957588 59
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 30.985915492957588 68
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 17.60563380281681 31
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 22.53521126760552 39
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 31.69014084507026 60
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 31.69014084507026 69
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcc0> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 18.309859154929484 32
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 23.23943661971819 40
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 32.39436619718293 61
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 32.39436619718293 70
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 19.014084507042156 33
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 23.943661971830863 41
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 33.098591549295605 62
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 33.098591549295605 71
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0f0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcc0> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 19.014084507042156 34
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 23.943661971830863 42
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 33.098591549295605 63
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 33.098591549295605 72
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 19.71830985915483 35
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 24.647887323943536 43
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 33.80281690140828 64
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 33.80281690140828 73
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 12.676056338028104 21
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 20.4225352112675 36
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 25.35211267605621 44
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 34.50704225352095 65
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 34.50704225352095 74
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bf60> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bcc0> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 20.4225352112675 37
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 25.35211267605621 45
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 34.50704225352095 66
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 34.50704225352095 75
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd198> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd2e8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bc88> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 20.4225352112675 38
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 25.35211267605621 46
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 34.50704225352095 67
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 34.50704225352095 76
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->6->4->8->19
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bc88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7518> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 13.380281690140777 24
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 21.126760563380174 39
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 26.05633802816888 47
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 35.21126760563362 68
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 35.21126760563362 77
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bda0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 26.760563380281553 48
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 35.915492957746295 69
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 35.915492957746295 78
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 22.53521126760552 41
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 27.464788732394226 49
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 36.61971830985897 70
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 36.61971830985897 79
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86ef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3630> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7518> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 23.23943661971819 42
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 28.169014084506898 50
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 37.32394366197164 71
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 37.32394366197164 80
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7eb8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 16.197183098591466 28
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 23.943661971830863 43
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 28.87323943661957 51
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 38.02816901408431 72
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 38.02816901408431 81
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4a90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bf28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 16.90140845070414 29
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 24.647887323943536 44
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 29.577464788732243 52
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 38.732394366196985 73
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 38.732394366196985 82
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
coverage_call_count 2200
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa55c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cd30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd198> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd2e8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bc88> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 17.60563380281681 30
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 25.35211267605621 45
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 30.281690140844916 53
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 39.43661971830966 74
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 39.43661971830966 83
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->6->4->8->19->5
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdc18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 18.309859154929484 31
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 26.05633802816888 46
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 30.985915492957588 54
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 40.14084507042233 75
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 40.14084507042233 84
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 19.014084507042156 32
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 26.760563380281553 47
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 31.69014084507026 55
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 40.845070422535 76
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 40.845070422535 85
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 13.380281690140777 21
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 19.71830985915483 33
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 27.464788732394226 48
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 32.39436619718293 56
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 41.549295774647675 77
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 41.549295774647675 86
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86630> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 14.084507042253449 22
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 20.4225352112675 34
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 28.169014084506898 49
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 33.098591549295605 57
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 42.25352112676035 78
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 42.25352112676035 87
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 14.084507042253449 23
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 20.4225352112675 35
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 28.169014084506898 50
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 33.098591549295605 58
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 42.25352112676035 79
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 42.25352112676035 88
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86630> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 20.4225352112675 36
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 28.169014084506898 51
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 33.098591549295605 59
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 42.25352112676035 80
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 42.25352112676035 89
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85828> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 20.4225352112675 37
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 28.169014084506898 52
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 33.098591549295605 60
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 42.25352112676035 81
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 42.25352112676035 90
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 21.126760563380174 38
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 28.87323943661957 53
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 33.80281690140828 61
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 42.95774647887302 82
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 42.95774647887302 91
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 14.788732394366122 27
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 21.126760563380174 39
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 28.87323943661957 54
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 33.80281690140828 62
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 42.95774647887302 83
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 42.95774647887302 92
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bb00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 6.338028169014052 14
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 15.492957746478794 28
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 29.577464788732243 55
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 34.50704225352095 63
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 43.66197183098569 84
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 43.66197183098569 93
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdb70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f98> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 16.197183098591466 29
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 22.53521126760552 41
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 30.281690140844916 56
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 35.21126760563362 64
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 44.366197183098365 85
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 44.366197183098365 94
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c7b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f98> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 16.90140845070414 30
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 23.23943661971819 42
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 30.985915492957588 57
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 35.915492957746295 65
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 45.07042253521104 86
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 45.07042253521104 95
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c7b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f98> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 7.746478873239397 17
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 16.90140845070414 31
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 23.23943661971819 43
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 30.985915492957588 58
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 35.915492957746295 66
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 45.07042253521104 87
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 45.07042253521104 96
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfb70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdc18> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 17.60563380281681 32
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 23.943661971830863 44
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 31.69014084507026 59
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 36.61971830985897 67
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 45.77464788732371 88
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 45.77464788732371 97
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 18.309859154929484 33
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 24.647887323943536 45
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 32.39436619718293 60
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 37.32394366197164 68
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 46.47887323943638 89
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 46.47887323943638 98
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->6->4->8->19->5->2
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b0246be10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86630> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 19.014084507042156 34
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 25.35211267605621 46
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 33.098591549295605 61
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 38.02816901408431 69
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 47.183098591549054 90
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 47.183098591549054 99
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86630> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 10.563380281690087 21
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 19.71830985915483 35
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 26.05633802816888 47
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 33.80281690140828 62
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 38.732394366196985 70
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 47.88732394366173 91
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 47.88732394366173 100
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 10.563380281690087 22
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 19.71830985915483 36
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 26.05633802816888 48
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 33.80281690140828 63
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 38.732394366196985 71
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 47.88732394366173 92
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 47.88732394366173 101
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c50> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 10.563380281690087 23
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 19.71830985915483 37
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 26.05633802816888 49
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 33.80281690140828 64
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 38.732394366196985 72
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 47.88732394366173 93
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 47.88732394366173 102
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf3c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 7.746478873239397 17
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 11.26760563380276 24
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 20.4225352112675 38
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 26.760563380281553 50
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 34.50704225352095 65
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 39.43661971830966 73
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 48.5915492957744 94
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 48.5915492957744 103
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b7b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024812b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bb00> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 11.971830985915432 25
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 21.126760563380174 39
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 27.464788732394226 51
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 35.21126760563362 66
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 40.14084507042233 74
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 49.29577464788707 95
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 49.29577464788707 104
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b7f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 12.676056338028104 26
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 28.169014084506898 52
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 35.915492957746295 67
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 40.845070422535 75
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 49.999999999999744 96
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 49.999999999999744 105
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024812b0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bb00> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 9.154929577464742 20
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 12.676056338028104 27
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 21.830985915492846 41
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 28.169014084506898 53
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 35.915492957746295 68
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 40.845070422535 76
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 49.999999999999744 97
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 49.999999999999744 106
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c50> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 9.154929577464742 21
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 12.676056338028104 28
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 21.830985915492846 42
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 28.169014084506898 54
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 35.915492957746295 69
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 40.845070422535 77
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 49.999999999999744 98
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 49.999999999999744 107
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b024acd68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 9.859154929577414 22
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 13.380281690140777 29
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 22.53521126760552 43
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 28.87323943661957 55
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 36.61971830985897 70
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 41.549295774647675 78
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 50.70422535211242 99
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 50.70422535211242 108
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 10.563380281690087 23
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 14.084507042253449 30
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 23.23943661971819 44
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 29.577464788732243 56
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 37.32394366197164 71
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 42.25352112676035 79
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 51.40845070422509 100
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 51.40845070422509 109
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86630> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 10.563380281690087 24
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 14.084507042253449 31
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 23.23943661971819 45
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 29.577464788732243 57
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 37.32394366197164 72
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 42.25352112676035 80
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 51.40845070422509 101
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 51.40845070422509 110
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->6->4->8->19->5->2->3
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b7f0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 10.563380281690087 25
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 14.084507042253449 32
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 23.23943661971819 46
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 29.577464788732243 58
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 37.32394366197164 73
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 42.25352112676035 81
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 51.40845070422509 102
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 51.40845070422509 111
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc518> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdc18> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 10.563380281690087 26
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 14.084507042253449 33
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 23.23943661971819 47
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 29.577464788732243 59
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 37.32394366197164 74
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 42.25352112676035 82
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 51.40845070422509 103
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 51.40845070422509 112
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfe10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b7f0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 11.26760563380276 27
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 14.788732394366122 34
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 23.943661971830863 48
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 30.281690140844916 60
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 38.02816901408431 75
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 42.95774647887302 83
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 52.11267605633776 104
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 52.11267605633776 113
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b7f0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 3.5211267605633623 10
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 11.26760563380276 28
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 14.788732394366122 35
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 23.943661971830863 49
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 30.281690140844916 61
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 38.02816901408431 76
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 42.95774647887302 84
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 52.11267605633776 105
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 52.11267605633776 114
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f948d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0b8> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 11.971830985915432 29
backprop <src.mcts.MCTS_Node object at 0x7f9b0245ba58> 15.492957746478794 36
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9748> 24.647887323943536 50
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 30.985915492957588 62
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7f0> 38.732394366196985 77
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 43.66197183098569 85
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ac8> 52.816901408450434 106
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 52.816901408450434 115
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->6->4->8->19->5->2->3->12
Best Reward: 0.7042253521126725
iteration: 72
found coverage increase 0.7042253521126725
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0760b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 2300
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f423c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0767b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1d30> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f429b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9345208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f429b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93097b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f50f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93764e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93094e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93094e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9309940> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f752e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93099b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93099b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9af9276128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92354e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92354e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92357f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af011c828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b70b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024817f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024817f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024817f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a46d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f862e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f862e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f862e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b84012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08ff28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bf98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0736d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7978> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f085f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e80> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b9da8ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b9da2f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 17
Completed Iteration #24
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef72e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9668> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b9da8ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1da0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a52b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a50f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9bebda0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a50f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8470> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72dd68> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b84079b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7714a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7714a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7650b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdf60> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b84079b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024815c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024815c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1c18> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 3300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a50f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f759b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f759b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f947b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928af28> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92763c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92352b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92352b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92769b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92763c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92769b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92089b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235f60> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92354a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0766d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0766d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92579e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af01371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92579e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9257470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af01377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137860> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 3700
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af01371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b72b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37586a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92359b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37309b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37126d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37309b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37125f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37582b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37304a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36904e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690208> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f75f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 4000
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f75f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a10b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36562e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36562e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36562e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36676a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36676a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36676a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c88d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c88d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac36671d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37124e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eb70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ef60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92762e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af01374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37301d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af01375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af0137828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af01374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 4300
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f945f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7630> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af01375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af01374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af01375c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8405af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af01375c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b74a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72df28> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b9da2f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b840710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b7b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af01374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af01374a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9257908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af01374a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af01374a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af01374a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d31d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0730b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7384a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7384a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1dd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af01375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 4700
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d60f0> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92357f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92357f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92357f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c54e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af011c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 4800
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37120b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37120b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92082b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37120b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37420b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37420b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37588d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9315908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690320> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36909e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36909e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36909e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37585c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37585c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9266550> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36497b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 5100
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b37f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aa20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36495c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9315898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93150f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9315e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9208ef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a326a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a325c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36569b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13947f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 5300
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13947f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13834e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13635f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13635f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13635f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363160> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136ffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136ffd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13638d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 5500
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d59e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363fd0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f98> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b46a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b46a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a43c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a43c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ab00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ab00> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12744a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12744a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12749b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12744a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12749b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12285f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df43c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d865c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12185f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d935c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9bebd2d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c717278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b019c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e7b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 70.4225352112676
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6bea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af928a278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12288d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c44e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394470> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 15
Completed Iteration #21
Best Reward: 0
coverage_call_count 6000
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12281d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a327b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36560f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 6100
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1394978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af28> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d5eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13c45c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9266518> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c98d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fbf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e85518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9376c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e859e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e856d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3758240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 6200
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3667f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3690cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e856d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9376e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024aca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f94d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37127f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92354e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92354e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3712ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af929c550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af929cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a1a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af93765f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a32e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9235668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0245be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b02481828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c073ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fa5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f1c550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7d30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7c9828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f15c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d559c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e738ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3649198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b02481c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ecd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ef7d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b024acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 6400
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3656c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9208c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af011cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9235550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af011cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac21b3198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024ac6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b9da2f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e2b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5d68> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b9da2f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e771b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93b7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b9da2f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e759d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e5b550> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37126d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af010be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1363470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b024acb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21c8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74ff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6d9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 6500
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b8d4eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1228320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7598d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9309898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c7e5048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9276978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92760f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92760f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92760f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af93454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9345d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af93458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c682a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9af9276748> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af010b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac136feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e6f1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e1e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c73b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af932c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b3c65e160> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c68fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3f98> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af92766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9257da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d4ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b0246b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac218eef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9345668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9266a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01f422e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cc50> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af932cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b3c765940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0248e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36c96a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b01ebb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ed9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c08f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c66bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af928a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383748> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9309748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b0245b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f86438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01e4c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e78d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d55c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d55c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af9208358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9af0137c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a1dd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13837b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c72db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e7fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac136f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac219cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac37b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c076fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e79a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac36a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d865c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1383ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86048> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12747f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12747f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a5ab38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac124a048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12741d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12745c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d866a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1e764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d869e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d866a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12741d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c6a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12745c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12745c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af0137c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01f42550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9af92c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac124aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac137fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0df4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac137f198> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac133b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac133bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac21d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac218e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13830b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d400> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac219c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86668> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf082e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf082e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c11e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01fcf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1218630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b3c74ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36320> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac3742e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf598d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf369b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb11d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb11d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbef32e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac124ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb25c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe454a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe454a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe536d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 7300
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2ac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbef3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe73160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac123d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac218ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1274a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13837b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9b841dbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe838d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe302e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe302e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe539e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac1a6b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac371d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbf36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c90b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b01ff8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c99e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac127f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d86940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac0d6d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe736d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfbe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7daa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7affd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a12b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a15c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbfb1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9b1c0b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af8d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac13832b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45a58> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb774400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb726400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb726400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb726400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac13830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b70> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb718940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7445f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 7600
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7445f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe83c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb718048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7181d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7183c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7000b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe45898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb78def0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e64a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e62b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6849b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6849b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb726128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6390> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb726e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbeb26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb726e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb726e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7002b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d7b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6496a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb663978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb663198> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 7800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbee5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb726c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6236a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb623390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbf59748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb744630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63cef0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb7a14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb675f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb78dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb663ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649dd8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f9abb6495c0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9ac12b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bcba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1941d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1faf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1941d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccd68> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6846d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aa7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aa7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abbe305c0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb78df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb774c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb194710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe30240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe00668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb700b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb700be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb744630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb649e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb649eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abbe737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1948d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb6bc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
coverage_call_count 8000
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb684da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb663ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb7444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb623b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1947b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb63ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1947b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb675e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb194048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb6235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb675cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb1ccda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb194048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb1aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb173198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f9abb173320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f9abb623cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f9abb774240> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 70.4225352112676
initial coverage: 69.0141
time passed (minutes): 60.3591
iterations: 297
number of new inputs: 128
final coverage: 70.4225
total coverage increase: 1.40845
