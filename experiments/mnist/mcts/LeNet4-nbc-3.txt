Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7fd1867f6f28>, tc2=<function tc2 at 0x7fd186807048>, tc3=<function tc3 at 0x7fd186807158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 9.50704
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db9b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 9.507042253521126
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1936d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1936d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c0b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c0b3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 9.507042253521126
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a81680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a81684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a81688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 9.507042253521126
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80feb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80feef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80feb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a81682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80feb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 9.507042253521126
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81680f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81680f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd15297c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81680f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a81683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd10c04a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81680f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81685f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 9.507042253521126
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c11d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.352112676056338 8
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.352112676056338 9
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.352112676056338 10
Completed Iteration #13
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.352112676056338 11
Completed Iteration #14
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.704225352112676 12
Completed Iteration #15
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.704225352112676 13
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.704225352112676 14
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.704225352112676 15
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 0.704225352112676 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.704225352112676 16
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #0
root
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 0.704225352112676 7
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 0.704225352112676 17
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb9e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbc88> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c11d0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.056338028169014 8
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.056338028169014 18
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb9e8> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbc88> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c11d0> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.056338028169014 9
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.056338028169014 19
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.056338028169014 10
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.056338028169014 20
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.056338028169014 11
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.056338028169014 21
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c11d0> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.056338028169014 12
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.056338028169014 22
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.056338028169014 13
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.056338028169014 23
Completed Iteration #13
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.056338028169014 14
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.056338028169014 24
Completed Iteration #14
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d52b0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1198> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c11d0> 1.056338028169014 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.408450704225352 15
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.408450704225352 25
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d59e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d57b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a278> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.76056338028169 16
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.76056338028169 26
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 1.76056338028169 17
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 1.76056338028169 27
Completed Iteration #20
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5668> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 2.112676056338028 18
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 2.112676056338028 28
Completed Iteration #21
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 2.112676056338028 19
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 2.112676056338028 29
Completed Iteration #22
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 2.112676056338028 20
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 2.112676056338028 30
Completed Iteration #23
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 2.112676056338028 21
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 2.112676056338028 31
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f68d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 2.464788732394366 22
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 2.464788732394366 32
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f68d0> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 2.464788732394366 23
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 2.464788732394366 33
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 1.056338028169014 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 2.464788732394366 24
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 2.464788732394366 34
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 1.056338028169014 7
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 2.464788732394366 25
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 2.464788732394366 35
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfac8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f68d0> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 1.408450704225352 8
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 2.816901408450704 26
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 2.816901408450704 36
Completed Iteration #17
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac588> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 1.76056338028169 9
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 3.169014084507042 27
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 3.169014084507042 37
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f68d0> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 1.76056338028169 10
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 3.169014084507042 28
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 3.169014084507042 38
Completed Iteration #20
Best Reward: 0.352112676056338
coverage_call_count 200
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5e80> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f68d0> 1.056338028169014 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 2.112676056338028 11
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 3.52112676056338 29
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 3.52112676056338 39
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfda0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfa20> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5668> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 2.464788732394366 12
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 3.873239436619718 30
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 3.873239436619718 40
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #2
root->2->18
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5668> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 1.056338028169014 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 2.464788732394366 13
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 3.873239436619718 31
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 3.873239436619718 41
Completed Iteration #2
Best Reward: 0.352112676056338
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 1.056338028169014 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 2.464788732394366 14
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 3.873239436619718 32
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 3.873239436619718 42
Completed Iteration #5
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5668> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 1.056338028169014 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 2.464788732394366 15
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 3.873239436619718 33
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 3.873239436619718 43
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 1.408450704225352 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 2.816901408450704 16
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 4.225352112676056 34
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 4.225352112676056 44
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083860> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfa20> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5668> 1.056338028169014 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 1.76056338028169 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 3.169014084507042 17
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 4.577464788732394 35
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 4.577464788732394 45
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b1d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 2.112676056338028 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 3.52112676056338 18
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 4.929577464788732 36
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 4.929577464788732 46
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2860> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2128> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5668> 1.408450704225352 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 2.464788732394366 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 3.873239436619718 19
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 5.28169014084507 37
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 5.28169014084507 47
Completed Iteration #21
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2fd0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2e80> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 2.816901408450704 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 4.225352112676056 20
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 5.633802816901408 38
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 5.633802816901408 48
Completed Iteration #22
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a83c8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2e80> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 3.169014084507042 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 4.577464788732394 21
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 5.985915492957746 39
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 5.985915492957746 49
Completed Iteration #23
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 3.169014084507042 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 4.577464788732394 22
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 5.985915492957746 40
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 5.985915492957746 50
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #3
root->2->18->5
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d57f0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5908> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2fd0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2e80> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 3.52112676056338 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 4.929577464788732 23
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 6.338028169014084 41
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 6.338028169014084 51
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 2.112676056338028 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 3.873239436619718 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 5.28169014084507 24
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 6.690140845070422 42
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 6.690140845070422 52
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083e80> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 2.464788732394366 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 4.225352112676056 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 5.633802816901408 25
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 7.04225352112676 43
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 7.04225352112676 53
Completed Iteration #6
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2668> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f28> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 2.816901408450704 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 4.577464788732394 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 5.985915492957746 26
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 7.394366197183098 44
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 7.394366197183098 54
Completed Iteration #7
Best Reward: 0.352112676056338
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a85c0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2e10> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 3.169014084507042 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 4.929577464788732 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 6.338028169014084 27
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 7.746478873239436 45
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 7.746478873239436 55
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a85f8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6eb8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 3.52112676056338 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 5.28169014084507 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 6.690140845070422 28
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 8.098591549295774 46
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 8.098591549295774 56
Completed Iteration #12
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a83c8> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2e80> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 3.52112676056338 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 5.28169014084507 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 6.690140845070422 29
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 8.098591549295774 47
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 8.098591549295774 57
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8a58> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2c50> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 3.873239436619718 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 5.633802816901408 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 7.04225352112676 30
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 8.450704225352112 48
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 8.450704225352112 58
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 3.873239436619718 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 5.633802816901408 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 7.04225352112676 31
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 8.450704225352112 49
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 8.450704225352112 59
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043940> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043f28> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b1d0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 4.225352112676056 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 5.985915492957746 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 7.394366197183098 32
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 8.80281690140845 50
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 8.80281690140845 60
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #4
root->2->18->5->1
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80506d8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 2.112676056338028 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 4.577464788732394 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 6.338028169014084 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 7.746478873239436 33
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 9.154929577464788 51
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 9.154929577464788 61
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b1d0> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 2.112676056338028 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 4.577464788732394 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 6.338028169014084 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 7.746478873239436 34
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 9.154929577464788 52
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 9.154929577464788 62
Completed Iteration #3
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a29e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb2b0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2668> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f28> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 2.464788732394366 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 4.929577464788732 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 6.690140845070422 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 8.098591549295774 35
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 9.507042253521126 53
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 9.507042253521126 63
Completed Iteration #4
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8470> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a82e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b1d0> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 2.816901408450704 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 5.28169014084507 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 7.04225352112676 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 8.450704225352112 36
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 9.859154929577464 54
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 9.859154929577464 64
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80431d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8390> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043940> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043f28> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b1d0> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 3.169014084507042 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 5.633802816901408 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 7.394366197183098 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 8.80281690140845 37
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 10.211267605633802 55
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 10.211267605633802 65
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f28> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 3.169014084507042 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 5.633802816901408 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 7.394366197183098 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 8.80281690140845 38
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 10.211267605633802 56
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 10.211267605633802 66
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80504e0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8438> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 3.52112676056338 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 5.985915492957746 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 7.746478873239436 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 9.154929577464788 39
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 10.56338028169014 57
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 10.56338028169014 67
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050ba8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050cc0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083e80> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 3.873239436619718 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 6.338028169014084 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 8.098591549295774 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 9.507042253521126 40
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 10.915492957746478 58
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 10.915492957746478 68
Completed Iteration #14
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b198> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f28> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 1.76056338028169 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 4.225352112676056 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 6.690140845070422 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 8.450704225352112 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 9.859154929577464 41
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 11.267605633802816 59
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 11.267605633802816 69
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b6a0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 4.577464788732394 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 7.04225352112676 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 8.80281690140845 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 10.211267605633802 42
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 11.619718309859154 60
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 11.619718309859154 70
Completed Iteration #17
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a806bc18> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 4.929577464788732 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 7.394366197183098 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 9.154929577464788 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 10.56338028169014 43
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 11.971830985915492 61
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 11.971830985915492 71
Completed Iteration #18
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050cc0> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083e80> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 4.929577464788732 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 7.394366197183098 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 9.154929577464788 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 10.56338028169014 44
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 11.971830985915492 62
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 11.971830985915492 72
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043a90> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043898> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083e80> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 5.28169014084507 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 7.746478873239436 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 9.507042253521126 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 10.915492957746478 45
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 12.32394366197183 63
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 12.32394366197183 73
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b400> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8dd8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80506d8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 5.633802816901408 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 8.098591549295774 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 9.859154929577464 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 11.267605633802816 46
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 12.676056338028168 64
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 12.676056338028168 74
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #5
root->2->18->5->1->1
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b6d8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f28> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 2.112676056338028 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 5.985915492957746 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 8.450704225352112 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 10.211267605633802 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 11.619718309859154 47
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 13.028169014084506 65
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 13.028169014084506 75
Completed Iteration #1
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80435c0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f28> 1.76056338028169 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 2.464788732394366 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 6.338028169014084 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 8.80281690140845 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 10.56338028169014 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 11.971830985915492 48
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 13.380281690140844 66
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 13.380281690140844 76
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a81683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80504e0> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8438> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 2.464788732394366 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 6.338028169014084 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 8.80281690140845 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 10.56338028169014 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 11.971830985915492 49
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 13.380281690140844 67
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 13.380281690140844 77
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050c88> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050eb8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b198> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f28> 2.112676056338028 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 2.816901408450704 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 6.690140845070422 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 9.154929577464788 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 10.915492957746478 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 12.32394366197183 50
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 13.732394366197182 68
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 13.732394366197182 78
Completed Iteration #5
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a26a0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2588> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 3.169014084507042 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 7.04225352112676 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 9.507042253521126 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 11.267605633802816 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 12.676056338028168 51
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 14.08450704225352 69
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 14.08450704225352 79
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f98> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 3.52112676056338 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 7.394366197183098 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 9.859154929577464 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 11.619718309859154 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 13.028169014084506 52
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 14.436619718309858 70
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 14.436619718309858 80
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4160> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8438> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 3.873239436619718 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 7.746478873239436 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 10.211267605633802 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 11.971830985915492 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 13.380281690140844 53
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 14.788732394366196 71
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 14.788732394366196 81
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6978> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8438> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 4.225352112676056 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 8.098591549295774 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 10.56338028169014 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 12.32394366197183 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 13.732394366197182 54
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 15.140845070422534 72
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 15.140845070422534 82
Completed Iteration #14
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 4.577464788732394 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 8.450704225352112 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 10.915492957746478 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 12.676056338028168 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 14.08450704225352 55
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 15.492957746478872 73
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 15.492957746478872 83
Completed Iteration #15
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8fd0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86d8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 4.929577464788732 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 8.80281690140845 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 11.267605633802816 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 13.028169014084506 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 14.436619718309858 56
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 15.84507042253521 74
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 15.84507042253521 84
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2a90> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050278> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a26a0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2588> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 5.28169014084507 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 9.154929577464788 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 11.619718309859154 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 13.380281690140844 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 14.788732394366196 57
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 16.197183098591548 75
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 16.197183098591548 85
Completed Iteration #20
Best Reward: 0.352112676056338
coverage_call_count 300
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c49b0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 5.633802816901408 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 9.507042253521126 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 11.971830985915492 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 13.732394366197182 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 15.140845070422534 58
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 16.549295774647888 76
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 16.549295774647888 86
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #6
root->2->18->5->1->1->29
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 5.633802816901408 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 9.507042253521126 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 11.971830985915492 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 13.732394366197182 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 15.140845070422534 59
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 16.549295774647888 77
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 16.549295774647888 87
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1860> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1630> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c49b0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 1.76056338028169 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 5.985915492957746 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 9.859154929577464 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 12.32394366197183 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 14.08450704225352 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 15.492957746478872 60
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 16.901408450704224 78
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 16.901408450704224 88
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1cf8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1b38> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f98> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 2.112676056338028 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 6.338028169014084 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 10.211267605633802 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 12.676056338028168 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 14.436619718309858 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 15.84507042253521 61
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 17.25352112676056 79
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 17.25352112676056 89
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9588> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 2.464788732394366 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 6.690140845070422 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 10.56338028169014 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 13.028169014084506 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 14.788732394366196 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 16.197183098591548 62
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 17.605633802816897 80
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 17.605633802816897 90
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f98> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 2.464788732394366 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 6.690140845070422 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 10.56338028169014 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 13.028169014084506 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 14.788732394366196 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 16.197183098591548 63
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 17.605633802816897 81
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 17.605633802816897 91
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c49b0> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 2.464788732394366 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 6.690140845070422 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 10.56338028169014 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 13.028169014084506 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 14.788732394366196 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 16.197183098591548 64
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 17.605633802816897 82
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 17.605633802816897 92
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4b00> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4400> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8fd0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86d8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 2.816901408450704 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 7.04225352112676 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 10.915492957746478 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 13.380281690140844 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 15.140845070422534 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 16.549295774647888 65
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 17.957746478873233 83
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 17.957746478873233 93
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050f28> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 3.169014084507042 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 7.394366197183098 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 11.267605633802816 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 13.732394366197182 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 15.492957746478872 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 16.901408450704224 66
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 18.30985915492957 84
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 18.30985915492957 94
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1828> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 3.52112676056338 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 7.746478873239436 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 11.619718309859154 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 14.08450704225352 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 15.84507042253521 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 17.25352112676056 67
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 18.661971830985905 85
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 18.661971830985905 95
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86d8> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 3.52112676056338 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 7.746478873239436 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 11.619718309859154 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 14.08450704225352 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 15.84507042253521 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 17.25352112676056 68
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 18.661971830985905 86
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 18.661971830985905 96
Completed Iteration #23
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb278> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb0b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c49b0> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 3.873239436619718 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 8.098591549295774 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 11.971830985915492 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 14.436619718309858 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 16.197183098591548 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 17.605633802816897 69
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 19.01408450704224 87
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 19.01408450704224 97
Completed Iteration #24
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050f28> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 3.873239436619718 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 8.098591549295774 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 11.971830985915492 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 14.436619718309858 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 16.197183098591548 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 17.605633802816897 70
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 19.01408450704224 88
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 19.01408450704224 98
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #7
root->2->18->5->1->1->29->3
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4400> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8fd0> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86d8> 1.056338028169014 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 4.225352112676056 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 8.450704225352112 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 12.32394366197183 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 14.788732394366196 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 16.549295774647888 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 17.957746478873233 71
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 19.366197183098578 89
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 19.366197183098578 99
Completed Iteration #3
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 1.408450704225352 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 4.225352112676056 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 8.450704225352112 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 12.32394366197183 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 14.788732394366196 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 16.549295774647888 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 17.957746478873233 72
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 19.366197183098578 90
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 19.366197183098578 100
Completed Iteration #4
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c42e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86d8> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 1.76056338028169 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 4.577464788732394 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 8.80281690140845 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 12.676056338028168 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 15.140845070422534 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 16.901408450704224 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 18.30985915492957 73
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 19.718309859154914 91
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 19.718309859154914 101
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1f60> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1780> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 2.112676056338028 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 4.929577464788732 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 9.154929577464788 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 13.028169014084506 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 15.492957746478872 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 17.25352112676056 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 18.661971830985905 74
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 20.07042253521125 92
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 20.07042253521125 102
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 2.112676056338028 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 4.929577464788732 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 9.154929577464788 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 13.028169014084506 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 15.492957746478872 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 17.25352112676056 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 18.661971830985905 75
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 20.07042253521125 93
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 20.07042253521125 103
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fdd8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb4a8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c42e8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86d8> 1.76056338028169 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 2.464788732394366 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 5.28169014084507 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 9.507042253521126 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 13.380281690140844 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 15.84507042253521 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 17.605633802816897 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 19.01408450704224 76
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 20.422535211267586 94
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 20.422535211267586 104
Completed Iteration #21
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a277ffd0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86d8> 2.112676056338028 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 2.816901408450704 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 5.633802816901408 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 9.859154929577464 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 13.732394366197182 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 16.197183098591548 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 17.957746478873233 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 19.366197183098578 77
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 20.774647887323923 95
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 20.774647887323923 105
Completed Iteration #22
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d4a8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86d8> 2.464788732394366 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 3.169014084507042 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083080> 5.985915492957746 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67b8> 10.211267605633802 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 14.08450704225352 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c88> 16.549295774647888 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d54e0> 18.30985915492957 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 19.718309859154914 78
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 21.12676056338026 96
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc88> 21.12676056338026 106
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #8
root->2->18->5->1->1->29->3->1
Best Reward: 0.352112676056338
iteration: 5
found coverage increase 0.352112676056338
Current Total Coverage 9.859154929577464
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d94e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a24a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 9.859154929577464
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a277ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27472e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27472e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 400
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27472e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 9.859154929577464
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752cf8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563398 3
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563398 4
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563398 5
Completed Iteration #5
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563398 6
Completed Iteration #6
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.3521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563398 7
Completed Iteration #7
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.3521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563398 8
Completed Iteration #8
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.3521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563398 9
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563398 10
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.3521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563398 11
Completed Iteration #12
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767278> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.7042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 12
Completed Iteration #13
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 13
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.7042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 14
Completed Iteration #15
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 15
Completed Iteration #16
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.7042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 16
Completed Iteration #17
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 17
Completed Iteration #18
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 18
Completed Iteration #19
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 19
Completed Iteration #20
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 20
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.7042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 21
Completed Iteration #24
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 22
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752cf8> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 0.7042253521126796 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126796 23
Completed Iteration #0
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752358> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9f98> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767278> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 1.0563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 1.0563380281690193 24
Completed Iteration #1
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 1.4084507042253591 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 1.4084507042253591 25
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752358> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9f98> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767278> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 1.4084507042253591 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 1.4084507042253591 26
Completed Iteration #4
Best Reward: 0.3521126760563398
Completed Iteration #5
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 1.4084507042253591 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 1.4084507042253591 27
Completed Iteration #6
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774d30> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e48> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 1.760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 1.760563380281699 28
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767438> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774278> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752cf8> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 2.1126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 2.1126760563380387 29
Completed Iteration #10
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 2.1126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 2.1126760563380387 30
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 2.1126760563380387 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 2.1126760563380387 31
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 2.1126760563380387 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 2.1126760563380387 32
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 2.1126760563380387 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 2.1126760563380387 33
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a271aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767278> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 2.1126760563380387 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 2.1126760563380387 34
Completed Iteration #21
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728128> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e48> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 2.4647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 2.4647887323943785 35
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 2.4647887323943785 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 2.4647887323943785 36
Completed Iteration #23
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728748> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 2.8169014084507182 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 2.8169014084507182 37
Completed Iteration #24
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ae80> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e48> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 3.169014084507058 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 3.169014084507058 38
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 1.4084507042253591 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 3.169014084507058 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 3.169014084507058 39
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Completed Iteration #2
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728128> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e48> 1.0563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 1.4084507042253591 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 3.169014084507058 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 3.169014084507058 40
Completed Iteration #3
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733438> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733358> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728128> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e48> 1.4084507042253591 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 1.760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 3.521126760563398 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 3.521126760563398 41
Completed Iteration #4
Best Reward: 0.3521126760563398
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ae80> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e48> 1.4084507042253591 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 1.760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 3.521126760563398 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 3.521126760563398 42
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774d30> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e48> 1.4084507042253591 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 1.760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 3.521126760563398 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 3.521126760563398 43
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 1.760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 3.521126760563398 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 3.521126760563398 44
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a279db70> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a160> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 2.1126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 3.8732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 3.8732394366197376 45
Completed Iteration #13
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27479e8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e48> 1.760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 2.4647887323943785 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 4.225352112676077 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 4.225352112676077 46
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 2.8169014084507182 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 4.577464788732417 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 4.577464788732417 47
Completed Iteration #18
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676d8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 3.169014084507058 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 4.929577464788757 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 4.929577464788757 48
Completed Iteration #19
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279db70> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a160> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 3.169014084507058 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 4.929577464788757 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 4.929577464788757 49
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fcc0> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 3.873239436619734 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 5.633802816901433 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 5.633802816901433 50
Completed Iteration #22
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 1.4084507042253556 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 3.873239436619734 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 5.633802816901433 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 5.633802816901433 51
Completed Iteration #23
Best Reward: 0.704225352112676
Completed Iteration #24
Best Reward: 0.704225352112676
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #2
root->2->12
Best Reward: 0.704225352112676
Completed Iteration #0
Best Reward: 0.704225352112676
Completed Iteration #1
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f9b0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 1.7605633802816953 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 4.225352112676074 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 5.985915492957773 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 5.985915492957773 52
Completed Iteration #2
Best Reward: 0.704225352112676
Completed Iteration #3
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 1.7605633802816953 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 4.225352112676074 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 5.985915492957773 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 5.985915492957773 53
Completed Iteration #4
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebe48> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb7f0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676d8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 1.7605633802816953 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 2.112676056338035 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 4.577464788732414 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 6.3380281690141125 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 6.3380281690141125 54
Completed Iteration #5
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f9b0> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 2.112676056338035 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 4.577464788732414 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 6.3380281690141125 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 6.3380281690141125 55
Completed Iteration #6
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 2.4647887323943714 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 2.816901408450711 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 5.28169014084509 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 7.0422535211267885 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 7.0422535211267885 56
Completed Iteration #7
Best Reward: 0.704225352112676
Completed Iteration #8
Best Reward: 0.704225352112676
Completed Iteration #9
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767748> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747128> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 2.816901408450711 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 3.169014084507051 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 5.633802816901429 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 7.394366197183128 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 7.394366197183128 57
Completed Iteration #10
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 3.169014084507051 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 5.633802816901429 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 7.394366197183128 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 7.394366197183128 58
Completed Iteration #11
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fa20> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747128> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 3.169014084507051 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 3.5211267605633907 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 5.985915492957769 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 7.746478873239468 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 7.746478873239468 59
Completed Iteration #12
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 3.5211267605633907 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 5.985915492957769 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 7.746478873239468 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 7.746478873239468 60
Completed Iteration #13
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 3.5211267605633907 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 5.985915492957769 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 7.746478873239468 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 7.746478873239468 61
Completed Iteration #14
Best Reward: 0.704225352112676
coverage_call_count 500
Completed Iteration #15
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb0b8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 3.8732394366197305 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 6.338028169014109 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 8.098591549295808 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 8.098591549295808 62
Completed Iteration #16
Best Reward: 0.704225352112676
Completed Iteration #17
Best Reward: 0.704225352112676
Completed Iteration #18
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebef0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebd30> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 3.5211267605633907 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 4.22535211267607 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 6.690140845070449 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 8.450704225352148 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 8.450704225352148 63
Completed Iteration #19
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f0b8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d748> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb0b8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 4.57746478873241 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 7.0422535211267885 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 8.802816901408487 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 8.802816901408487 64
Completed Iteration #20
Best Reward: 0.704225352112676
Completed Iteration #21
Best Reward: 0.704225352112676
Completed Iteration #22
Best Reward: 0.704225352112676
Completed Iteration #23
Best Reward: 0.704225352112676
Completed Iteration #24
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f9b0> 0.3521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 4.57746478873241 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 7.0422535211267885 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 8.802816901408487 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 8.802816901408487 65
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #3
root->2->12->7
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4eb8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4828> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 2.8169014084507076 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 4.225352112676067 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 5.281690140845086 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 7.7464788732394645 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 9.507042253521163 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 9.507042253521163 66
Completed Iteration #0
Best Reward: 0.704225352112676
Completed Iteration #1
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1518> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747128> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 4.5774647887324065 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 5.633802816901426 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 8.098591549295804 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 9.859154929577503 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 9.859154929577503 67
Completed Iteration #2
Best Reward: 0.704225352112676
Completed Iteration #3
Best Reward: 0.704225352112676
Completed Iteration #4
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d97b8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4828> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 2.112676056338028 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 3.5211267605633836 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 5.2816901408450825 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 6.338028169014102 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 8.80281690140848 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 10.56338028169018 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 10.56338028169018 68
Completed Iteration #5
Best Reward: 0.704225352112676
Completed Iteration #6
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747128> 1.0563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 5.2816901408450825 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 6.338028169014102 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 8.80281690140848 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 10.56338028169018 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 10.56338028169018 69
Completed Iteration #7
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebef0> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebd30> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 5.2816901408450825 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 6.338028169014102 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 8.80281690140848 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 10.56338028169018 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 10.56338028169018 70
Completed Iteration #8
Best Reward: 0.704225352112676
Completed Iteration #9
Best Reward: 0.704225352112676
Completed Iteration #10
Best Reward: 0.704225352112676
Completed Iteration #11
Best Reward: 0.704225352112676
Completed Iteration #12
Best Reward: 0.704225352112676
Completed Iteration #13
Best Reward: 0.704225352112676
Completed Iteration #14
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f0f0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277ff28> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767748> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747128> 1.4084507042253591 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 5.633802816901422 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 6.690140845070442 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 9.15492957746482 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 10.915492957746519 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 10.915492957746519 71
Completed Iteration #15
Best Reward: 0.704225352112676
Completed Iteration #16
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747e48> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747128> 1.760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 5.985915492957762 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 7.042253521126781 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 9.50704225352116 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 11.267605633802859 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 11.267605633802859 72
Completed Iteration #17
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4c18> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4320> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fcc0> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 4.22535211267606 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 6.690140845070438 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 7.746478873239457 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 10.211267605633836 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 11.971830985915535 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 11.971830985915535 73
Completed Iteration #18
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fcc0> 1.408450704225352 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 4.22535211267606 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 6.690140845070438 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 7.746478873239457 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 10.211267605633836 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 11.971830985915535 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 11.971830985915535 74
Completed Iteration #19
Best Reward: 0.704225352112676
Completed Iteration #20
Best Reward: 0.704225352112676
Completed Iteration #21
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9128> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 4.577464788732399 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 7.042253521126778 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 8.098591549295797 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 10.563380281690176 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 12.323943661971875 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 12.323943661971875 75
Completed Iteration #22
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050710> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747128> 2.1126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 7.394366197183118 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 8.450704225352137 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 10.915492957746515 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 12.676056338028214 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 12.676056338028214 76
Completed Iteration #23
Best Reward: 0.704225352112676
Completed Iteration #24
Best Reward: 0.704225352112676
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #4
root->2->12->7->29
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d17b8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a90> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fcc0> 2.112676056338028 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 5.281690140845075 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 8.098591549295794 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 9.154929577464813 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 11.619718309859191 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 13.38028169014089 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 13.38028169014089 77
Completed Iteration #0
Best Reward: 0.704225352112676
Completed Iteration #1
Best Reward: 0.704225352112676
Completed Iteration #2
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a806bfd0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b1d0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9128> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 5.633802816901415 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 8.450704225352133 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 9.507042253521153 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 11.971830985915531 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 13.73239436619723 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 13.73239436619723 78
Completed Iteration #3
Best Reward: 0.704225352112676
Completed Iteration #4
Best Reward: 0.704225352112676
Completed Iteration #5
Best Reward: 0.704225352112676
Completed Iteration #6
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb630> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767e10> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4eb8> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4828> 1.7605633802816918 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 2.464788732394368 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 5.985915492957755 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 8.802816901408473 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 9.859154929577493 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 12.323943661971871 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 14.08450704225357 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 14.08450704225357 79
Completed Iteration #7
Best Reward: 0.704225352112676
Completed Iteration #8
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4e80> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 6.690140845070431 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 9.50704225352115 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 10.563380281690169 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 13.028169014084547 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 14.788732394366246 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 14.788732394366246 80
Completed Iteration #9
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9668> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4828> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 2.8169014084507076 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 7.042253521126771 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 9.859154929577489 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 10.915492957746508 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 13.380281690140887 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 15.140845070422586 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 15.140845070422586 81
Completed Iteration #10
Best Reward: 0.704225352112676
Completed Iteration #11
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050860> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050a58> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fcc0> 2.464788732394368 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 7.3943661971831105 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 10.211267605633829 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 11.267605633802848 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 13.732394366197227 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 15.492957746478925 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 15.492957746478925 82
Completed Iteration #12
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a80506d8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 8.098591549295787 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 10.915492957746505 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 11.971830985915524 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 14.436619718309903 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 16.1971830985916 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 16.1971830985916 83
Completed Iteration #13
Best Reward: 0.704225352112676
Completed Iteration #14
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1a20> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 8.802816901408463 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 11.61971830985918 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 12.6760563380282 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 15.140845070422579 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 16.901408450704277 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 16.901408450704277 84
Completed Iteration #15
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b908> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806bf28> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4e80> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 9.507042253521139 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 12.323943661971857 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 13.380281690140876 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 15.845070422535255 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 17.605633802816953 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 17.605633802816953 85
Completed Iteration #16
Best Reward: 0.704225352112676
Completed Iteration #17
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80437f0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4320> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fcc0> 2.8169014084507076 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 9.859154929577478 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 12.676056338028197 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 13.732394366197216 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 16.197183098591594 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 17.957746478873293 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 17.957746478873293 86
Completed Iteration #18
Best Reward: 0.704225352112676
Completed Iteration #19
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043d30> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80506d8> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 10.211267605633818 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 13.028169014084536 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 14.084507042253556 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 16.549295774647934 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 18.309859154929633 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 18.309859154929633 87
Completed Iteration #20
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043a58> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4828> 2.8169014084507076 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 3.5211267605633836 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 10.915492957746494 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 13.732394366197212 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 14.788732394366232 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 17.25352112676061 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 19.01408450704231 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 19.01408450704231 88
Completed Iteration #21
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 10.915492957746494 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 13.732394366197212 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 14.788732394366232 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 17.25352112676061 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 19.01408450704231 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 19.01408450704231 89
Completed Iteration #22
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 4.22535211267606 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 11.61971830985917 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 14.436619718309888 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 15.492957746478908 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 17.957746478873286 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 19.718309859154985 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 19.718309859154985 90
Completed Iteration #23
Best Reward: 0.704225352112676
Completed Iteration #24
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050f28> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 4.577464788732399 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 11.97183098591551 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 14.788732394366228 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 15.845070422535247 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 18.309859154929626 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 20.070422535211325 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 20.070422535211325 91
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #5
root->2->12->7->29->5
Best Reward: 0.704225352112676
Completed Iteration #0
Best Reward: 0.704225352112676
Completed Iteration #1
Best Reward: 0.704225352112676
Completed Iteration #2
Best Reward: 0.704225352112676
Completed Iteration #3
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050c88> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 4.929577464788739 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 12.32394366197185 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 15.140845070422568 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 16.197183098591587 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 18.661971830985966 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 20.422535211267665 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 20.422535211267665 92
Completed Iteration #4
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb710> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 1.7605633802816953 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 5.281690140845079 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 12.67605633802819 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 15.492957746478908 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 16.549295774647927 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 19.014084507042305 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 20.774647887324004 82
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 20.774647887324004 93
Completed Iteration #5
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043710> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043c50> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4eb8> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4828> 3.1690140845070474 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 5.633802816901419 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 13.02816901408453 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 15.845070422535247 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 16.901408450704267 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 19.366197183098645 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 21.126760563380344 83
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 21.126760563380344 94
Completed Iteration #6
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d97b8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4828> 3.1690140845070474 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 5.633802816901419 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 13.02816901408453 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 15.845070422535247 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 16.901408450704267 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 19.366197183098645 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 21.126760563380344 84
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 21.126760563380344 95
Completed Iteration #7
Best Reward: 0.704225352112676
Completed Iteration #8
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4710> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4a90> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9668> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4828> 3.521126760563387 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 5.9859154929577585 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 13.380281690140869 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 16.197183098591587 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 17.253521126760607 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 19.718309859154985 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 21.478873239436684 85
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 21.478873239436684 96
Completed Iteration #9
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a23c8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2d30> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050f28> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 2.4647887323943714 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 6.6901408450704345 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 14.084507042253545 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 16.901408450704263 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 17.957746478873283 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 20.42253521126766 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 22.18309859154936 86
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 22.18309859154936 97
Completed Iteration #10
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043ef0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2ef0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050f28> 1.4084507042253556 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 2.816901408450711 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 7.042253521126774 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 14.436619718309885 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 17.253521126760603 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 18.309859154929622 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 20.774647887324 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 22.5352112676057 87
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 22.5352112676057 98
Completed Iteration #11
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9c50> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 3.169014084507051 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 7.394366197183114 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 14.788732394366225 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 17.605633802816943 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 18.661971830985962 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 21.12676056338034 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 22.88732394366204 88
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 22.88732394366204 99
Completed Iteration #12
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050eb8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050978> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a23c8> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2d30> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050f28> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 3.873239436619727 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 8.09859154929579 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 15.4929577464789 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 18.30985915492962 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 19.366197183098638 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 21.830985915493017 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 23.591549295774715 89
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 23.591549295774715 100
Completed Iteration #13
Best Reward: 0.704225352112676
Completed Iteration #14
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043278> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043978> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 8.802816901408466 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 16.197183098591577 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 19.014084507042295 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 20.070422535211314 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 22.535211267605693 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 24.29577464788739 90
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 24.29577464788739 101
Completed Iteration #15
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b0f0> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b550> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 9.507042253521142 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 16.901408450704253 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 19.71830985915497 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 20.77464788732399 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 23.23943661971837 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 25.000000000000068 91
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 25.000000000000068 102
Completed Iteration #16
Best Reward: 0.704225352112676
Completed Iteration #17
Best Reward: 0.704225352112676
Completed Iteration #18
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4f98> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 4.225352112676067 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 9.859154929577482 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 17.253521126760592 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 20.07042253521131 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 21.12676056338033 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 23.59154929577471 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 25.352112676056407 92
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 25.352112676056407 103
Completed Iteration #19
Best Reward: 0.704225352112676
Completed Iteration #20
Best Reward: 0.704225352112676
Completed Iteration #21
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a22e8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2780> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 10.211267605633822 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 17.605633802816932 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 20.42253521126765 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 21.47887323943667 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 23.943661971831048 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 25.704225352112747 93
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 25.704225352112747 104
Completed Iteration #22
Best Reward: 0.704225352112676
Completed Iteration #23
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a89e8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 4.5774647887324065 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 10.563380281690161 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 17.957746478873272 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 20.77464788732399 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 21.83098591549301 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 24.295774647887388 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 26.056338028169087 94
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 26.056338028169087 105
Completed Iteration #24
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a82b0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4828> 3.873239436619727 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 10.915492957746501 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 18.30985915492961 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 21.12676056338033 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 22.18309859154935 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 24.647887323943728 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 26.408450704225427 95
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 26.408450704225427 106
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #6
root->2->12->7->29->5->10
Best Reward: 0.704225352112676
Completed Iteration #0
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8d68> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 4.929577464788746 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 11.267605633802841 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 18.66197183098595 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 21.47887323943667 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 22.53521126760569 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 25.000000000000068 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 26.760563380281766 96
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 26.760563380281766 107
Completed Iteration #1
Best Reward: 0.704225352112676
Completed Iteration #2
Best Reward: 0.704225352112676
Completed Iteration #3
Best Reward: 0.704225352112676
Completed Iteration #4
Best Reward: 0.704225352112676
Completed Iteration #5
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083320> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 5.633802816901422 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 11.971830985915517 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 19.366197183098627 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 22.183098591549346 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 23.239436619718365 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 25.704225352112744 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 27.464788732394442 97
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 27.464788732394442 108
Completed Iteration #6
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747438> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1b38> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050c88> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 5.985915492957762 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 12.323943661971857 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 19.718309859154967 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 22.535211267605685 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 23.591549295774705 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 26.056338028169083 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 27.816901408450782 98
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 27.816901408450782 109
Completed Iteration #7
Best Reward: 0.704225352112676
Completed Iteration #8
Best Reward: 0.704225352112676
Completed Iteration #9
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043b70> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747240> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8d68> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 6.338028169014102 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 12.676056338028197 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 20.070422535211307 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 22.887323943662025 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 23.943661971831045 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 26.408450704225423 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 28.169014084507122 99
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 28.169014084507122 110
Completed Iteration #10
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86a0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1b38> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050c88> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 6.690140845070442 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 13.028169014084536 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 20.422535211267647 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 23.239436619718365 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 24.295774647887384 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 26.760563380281763 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 28.52112676056346 100
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 28.52112676056346 111
Completed Iteration #11
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8d68> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 6.690140845070442 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 13.028169014084536 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 20.422535211267647 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 23.239436619718365 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 24.295774647887384 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 26.760563380281763 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 28.52112676056346 101
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 28.52112676056346 112
Completed Iteration #12
Best Reward: 0.704225352112676
Completed Iteration #13
Best Reward: 0.704225352112676
Completed Iteration #14
Best Reward: 0.704225352112676
coverage_call_count 600
Completed Iteration #15
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083be0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083128> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb710> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 7.042253521126781 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 13.380281690140876 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 20.774647887323987 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 23.591549295774705 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 24.647887323943724 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 27.112676056338103 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 28.8732394366198 102
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 28.8732394366198 113
Completed Iteration #16
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9c50> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 7.042253521126781 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 13.380281690140876 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 20.774647887323987 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 23.591549295774705 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 24.647887323943724 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 27.112676056338103 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 28.8732394366198 103
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 28.8732394366198 114
Completed Iteration #17
Best Reward: 0.704225352112676
Completed Iteration #18
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043b70> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747240> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8d68> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 7.042253521126781 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 13.380281690140876 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 20.774647887323987 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 23.591549295774705 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 24.647887323943724 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 27.112676056338103 82
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 28.8732394366198 104
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 28.8732394366198 115
Completed Iteration #19
Best Reward: 0.704225352112676
Completed Iteration #20
Best Reward: 0.704225352112676
Completed Iteration #21
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6080> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6ef0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a89e8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 7.394366197183121 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 13.732394366197216 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 21.126760563380326 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 23.943661971831045 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 25.000000000000064 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 27.464788732394442 83
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 29.22535211267614 105
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 29.22535211267614 116
Completed Iteration #22
Best Reward: 0.704225352112676
Completed Iteration #23
Best Reward: 0.704225352112676
Completed Iteration #24
Best Reward: 0.704225352112676
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #7
root->2->12->7->29->5->10->4
Best Reward: 0.704225352112676
Completed Iteration #0
Best Reward: 0.704225352112676
Completed Iteration #1
Best Reward: 0.704225352112676
Completed Iteration #2
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083f60> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 1.7605633802816918 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 7.746478873239461 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 14.084507042253556 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 21.478873239436666 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 24.295774647887384 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 25.352112676056404 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 27.816901408450782 84
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 29.57746478873248 106
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 29.57746478873248 117
Completed Iteration #3
Best Reward: 0.704225352112676
Completed Iteration #4
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8898> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 1.7605633802816918 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 2.464788732394368 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 8.450704225352137 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 14.788732394366232 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 22.183098591549342 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 25.00000000000006 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 26.05633802816908 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 28.521126760563458 85
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 30.281690140845157 107
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 30.281690140845157 118
Completed Iteration #5
Best Reward: 0.704225352112676
Completed Iteration #6
Best Reward: 0.704225352112676
Completed Iteration #7
Best Reward: 0.704225352112676
Completed Iteration #8
Best Reward: 0.704225352112676
Completed Iteration #9
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f66a0> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8048> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083320> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 2.464788732394368 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 3.169014084507044 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 9.154929577464813 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 15.492957746478908 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 22.887323943662018 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 25.704225352112736 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 26.760563380281756 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 29.225352112676134 86
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 30.985915492957833 108
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 30.985915492957833 119
Completed Iteration #10
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5f98> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5208> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 3.5211267605633836 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 9.507042253521153 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 15.845070422535247 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 23.239436619718358 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 26.056338028169076 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 27.112676056338096 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 29.577464788732474 87
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 31.338028169014173 109
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 31.338028169014173 120
Completed Iteration #11
Best Reward: 0.704225352112676
Completed Iteration #12
Best Reward: 0.704225352112676
Completed Iteration #13
Best Reward: 0.704225352112676
Completed Iteration #14
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d57b8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 3.169014084507044 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 4.22535211267606 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 10.211267605633829 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 16.549295774647923 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 23.943661971831034 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 26.760563380281752 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 27.81690140845077 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 30.28169014084515 88
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 32.04225352112685 110
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 32.04225352112685 121
Completed Iteration #15
Best Reward: 0.704225352112676
Completed Iteration #16
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb630> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5208> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 4.929577464788736 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 10.915492957746505 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 17.2535211267606 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 24.64788732394371 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 27.464788732394428 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 28.521126760563448 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 30.985915492957826 89
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 32.746478873239525 111
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 32.746478873239525 122
Completed Iteration #17
Best Reward: 0.704225352112676
Completed Iteration #18
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbbe0> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 3.5211267605633836 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 5.281690140845075 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 11.267605633802845 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 17.60563380281694 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 25.00000000000005 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 27.816901408450768 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 28.873239436619787 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 31.338028169014166 90
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 33.09859154929586 112
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 33.09859154929586 123
Completed Iteration #19
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbbe0> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 3.5211267605633836 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 5.281690140845075 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 11.267605633802845 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 17.60563380281694 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 25.00000000000005 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 27.816901408450768 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 28.873239436619787 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 31.338028169014166 91
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 33.09859154929586 113
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 33.09859154929586 124
Completed Iteration #20
Best Reward: 0.704225352112676
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083898> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043400> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083f60> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 3.8732394366197234 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 5.633802816901415 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 11.619718309859184 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 17.95774647887328 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 25.35211267605639 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 28.169014084507108 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 29.225352112676127 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 31.690140845070506 92
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 33.4507042253522 114
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 33.4507042253522 125
Completed Iteration #21
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5208> 1.0563380281690158 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 5.633802816901415 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 11.619718309859184 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 17.95774647887328 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 25.35211267605639 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 28.169014084507108 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 29.225352112676127 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 31.690140845070506 93
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 33.4507042253522 115
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 33.4507042253522 126
Completed Iteration #22
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8c18> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5fd0> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d57b8> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 4.577464788732399 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 6.338028169014091 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 12.32394366197186 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 18.661971830985955 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 26.056338028169066 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 28.873239436619784 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 29.929577464788803 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 32.39436619718318 94
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 34.15492957746487 116
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 34.15492957746487 127
Completed Iteration #23
Best Reward: 0.704225352112676
Completed Iteration #24
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8898> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083550> 4.577464788732399 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747dd8> 6.338028169014091 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f710> 12.32394366197186 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c88> 18.661971830985955 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d278> 26.056338028169066 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767470> 28.873239436619784 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a780> 29.929577464788803 82
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752908> 32.39436619718318 95
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529b0> 34.15492957746487 117
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 34.15492957746487 128
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #8
root->2->12->7->29->5->10->4->29
Best Reward: 0.704225352112676
iteration: 8
found coverage increase 0.704225352112676
Current Total Coverage 10.56338028169014
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbcf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 10.56338028169014
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 6
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 7
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd10c04aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 8
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 9
Completed Iteration #13
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80feba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 0.352112676056338 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 10
Completed Iteration #14
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 11
Completed Iteration #15
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 12
Completed Iteration #16
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 0.352112676056338 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 13
Completed Iteration #17
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 14
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.352112676056338 15
Completed Iteration #22
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a7b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 0.704225352112676 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 0.704225352112676 16
Completed Iteration #23
Best Reward: 0.352112676056338
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf4e0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 1.4084507042253538 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 1.4084507042253538 17
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf1d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 1.7605633802816918 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 1.7605633802816918 18
Completed Iteration #1
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff60> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 2.11267605633803 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 2.11267605633803 19
Completed Iteration #2
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6a0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168550> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf1d0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 2.464788732394368 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 2.464788732394368 20
Completed Iteration #3
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80feb70> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a128> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6a0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168550> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf1d0> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 2.816901408450706 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 2.816901408450706 21
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6c50> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8390> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff60> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 3.169014084507044 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 3.169014084507044 22
Completed Iteration #6
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 3.169014084507044 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 3.169014084507044 23
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 3.169014084507044 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 3.169014084507044 24
Completed Iteration #9
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfa90> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff60> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 3.521126760563382 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 3.521126760563382 25
Completed Iteration #10
Best Reward: 0.7042253521126778
coverage_call_count 700
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 1.7605633802816918 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 3.87323943661972 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 3.87323943661972 26
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe780> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ab38> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff60> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 4.225352112676058 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 4.225352112676058 27
Completed Iteration #13
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 4.225352112676058 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 4.225352112676058 28
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a81686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 4.225352112676058 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 4.225352112676058 29
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a81688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 4.225352112676058 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 4.225352112676058 30
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe0f0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168ef0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80feb70> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a128> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6a0> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168550> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf1d0> 1.7605633802816918 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 4.929577464788736 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 4.929577464788736 31
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 4.929577464788736 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 4.929577464788736 32
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1accc0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ace48> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe780> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ab38> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff60> 2.464788732394366 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 5.98591549295775 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 5.98591549295775 33
Completed Iteration #22
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 2.4647887323943696 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 6.690140845070427 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 6.690140845070427 34
Completed Iteration #23
Best Reward: 1.056338028169014
Completed Iteration #24
Best Reward: 1.056338028169014
Completed Iteration #25
Best Reward: 1.056338028169014
Completed MCTS Level/Depth: #1
root->6
Best Reward: 1.056338028169014
Completed Iteration #0
Best Reward: 1.056338028169014
Completed Iteration #1
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac5f8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 2.4647887323943696 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 2.8169014084507076 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 7.042253521126765 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 7.042253521126765 35
Completed Iteration #2
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1939b0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1938d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf4e0> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 2.8169014084507076 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 3.1690140845070456 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 7.394366197183103 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 7.394366197183103 36
Completed Iteration #3
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0c885ce10> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1938d0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf4e0> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 3.1690140845070456 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 3.5211267605633836 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 7.746478873239441 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 7.746478873239441 37
Completed Iteration #4
Best Reward: 1.056338028169014
Completed Iteration #5
Best Reward: 1.056338028169014
Completed Iteration #6
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f6d8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 3.5211267605633836 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 3.8732394366197216 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 8.09859154929578 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 8.09859154929578 38
Completed Iteration #7
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083668> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6278> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 4.22535211267606 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 8.450704225352117 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 8.450704225352117 39
Completed Iteration #8
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfbe0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6278> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 4.577464788732398 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 8.802816901408455 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 8.802816901408455 40
Completed Iteration #9
Best Reward: 1.056338028169014
Completed Iteration #10
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a668> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81684e0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a7b8> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 4.225352112676061 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 5.281690140845075 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 9.507042253521133 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 9.507042253521133 41
Completed Iteration #11
Best Reward: 1.056338028169014
Completed Iteration #12
Best Reward: 1.056338028169014
Completed Iteration #13
Best Reward: 1.056338028169014
Completed Iteration #14
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1931d0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 1.7605633802816918 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 1.7605633802816918 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 2.11267605633803 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 5.281690140845075 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 6.338028169014089 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 10.563380281690147 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 10.563380281690147 42
Completed Iteration #15
Best Reward: 1.056338028169014
Completed Iteration #16
Best Reward: 1.056338028169014
Completed Iteration #17
Best Reward: 1.056338028169014
Completed Iteration #18
Best Reward: 1.056338028169014
Completed Iteration #19
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cb00> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1938d0> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf4e0> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 5.985915492957753 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 7.042253521126767 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 11.267605633802825 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 11.267605633802825 43
Completed Iteration #20
Best Reward: 1.056338028169014
Completed Iteration #21
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cac8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c160> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083668> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6278> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 7.394366197183105 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 11.619718309859163 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 11.619718309859163 44
Completed Iteration #22
Best Reward: 1.056338028169014
Completed Iteration #23
Best Reward: 1.056338028169014
Completed Iteration #24
Best Reward: 1.056338028169014
Completed Iteration #25
Best Reward: 1.056338028169014
Completed MCTS Level/Depth: #2
root->6->17
Best Reward: 1.056338028169014
Completed Iteration #0
Best Reward: 1.056338028169014
Completed Iteration #1
Best Reward: 1.056338028169014
Completed Iteration #2
Best Reward: 1.056338028169014
Completed Iteration #3
Best Reward: 1.056338028169014
Completed Iteration #4
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff400> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 6.338028169014091 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 7.746478873239443 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 11.971830985915501 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 11.971830985915501 45
Completed Iteration #5
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a7b8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a81684e0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a7b8> 1.7605633802816936 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 7.042253521126769 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 8.450704225352121 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 12.676056338028179 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 12.676056338028179 46
Completed Iteration #6
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac88> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 7.394366197183107 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 8.802816901408459 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 13.028169014084517 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 13.028169014084517 47
Completed Iteration #7
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffeb8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 7.746478873239445 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 9.154929577464797 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 13.380281690140855 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 13.380281690140855 48
Completed Iteration #8
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168208> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 8.098591549295783 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 9.507042253521135 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 13.732394366197193 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 13.732394366197193 49
Completed Iteration #9
Best Reward: 1.056338028169014
Completed Iteration #10
Best Reward: 1.056338028169014
Completed Iteration #11
Best Reward: 1.056338028169014
Completed Iteration #12
Best Reward: 1.056338028169014
Completed Iteration #13
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728e80> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27289e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a7b8> 2.1126760563380316 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 8.450704225352121 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 9.859154929577473 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 14.08450704225353 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 14.08450704225353 50
Completed Iteration #14
Best Reward: 1.056338028169014
Completed Iteration #15
Best Reward: 1.056338028169014
Completed Iteration #16
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf2b0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe128> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a7b8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a81684e0> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a7b8> 2.8169014084507094 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 9.154929577464799 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 10.56338028169015 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 14.788732394366209 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 14.788732394366209 51
Completed Iteration #17
Best Reward: 1.056338028169014
Completed Iteration #18
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffc88> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c588> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a668> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a81684e0> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a7b8> 3.521126760563387 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 9.859154929577477 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 11.267605633802829 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 15.492957746478886 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 15.492957746478886 52
Completed Iteration #19
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752668> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c50> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff400> 1.0563380281690158 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 10.563380281690154 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 11.971830985915506 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 16.197183098591566 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 16.197183098591566 53
Completed Iteration #20
Best Reward: 1.056338028169014
Completed Iteration #21
Best Reward: 1.056338028169014
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff400> 1.0563380281690158 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 10.563380281690154 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 11.971830985915506 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 16.197183098591566 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 16.197183098591566 54
Completed Iteration #22
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ae10> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193470> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffeb8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 10.915492957746492 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 12.323943661971844 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 16.549295774647902 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 16.549295774647902 55
Completed Iteration #23
Best Reward: 1.056338028169014
Completed Iteration #24
Best Reward: 1.056338028169014
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe8d0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac88> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 11.26760563380283 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 12.676056338028182 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 16.90140845070424 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 16.90140845070424 56
Completed Iteration #25
Best Reward: 1.056338028169014
Completed MCTS Level/Depth: #3
root->6->17->7
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a7f0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 2.4647887323943696 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 2.8169014084507076 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 11.971830985915508 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 13.38028169014086 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 17.605633802816918 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 17.605633802816918 57
Completed Iteration #0
Best Reward: 1.056338028169014
Completed Iteration #1
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a27281d0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 3.1690140845070474 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 3.5211267605633854 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 12.676056338028186 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 14.084507042253538 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 18.309859154929597 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 18.309859154929597 58
Completed Iteration #2
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728b38> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 3.873239436619725 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 4.225352112676063 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 13.380281690140864 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 14.788732394366216 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 19.014084507042277 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 19.014084507042277 59
Completed Iteration #3
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733400> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 4.577464788732403 7
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 4.929577464788741 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 14.084507042253541 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 15.492957746478893 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 19.718309859154957 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 19.718309859154957 60
Completed Iteration #4
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733898> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733748> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 5.633802816901419 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 14.78873239436622 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 16.197183098591573 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 20.422535211267636 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 20.422535211267636 61
Completed Iteration #5
Best Reward: 1.056338028169014
Completed Iteration #6
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 2.816901408450706 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 5.633802816901417 8
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 6.690140845070433 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 15.845070422535233 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 17.25352112676059 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 21.478873239436652 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 21.478873239436652 62
Completed Iteration #7
Best Reward: 1.056338028169014
Completed Iteration #8
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a811acf8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c668> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27281d0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 6.338028169014095 9
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 7.3943661971831105 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 16.54929577464791 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 17.95774647887327 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 22.18309859154933 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 22.18309859154933 63
Completed Iteration #9
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac0b8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffe10> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733898> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733748> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 8.098591549295788 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 17.25352112676059 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 18.661971830985948 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 22.88732394366201 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 22.88732394366201 64
Completed Iteration #10
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1933c8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffe10> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733898> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733748> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 8.802816901408466 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 17.95774647887327 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 19.366197183098627 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 23.59154929577469 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 23.59154929577469 65
Completed Iteration #11
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728c50> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728908> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811acf8> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c668> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27281d0> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 7.0422535211267725 10
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 9.507042253521144 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 18.661971830985948 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 20.070422535211307 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 24.29577464788737 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 24.29577464788737 66
Completed Iteration #12
Best Reward: 1.056338028169014
Completed Iteration #13
Best Reward: 1.056338028169014
Completed Iteration #14
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a27336a0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728be0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 10.211267605633822 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 19.366197183098627 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 20.774647887323987 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 25.00000000000005 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 25.00000000000005 67
Completed Iteration #15
Best Reward: 1.056338028169014
Completed Iteration #16
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733080> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733da0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733898> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733748> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 10.9154929577465 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 20.070422535211307 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 21.478873239436666 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 25.70422535211273 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 25.70422535211273 68
Completed Iteration #17
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145278> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733748> 3.521126760563389 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 11.619718309859177 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 20.774647887323987 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 22.183098591549346 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 26.40845070422541 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 26.40845070422541 69
Completed Iteration #18
Best Reward: 1.056338028169014
Completed Iteration #19
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145978> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145748> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 3.87323943661972 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 8.098591549295787 11
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 12.676056338028191 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 21.830985915493002 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 23.23943661971836 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 27.464788732394425 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 27.464788732394425 70
Completed Iteration #20
Best Reward: 1.056338028169014
Completed Iteration #21
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145940> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733e10> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27336a0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728be0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 13.380281690140869 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 22.535211267605682 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 23.94366197183104 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 28.169014084507104 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 28.169014084507104 71
Completed Iteration #22
Best Reward: 1.056338028169014
Completed Iteration #23
Best Reward: 1.056338028169014
Completed Iteration #24
Best Reward: 1.056338028169014
Completed Iteration #25
Best Reward: 1.056338028169014
Completed MCTS Level/Depth: #4
root->6->17->7->17
Best Reward: 1.056338028169014
Completed Iteration #0
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151908> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151a20> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a7f0> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 8.802816901408464 12
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 14.084507042253547 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 23.23943661971836 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 24.64788732394372 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 28.873239436619784 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 28.873239436619784 72
Completed Iteration #1
Best Reward: 1.056338028169014
Completed Iteration #2
Best Reward: 1.056338028169014
Completed Iteration #3
Best Reward: 1.056338028169014
Completed Iteration #4
Best Reward: 1.056338028169014
Completed Iteration #5
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728390> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c518> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145978> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145748> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 4.225352112676056 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 4.929577464788734 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 9.859154929577478 13
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 15.14084507042256 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 24.295774647887377 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 25.704225352112736 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 29.9295774647888 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 29.9295774647888 73
Completed Iteration #6
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733e48> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151a20> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a7f0> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 10.563380281690156 14
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 15.845070422535239 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 25.000000000000057 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 26.408450704225416 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 30.63380281690148 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 30.63380281690148 74
Completed Iteration #7
Best Reward: 1.056338028169014
Completed Iteration #8
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a01456a0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01459b0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728b38> 1.7605633802816918 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 11.61971830985917 15
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 16.901408450704253 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 26.056338028169073 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 27.46478873239443 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 31.690140845070495 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 31.690140845070495 75
Completed Iteration #9
Best Reward: 1.056338028169014
Completed Iteration #10
Best Reward: 1.056338028169014
Completed Iteration #11
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145400> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 12.323943661971848 16
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 17.605633802816932 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 26.760563380281752 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 28.16901408450711 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 32.394366197183174 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 32.394366197183174 76
Completed Iteration #12
Best Reward: 1.056338028169014
coverage_call_count 800
Completed Iteration #13
Best Reward: 1.056338028169014
Completed Iteration #14
Best Reward: 1.056338028169014
Completed Iteration #15
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 4.929577464788734 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 5.633802816901412 7
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 13.028169014084526 17
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 18.30985915492961 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 27.46478873239443 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 28.87323943661979 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 33.098591549295854 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 33.098591549295854 77
Completed Iteration #16
Best Reward: 1.056338028169014
Completed Iteration #17
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b2b0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b3c8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a7f0> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 13.732394366197203 18
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 19.01408450704229 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 28.16901408450711 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 29.57746478873247 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 33.802816901408534 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 33.802816901408534 78
Completed Iteration #18
Best Reward: 1.056338028169014
Completed Iteration #19
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151b70> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 14.436619718309881 19
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 19.71830985915497 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 28.87323943661979 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 30.28169014084515 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 34.50704225352121 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 34.50704225352121 79
Completed Iteration #20
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a016ba20> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b978> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145400> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 15.140845070422559 20
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 20.42253521126765 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 29.57746478873247 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 30.98591549295783 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 35.21126760563389 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 35.21126760563389 80
Completed Iteration #21
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a016beb8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016bc18> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811acf8> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c668> 2.1126760563380333 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27281d0> 2.816901408450711 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 15.845070422535237 21
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 21.12676056338033 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 30.28169014084515 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 31.69014084507051 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 35.91549295774657 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 35.91549295774657 81
Completed Iteration #22
Best Reward: 1.056338028169014
Completed Iteration #23
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a01764a8> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01765c0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27281d0> 3.521126760563389 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 16.549295774647916 22
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 21.83098591549301 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 30.98591549295783 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 32.39436619718319 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 36.61971830985925 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 36.61971830985925 82
Completed Iteration #24
Best Reward: 1.056338028169014
Completed Iteration #25
Best Reward: 1.056338028169014
Completed MCTS Level/Depth: #5
root->6->17->7->17->2
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a27289b0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c518> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145978> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145748> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 4.225352112676056 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 5.985915492957748 7
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 6.690140845070426 8
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 17.605633802816932 23
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 22.887323943662025 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 32.042253521126845 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 33.450704225352204 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 37.67605633802827 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 37.67605633802827 83
Completed Iteration #0
Best Reward: 1.056338028169014
Completed Iteration #1
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 1.7605633802816918 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 7.042253521126762 8
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 7.74647887323944 9
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 18.661971830985948 24
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 23.94366197183104 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 33.09859154929586 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 34.50704225352122 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 38.73239436619728 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 38.73239436619728 84
Completed Iteration #2
Best Reward: 1.056338028169014
Completed Iteration #3
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145a20> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151da0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1931d0> 1.7605633802816918 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 7.74647887323944 9
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 8.450704225352117 10
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 19.366197183098627 25
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 24.64788732394372 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 33.80281690140854 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 35.2112676056339 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 39.43661971830996 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 39.43661971830996 85
Completed Iteration #4
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b198> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145390> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 2.816901408450706 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 8.802816901408454 10
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 9.507042253521131 11
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 20.422535211267643 26
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 25.704225352112736 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 34.85915492957756 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 36.267605633802916 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 40.49295774647898 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 40.49295774647898 86
Completed Iteration #5
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a016bb00> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b8d0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 10.21126760563381 12
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 21.126760563380323 27
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 26.408450704225416 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 35.563380281690236 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 36.971830985915595 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 41.19718309859166 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 41.19718309859166 87
Completed Iteration #6
Best Reward: 1.056338028169014
Completed Iteration #7
Best Reward: 1.056338028169014
Completed Iteration #8
Best Reward: 1.056338028169014
Completed Iteration #9
Best Reward: 1.056338028169014
Completed Iteration #10
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a01766d8> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c518> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145978> 4.225352112676056 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145748> 4.225352112676056 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 5.28169014084507 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 9.859154929577468 11
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 11.267605633802823 13
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 22.18309859154934 28
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 27.46478873239443 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 36.61971830985925 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 38.02816901408461 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 42.253521126760674 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 42.253521126760674 88
Completed Iteration #11
Best Reward: 1.056338028169014
Completed Iteration #12
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176f98> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176e48> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016bb00> 1.7605633802816918 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b8d0> 1.7605633802816918 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 12.323943661971837 14
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 23.239436619718354 29
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 28.521126760563448 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 37.67605633802827 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 39.08450704225363 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 43.30985915492969 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 43.30985915492969 89
Completed Iteration #13
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a01104e0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b8d0> 2.4647887323943696 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 13.028169014084515 15
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 23.943661971831034 30
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 29.225352112676127 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 38.38028169014095 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 39.788732394366306 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 44.01408450704237 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 44.01408450704237 90
Completed Iteration #14
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733908> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145748> 5.28169014084507 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 6.338028169014084 7
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 10.915492957746482 12
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 14.084507042253529 16
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 25.00000000000005 31
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 30.281690140845143 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 39.43661971830996 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 40.84507042253532 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 45.070422535211385 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 45.070422535211385 91
Completed Iteration #15
Best Reward: 1.056338028169014
Completed Iteration #16
Best Reward: 1.056338028169014
Completed Iteration #17
Best Reward: 1.056338028169014
Completed Iteration #18
Best Reward: 1.056338028169014
Completed Iteration #19
Best Reward: 1.056338028169014
Completed Iteration #20
Best Reward: 1.056338028169014
Completed Iteration #21
Best Reward: 1.056338028169014
Completed Iteration #22
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151fd0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 3.87323943661972 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 11.971830985915496 13
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 15.140845070422543 17
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 26.056338028169066 32
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 31.33802816901416 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 40.49295774647898 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 41.90140845070434 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 46.1267605633804 82
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 46.1267605633804 92
Completed Iteration #23
Best Reward: 1.056338028169014
Completed Iteration #24
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110400> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01763c8> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1931d0> 2.816901408450706 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 13.02816901408451 14
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 16.19718309859156 18
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 27.11267605633808 33
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 32.394366197183174 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 41.549295774647995 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 42.957746478873354 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 47.18309859154942 83
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 47.18309859154942 93
Completed Iteration #25
Best Reward: 1.056338028169014
Completed MCTS Level/Depth: #6
root->6->17->7->17->2->14
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176d68> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 13.732394366197187 15
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 16.90140845070424 19
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 27.81690140845076 34
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 33.098591549295854 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 42.253521126760674 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 43.66197183098603 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 47.887323943662096 84
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 47.887323943662096 94
Completed Iteration #0
Best Reward: 1.056338028169014
Completed Iteration #1
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a271aef0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b5c0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733908> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145748> 6.338028169014084 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 7.394366197183098 8
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 14.788732394366201 16
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 17.957746478873254 20
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 28.873239436619777 35
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 34.15492957746487 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 43.30985915492969 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 44.71830985915505 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 48.94366197183111 85
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 48.94366197183111 95
Completed Iteration #2
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110828> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 15.49295774647888 17
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 18.661971830985934 21
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 29.577464788732456 36
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 34.85915492957755 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 44.01408450704237 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 45.42253521126773 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 49.64788732394379 86
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 49.64788732394379 96
Completed Iteration #3
Best Reward: 1.056338028169014
Completed Iteration #4
Best Reward: 1.056338028169014
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110eb8> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110c88> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271aef0> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b5c0> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733908> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145748> 7.394366197183098 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 8.450704225352112 9
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 16.549295774647895 18
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 19.71830985915495 22
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 30.633802816901472 37
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 35.915492957746565 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 45.070422535211385 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 46.478873239436744 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 50.70422535211281 87
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 50.70422535211281 97
Completed Iteration #5
Best Reward: 1.056338028169014
Completed Iteration #6
Best Reward: 1.056338028169014
Completed Iteration #7
Best Reward: 1.056338028169014
Completed Iteration #8
Best Reward: 1.056338028169014
Completed Iteration #9
Best Reward: 1.056338028169014
Completed Iteration #10
Best Reward: 1.056338028169014
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129588> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 17.253521126760575 19
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 20.42253521126763 23
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 31.33802816901415 38
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 36.619718309859245 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 45.774647887324065 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 47.183098591549424 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 51.40845070422549 88
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 51.40845070422549 98
Completed Iteration #11
Best Reward: 1.056338028169014
Reward: 1.7605633802816918
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176160> 1.7605633802816918 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176358> 1.7605633802816918 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b198> 2.816901408450706 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145390> 2.816901408450706 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 3.87323943661972 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 4.929577464788734 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 5.633802816901412 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 19.014084507042266 20
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 22.18309859154932 24
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 33.09859154929585 39
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 38.38028169014093 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 47.53521126760576 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 48.94366197183112 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 53.16901408450718 89
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 53.16901408450718 99
Completed Iteration #12
Best Reward: 1.7605633802816918
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145c18> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01510f0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110400> 1.7605633802816918 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a01763c8> 1.7605633802816918 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1931d0> 3.5211267605633836 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 19.718309859154942 21
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 22.887323943661997 25
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 33.80281690140853 40
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 39.08450704225361 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 48.23943661971844 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 49.6478873239438 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 53.87323943661986 90
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 53.87323943661986 100
Completed Iteration #13
Best Reward: 1.7605633802816918
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176fd0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733b00> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110eb8> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110c88> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271aef0> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b5c0> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733908> 4.225352112676056 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145748> 8.450704225352112 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 9.507042253521126 10
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 20.774647887323958 22
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 23.943661971831013 26
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 34.85915492957754 41
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 40.14084507042263 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 49.295774647887455 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 50.704225352112815 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 54.92957746478888 91
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 54.92957746478888 101
Completed Iteration #14
Best Reward: 1.7605633802816918
Completed Iteration #15
Best Reward: 1.7605633802816918
Completed Iteration #16
Best Reward: 1.7605633802816918
Reward: 1.408450704225352
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110f60> 1.408450704225352 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01109e8> 1.408450704225352 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110828> 2.11267605633803 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 22.18309859154931 23
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 25.352112676056365 27
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 36.267605633802894 42
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 41.54929577464798 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 50.70422535211281 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 52.11267605633817 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 56.33802816901423 92
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 56.33802816901423 102
Completed Iteration #17
Best Reward: 1.7605633802816918
Completed Iteration #18
Best Reward: 1.7605633802816918
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129668> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 5.985915492957748 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 6.690140845070426 7
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 23.239436619718326 24
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 26.40845070422538 28
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 37.32394366197191 43
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 42.605633802816996 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 51.76056338028182 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 53.16901408450718 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 57.394366197183246 93
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 57.394366197183246 103
Completed Iteration #19
Best Reward: 1.7605633802816918
Completed Iteration #20
Best Reward: 1.7605633802816918
Completed Iteration #21
Best Reward: 1.7605633802816918
Reward: 2.112676056338028
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129e10> 2.112676056338028 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136198> 2.112676056338028 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b198> 4.929577464788734 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145390> 4.929577464788734 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 5.985915492957748 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 8.098591549295776 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 8.802816901408454 8
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 25.352112676056354 25
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 28.52112676056341 29
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 39.43661971830994 44
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 44.71830985915503 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 53.873239436619855 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 55.281690140845214 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 59.50704225352128 94
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 59.50704225352128 104
Completed Iteration #22
Best Reward: 2.112676056338028
Completed Iteration #23
Best Reward: 2.112676056338028
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136710> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01364e0> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733908> 4.929577464788734 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145748> 9.15492957746479 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cc0> 10.211267605633804 11
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 26.05633802816903 26
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 29.225352112676084 30
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 40.14084507042262 45
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 45.42253521126771 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 54.577464788732534 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 55.98591549295789 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 60.21126760563396 95
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 60.21126760563396 105
Completed Iteration #24
Best Reward: 2.112676056338028
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728630> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffc50> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151fd0> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 9.15492957746479 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 9.859154929577468 9
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 27.112676056338046 27
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 30.2816901408451 31
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 41.19718309859164 46
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 46.47887323943672 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 55.63380281690155 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 57.04225352112691 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 61.26760563380297 96
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 61.26760563380297 106
Completed Iteration #25
Best Reward: 2.112676056338028
Completed MCTS Level/Depth: #7
root->6->17->7->17->2->14->4
Best Reward: 2.112676056338028
Completed Iteration #0
Best Reward: 2.112676056338028
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733a20> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145390> 5.985915492957748 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 7.042253521126762 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 10.211267605633804 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 10.915492957746482 10
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 28.16901408450706 28
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 31.338028169014116 32
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 42.25352112676065 47
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 47.53521126760574 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 56.690140845070566 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 58.098591549295925 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 62.32394366197199 97
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 62.32394366197199 107
Completed Iteration #1
Best Reward: 2.112676056338028
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a01291d0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176358> 2.816901408450706 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b198> 5.985915492957748 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145390> 7.042253521126762 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 8.098591549295776 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 11.267605633802818 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 11.971830985915496 11
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 29.225352112676077 29
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 32.39436619718313 33
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 43.30985915492967 48
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 48.591549295774755 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 57.74647887323958 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 59.15492957746494 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 63.380281690141004 98
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 63.380281690141004 108
Completed Iteration #2
Best Reward: 2.112676056338028
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a01290b8> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145390> 8.098591549295776 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 9.15492957746479 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 12.323943661971832 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 13.02816901408451 12
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 30.281690140845093 30
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 33.45070422535215 34
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 44.366197183098684 49
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 49.64788732394377 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 58.8028169014086 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 60.21126760563396 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 64.43661971831001 99
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 64.43661971831001 109
Completed Iteration #3
Best Reward: 2.112676056338028
Reward: 2.112676056338028
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110e80> 2.112676056338028 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01102e8> 2.112676056338028 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129e10> 4.225352112676056 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136198> 4.225352112676056 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b198> 8.098591549295776 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145390> 10.211267605633804 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 11.267605633802818 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 14.43661971830986 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 15.140845070422538 13
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 32.39436619718312 31
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 35.56338028169017 35
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 46.47887323943671 50
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 51.760563380281795 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 60.91549295774662 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 62.32394366197198 82
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 66.54929577464804 100
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 66.54929577464804 110
Completed Iteration #4
Best Reward: 2.112676056338028
Completed Iteration #5
Best Reward: 2.112676056338028
Completed Iteration #6
Best Reward: 2.112676056338028
Completed Iteration #7
Best Reward: 2.112676056338028
Completed Iteration #8
Best Reward: 2.112676056338028
Completed Iteration #9
Best Reward: 2.112676056338028
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5208> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136c88> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01290b8> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145390> 11.267605633802818 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 12.323943661971832 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 15.492957746478874 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 16.19718309859155 14
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 33.45070422535213 32
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 36.61971830985919 36
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 47.535211267605725 51
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 52.81690140845081 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 61.97183098591564 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 63.380281690141 83
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 67.60563380281705 101
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 67.60563380281705 111
Completed Iteration #10
Best Reward: 2.112676056338028
Completed Iteration #11
Best Reward: 2.112676056338028
Completed Iteration #12
Best Reward: 2.112676056338028
Completed Iteration #13
Best Reward: 2.112676056338028
Completed Iteration #14
Best Reward: 2.112676056338028
Completed Iteration #15
Best Reward: 2.112676056338028
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2160> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5f60> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728630> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffc50> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151fd0> 3.169014084507042 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 16.549295774647888 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 17.253521126760567 15
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 34.50704225352115 33
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 37.676056338028204 37
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 48.59154929577474 52
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 53.873239436619826 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 63.028169014084654 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 64.43661971831001 84
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 68.66197183098606 102
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 68.66197183098606 112
Completed Iteration #16
Best Reward: 2.112676056338028
Completed Iteration #17
Best Reward: 2.112676056338028
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b6a0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733668> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733a20> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145390> 12.323943661971832 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 13.380281690140846 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 17.605633802816904 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 18.309859154929583 16
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 35.563380281690165 34
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 38.73239436619722 38
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 49.647887323943756 53
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 54.92957746478884 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 64.08450704225366 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 65.49295774647902 85
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 69.71830985915507 103
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 69.71830985915507 113
Completed Iteration #18
Best Reward: 2.112676056338028
Completed Iteration #19
Best Reward: 2.112676056338028
Completed Iteration #20
Best Reward: 2.112676056338028
Completed Iteration #21
Best Reward: 2.112676056338028
Completed Iteration #22
Best Reward: 2.112676056338028
Completed Iteration #23
Best Reward: 2.112676056338028
Reward: 1.056338028169014
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ef0> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110208> 1.056338028169014 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129668> 2.112676056338028 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac50> 18.66197183098592 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151c18> 19.3661971830986 17
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acc50> 36.61971830985918 35
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935f8> 39.788732394366235 39
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 50.70422535211277 54
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 55.98591549295786 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a080> 65.14084507042267 82
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f69b0> 66.54929577464803 86
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb518> 70.77464788732408 104
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5c18> 70.77464788732408 114
Completed Iteration #24
Best Reward: 2.112676056338028
Completed Iteration #25
Best Reward: 2.112676056338028
Completed MCTS Level/Depth: #8
root->6->17->7->17->2->14->4->13
Best Reward: 2.112676056338028
iteration: 10
found coverage increase 2.112676056338028
Current Total Coverage 12.676056338028168
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 900
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 12.676056338028168
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01769b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01294e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 12.676056338028168
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a01107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00889e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00887f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00888d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00886a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00888d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 12.676056338028168
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00886d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00886d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 12.676056338028168
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00692e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00444e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044ef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 12.676056338028168
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00445c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00445c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 12.676056338028168
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058eb8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 0.352112676056338 5
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3860> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3cf8> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 0.704225352112676 6
Completed Iteration #5
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3cf8> 0.352112676056338 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 0.704225352112676 7
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 0.704225352112676 8
Completed Iteration #8
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088860> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 1.056338028169014 9
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 1.056338028169014 10
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 1.056338028169014 11
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a01100b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 1.056338028169014 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 1.408450704225352 12
Completed Iteration #16
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 1.408450704225352 13
Completed Iteration #17
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 1.408450704225352 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 1.76056338028169 14
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb630> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb320> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3860> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3cf8> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 2.112676056338028 15
Completed Iteration #20
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3cf8> 0.704225352112676 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 2.112676056338028 16
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbef278> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5a58> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 2.464788732394366 17
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #0
root
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 1.408450704225352 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 2.464788732394366 18
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Completed Iteration #3
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfa080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbefe80> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058eb8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 1.76056338028169 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 2.816901408450704 19
Completed Iteration #4
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbefda0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbefe80> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058eb8> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 2.112676056338028 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 3.169014084507042 20
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 2.112676056338028 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 3.169014084507042 21
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 2.112676056338028 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 3.169014084507042 22
Completed Iteration #8
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 2.112676056338028 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 3.169014084507042 23
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058c88> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 2.464788732394366 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 3.52112676056338 24
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 2.464788732394366 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 3.52112676056338 25
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7550> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b6d8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 2.816901408450704 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 3.873239436619718 26
Completed Iteration #12
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069048> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5be0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058eb8> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 3.169014084507042 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 4.225352112676056 27
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058eb8> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 3.169014084507042 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 4.225352112676056 28
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbefc50> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbef6d8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01100b8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 3.52112676056338 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 4.577464788732394 29
Completed Iteration #18
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfa400> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b6d8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 3.873239436619718 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 4.929577464788732 30
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfaf98> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfaa20> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 4.225352112676056 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 5.28169014084507 31
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #1
root->3
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95828> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb955f8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfaf98> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfaa20> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 4.577464788732394 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 5.633802816901408 32
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Completed Iteration #3
Best Reward: 0.352112676056338
coverage_call_count 1100
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c88> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 2.112676056338028 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 4.929577464788732 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 5.985915492957746 33
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bba04a8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 2.464788732394366 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 5.28169014084507 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 6.338028169014084 34
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95f98> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 2.816901408450704 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 5.633802816901408 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 6.690140845070422 35
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0668> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfaa20> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 3.169014084507042 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 5.985915492957746 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 7.04225352112676 36
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0e10> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 3.52112676056338 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 6.338028169014084 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 7.394366197183098 37
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7550> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b6d8> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 3.52112676056338 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 6.338028169014084 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 7.394366197183098 38
Completed Iteration #15
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 3.873239436619718 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 6.690140845070422 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 7.746478873239436 39
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #2
root->3->6
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 1.76056338028169 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 3.873239436619718 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 6.690140845070422 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 7.746478873239436 40
Completed Iteration #2
Best Reward: 0.352112676056338
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 2.112676056338028 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 4.225352112676056 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 7.04225352112676 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 8.098591549295774 41
Completed Iteration #7
Best Reward: 0.352112676056338
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfa588> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 2.464788732394366 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 4.577464788732394 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 7.394366197183098 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 8.450704225352112 42
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #3
root->3->6->0
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb4b780> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 2.816901408450704 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 4.929577464788732 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 7.746478873239436 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 8.80281690140845 43
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Completed Iteration #3
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb546a0> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 3.169014084507042 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 5.28169014084507 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 8.098591549295774 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 9.154929577464788 44
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60898> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 3.52112676056338 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 5.633802816901408 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 8.450704225352112 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 9.507042253521126 45
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60940> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 2.112676056338028 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 3.873239436619718 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 5.985915492957746 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 8.80281690140845 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 9.859154929577464 46
Completed Iteration #17
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70358> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 2.112676056338028 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 2.464788732394366 8
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 4.225352112676056 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 6.338028169014084 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 9.154929577464788 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 10.211267605633802 47
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb709e8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb707b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 2.816901408450704 9
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 4.577464788732394 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 6.690140845070422 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 9.507042253521126 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 10.56338028169014 48
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb709e8> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb707b8> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 2.816901408450704 10
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 4.577464788732394 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 6.690140845070422 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 9.507042253521126 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 10.56338028169014 49
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #4
root->3->6->0->2
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0390> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 2.464788732394366 8
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 3.169014084507042 11
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 4.929577464788732 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 7.04225352112676 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 9.859154929577464 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 10.915492957746478 50
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbefe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 2.464788732394366 9
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 3.169014084507042 12
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 4.929577464788732 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 7.04225352112676 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 9.859154929577464 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 10.915492957746478 51
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #5
root->3->6->0->2->6
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Completed Iteration #3
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb15c88> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 2.816901408450704 10
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 3.52112676056338 13
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 5.28169014084507 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 7.394366197183098 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 10.211267605633802 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 11.267605633802816 52
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Completed Iteration #8
Best Reward: 0.352112676056338
coverage_call_count 1200
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23eb8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23c88> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb546a0> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 3.169014084507042 11
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 3.873239436619718 14
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 5.633802816901408 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 7.746478873239436 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 10.56338028169014 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 11.619718309859154 53
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb604a8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23a58> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb15c88> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 2.112676056338028 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 3.52112676056338 12
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 4.225352112676056 15
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 5.985915492957746 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 8.098591549295774 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 10.915492957746478 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 11.971830985915492 54
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #6
root->3->6->0->2->6->0
Best Reward: 0.352112676056338
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f198> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb32f98> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23eb8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23c88> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb546a0> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 2.112676056338028 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 2.464788732394366 8
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 3.873239436619718 13
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 4.577464788732394 16
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 6.338028169014084 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 8.450704225352112 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 11.267605633802816 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 12.32394366197183 55
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb230b8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 2.464788732394366 8
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 2.816901408450704 9
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 4.225352112676056 14
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 4.929577464788732 17
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 6.690140845070422 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 8.80281690140845 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 11.619718309859154 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 12.676056338028168 56
Completed Iteration #8
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60f60> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb32f98> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23eb8> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23c88> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb546a0> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 2.816901408450704 9
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 3.169014084507042 10
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 4.577464788732394 15
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 5.28169014084507 18
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 7.04225352112676 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 9.154929577464788 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 11.971830985915492 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 13.028169014084506 57
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb705f8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 3.169014084507042 10
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 3.52112676056338 11
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 4.929577464788732 16
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 5.633802816901408 19
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 7.394366197183098 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 9.507042253521126 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 12.32394366197183 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 13.380281690140844 58
Completed Iteration #15
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb54c50> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23c88> 1.408450704225352 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb546a0> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 3.52112676056338 11
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 3.873239436619718 12
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 5.28169014084507 17
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 5.985915492957746 20
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 7.746478873239436 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 9.859154929577464 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 12.676056338028168 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 13.732394366197182 59
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb32748> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0898> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb604a8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23a58> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb15c88> 1.056338028169014 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 3.873239436619718 12
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 4.225352112676056 13
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 5.633802816901408 18
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 6.338028169014084 21
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 8.098591549295774 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 10.211267605633802 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 13.028169014084506 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 14.08450704225352 60
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #7
root->3->6->0->2->6->0->3
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb156d8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23c88> 1.76056338028169 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bb546a0> 2.112676056338028 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 4.225352112676056 13
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 4.577464788732394 14
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 5.985915492957746 19
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 6.690140845070422 22
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 8.450704225352112 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 10.56338028169014 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 13.380281690140844 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 14.436619718309858 61
Completed Iteration #0
Best Reward: 0.352112676056338
Completed Iteration #1
Best Reward: 0.352112676056338
Completed Iteration #2
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa58> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23c88> 2.112676056338028 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bb546a0> 2.464788732394366 8
backprop <src.mcts.MCTS_Node object at 0x7fd06bb547b8> 4.577464788732394 14
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 4.929577464788732 15
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 6.338028169014084 20
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0978> 7.04225352112676 23
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c50> 8.80281690140845 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 10.915492957746478 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c50> 13.732394366197182 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a00698d0> 14.788732394366196 62
Completed Iteration #3
Best Reward: 0.352112676056338
Completed Iteration #4
Best Reward: 0.352112676056338
Completed Iteration #5
Best Reward: 0.352112676056338
Completed Iteration #6
Best Reward: 0.352112676056338
Completed Iteration #7
Best Reward: 0.352112676056338
Completed Iteration #8
Best Reward: 0.352112676056338
Completed Iteration #9
Best Reward: 0.352112676056338
Completed Iteration #10
Best Reward: 0.352112676056338
Completed Iteration #11
Best Reward: 0.352112676056338
Completed Iteration #12
Best Reward: 0.352112676056338
Completed Iteration #13
Best Reward: 0.352112676056338
Completed Iteration #14
Best Reward: 0.352112676056338
Completed Iteration #15
Best Reward: 0.352112676056338
Completed Iteration #16
Best Reward: 0.352112676056338
Completed Iteration #17
Best Reward: 0.352112676056338
Completed Iteration #18
Best Reward: 0.352112676056338
Completed Iteration #19
Best Reward: 0.352112676056338
Completed Iteration #20
Best Reward: 0.352112676056338
Completed Iteration #21
Best Reward: 0.352112676056338
Completed Iteration #22
Best Reward: 0.352112676056338
Completed Iteration #23
Best Reward: 0.352112676056338
Completed Iteration #24
Best Reward: 0.352112676056338
Completed Iteration #25
Best Reward: 0.352112676056338
Completed MCTS Level/Depth: #8
root->3->6->0->2->6->0->3->0
Best Reward: 0.352112676056338
iteration: 17
found coverage increase 0.352112676056338
Current Total Coverage 13.028169014084506
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb32ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fa20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 13.028169014084506
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb953c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 13.028169014084506
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f128> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.7042253521126778 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 10
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 11
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 12
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.7042253521126778 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 13
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.7042253521126778 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 14
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.7042253521126778 8
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 15
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 16
Completed Iteration #24
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 17
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.7042253521126778 9
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 18
Completed Iteration #5
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.7042253521126778 10
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 19
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb54860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.7042253521126778 11
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 20
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.7042253521126778 12
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 21
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 0.7042253521126778 13
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 0.7042253521126778 22
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Reward: 0.7042253521126778
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6630> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e438> 0.7042253521126778 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f128> 1.4084507042253556 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 1.4084507042253556 14
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 1.4084507042253556 23
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 1.4084507042253556 15
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 1.4084507042253556 24
Completed Iteration #20
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb54860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 1.4084507042253556 16
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 1.4084507042253556 25
Completed Iteration #21
Best Reward: 0.7042253521126778
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c080> 1.4084507042253556 17
backprop <src.mcts.MCTS_Node object at 0x7fd06bae58d0> 1.4084507042253556 26
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #1
root->7
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #2
root->7->26
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
coverage_call_count 1400
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #3
root->7->26->8
Best Reward: 0.7042253521126778
Completed Iteration #0
Best Reward: 0.7042253521126778
Completed Iteration #1
Best Reward: 0.7042253521126778
Completed Iteration #2
Best Reward: 0.7042253521126778
Completed Iteration #3
Best Reward: 0.7042253521126778
Completed Iteration #4
Best Reward: 0.7042253521126778
Completed Iteration #5
Best Reward: 0.7042253521126778
Completed Iteration #6
Best Reward: 0.7042253521126778
Completed Iteration #7
Best Reward: 0.7042253521126778
Completed Iteration #8
Best Reward: 0.7042253521126778
Completed Iteration #9
Best Reward: 0.7042253521126778
Completed Iteration #10
Best Reward: 0.7042253521126778
Completed Iteration #11
Best Reward: 0.7042253521126778
Completed Iteration #12
Best Reward: 0.7042253521126778
Completed Iteration #13
Best Reward: 0.7042253521126778
Completed Iteration #14
Best Reward: 0.7042253521126778
Completed Iteration #15
Best Reward: 0.7042253521126778
Completed Iteration #16
Best Reward: 0.7042253521126778
Completed Iteration #17
Best Reward: 0.7042253521126778
Completed Iteration #18
Best Reward: 0.7042253521126778
Completed Iteration #19
Best Reward: 0.7042253521126778
Completed Iteration #20
Best Reward: 0.7042253521126778
Completed Iteration #21
Best Reward: 0.7042253521126778
Completed Iteration #22
Best Reward: 0.7042253521126778
Completed Iteration #23
Best Reward: 0.7042253521126778
Completed Iteration #24
Best Reward: 0.7042253521126778
Completed Iteration #25
Best Reward: 0.7042253521126778
Completed MCTS Level/Depth: #4
root->7->26->8->26
Best Reward: 0.7042253521126778
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0.7042253521126778
Current Total Coverage 13.732394366197184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba456a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba456a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba456a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f4e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 13.732394366197184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 13.732394366197184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 1500
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 13.732394366197184
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 13.732394366197184
Completed Iteration #0
Best Reward: 0
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 0.704225352112676 2
Completed Iteration #1
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 0.704225352112676 3
Completed Iteration #2
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 0.704225352112676 4
Completed Iteration #3
Best Reward: 0.704225352112676
Completed Iteration #4
Best Reward: 0.704225352112676
Completed Iteration #5
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 0.704225352112676 5
Completed Iteration #6
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e278> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 1.408450704225352 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 1.408450704225352 6
Completed Iteration #7
Best Reward: 0.704225352112676
Completed Iteration #8
Best Reward: 0.704225352112676
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e278> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9eeb8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 1.76056338028169 7
Completed Iteration #9
Best Reward: 0.704225352112676
Completed Iteration #10
Best Reward: 0.704225352112676
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9ef60> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9eeb8> 0.704225352112676 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 2.112676056338028 8
Completed Iteration #11
Best Reward: 0.704225352112676
Completed Iteration #12
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e278> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9eeb8> 0.704225352112676 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 2.112676056338028 9
Completed Iteration #13
Best Reward: 0.704225352112676
Completed Iteration #14
Best Reward: 0.704225352112676
Completed Iteration #15
Best Reward: 0.704225352112676
Completed Iteration #16
Best Reward: 0.704225352112676
Completed Iteration #17
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9eeb8> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 2.112676056338028 10
Completed Iteration #18
Best Reward: 0.704225352112676
Completed Iteration #19
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9eeb8> 0.704225352112676 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 2.112676056338028 11
Completed Iteration #20
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 2.112676056338028 12
Completed Iteration #21
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 1.408450704225352 7
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 2.112676056338028 13
Completed Iteration #22
Best Reward: 0.704225352112676
Completed Iteration #23
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e438> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5b38> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 2.112676056338028 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 2.112676056338028 8
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 2.816901408450704 14
Completed Iteration #24
Best Reward: 0.704225352112676
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd06bae54a8> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e080> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 3.169014084507042 15
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #0
root
Best Reward: 0.704225352112676
Completed Iteration #0
Best Reward: 0.704225352112676
Completed Iteration #1
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9b0> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 2.816901408450704 9
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 3.873239436619718 16
Completed Iteration #2
Best Reward: 0.704225352112676
Completed Iteration #3
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 2.816901408450704 10
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 3.873239436619718 17
Completed Iteration #4
Best Reward: 0.704225352112676
Completed Iteration #5
Best Reward: 0.704225352112676
Completed Iteration #6
Best Reward: 0.704225352112676
Completed Iteration #7
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 2.816901408450704 11
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 3.873239436619718 18
Completed Iteration #8
Best Reward: 0.704225352112676
Completed Iteration #9
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 2.816901408450704 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 3.52112676056338 12
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 4.577464788732394 19
Completed Iteration #10
Best Reward: 0.704225352112676
Completed Iteration #11
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 3.52112676056338 13
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 4.577464788732394 20
Completed Iteration #12
Best Reward: 0.704225352112676
Completed Iteration #13
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 3.52112676056338 14
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 4.577464788732394 21
Completed Iteration #14
Best Reward: 0.704225352112676
Completed Iteration #15
Best Reward: 0.704225352112676
Completed Iteration #16
Best Reward: 0.704225352112676
Completed Iteration #17
Best Reward: 0.704225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 3.52112676056338 15
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 4.577464788732394 22
Completed Iteration #18
Best Reward: 0.704225352112676
Completed Iteration #19
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3fb70> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 4.225352112676056 16
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 5.28169014084507 23
Completed Iteration #20
Best Reward: 0.704225352112676
Completed Iteration #21
Best Reward: 0.704225352112676
Completed Iteration #22
Best Reward: 0.704225352112676
Completed Iteration #23
Best Reward: 0.704225352112676
Completed Iteration #24
Best Reward: 0.704225352112676
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.704225352112676
Completed Iteration #0
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb32518> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba044e0> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e438> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5b38> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 3.52112676056338 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 4.929577464788732 17
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 5.985915492957746 24
Completed Iteration #1
Best Reward: 0.704225352112676
Completed Iteration #2
Best Reward: 0.704225352112676
Completed Iteration #3
Best Reward: 0.704225352112676
Completed Iteration #4
Best Reward: 0.704225352112676
Completed Iteration #5
Best Reward: 0.704225352112676
Completed Iteration #6
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23ef0> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 2.112676056338028 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 4.225352112676056 7
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 5.633802816901408 18
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 6.690140845070422 25
Completed Iteration #7
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb236a0> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23828> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 2.816901408450704 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 4.929577464788732 8
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 6.338028169014084 19
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 7.394366197183098 26
Completed Iteration #8
Best Reward: 0.704225352112676
Completed Iteration #9
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb15828> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 3.52112676056338 6
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 5.633802816901408 9
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 7.04225352112676 20
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 8.098591549295774 27
Completed Iteration #10
Best Reward: 0.704225352112676
Completed Iteration #11
Best Reward: 0.704225352112676
Completed Iteration #12
Best Reward: 0.704225352112676
Completed Iteration #13
Best Reward: 0.704225352112676
Completed Iteration #14
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7630> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e898> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 6.338028169014084 10
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 7.746478873239436 21
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 8.80281690140845 28
Completed Iteration #15
Best Reward: 0.704225352112676
Completed Iteration #16
Best Reward: 0.704225352112676
Completed Iteration #17
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bae5080> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb15748> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f7630> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e898> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 7.04225352112676 11
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 8.450704225352112 22
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 9.507042253521126 29
Completed Iteration #18
Best Reward: 0.704225352112676
Completed Iteration #19
Best Reward: 0.704225352112676
coverage_call_count 1600
Completed Iteration #20
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70550> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e898> 2.112676056338028 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 7.746478873239436 12
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 9.154929577464788 23
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 10.211267605633802 30
Completed Iteration #21
Best Reward: 0.704225352112676
Completed Iteration #22
Best Reward: 0.704225352112676
Completed Iteration #23
Best Reward: 0.704225352112676
Completed Iteration #24
Best Reward: 0.704225352112676
Completed Iteration #25
Best Reward: 0.704225352112676
Completed MCTS Level/Depth: #2
root->6->8
Best Reward: 0.704225352112676
Completed Iteration #0
Best Reward: 0.704225352112676
Completed Iteration #1
Best Reward: 0.704225352112676
Completed Iteration #2
Best Reward: 0.704225352112676
Completed Iteration #3
Best Reward: 0.704225352112676
Completed Iteration #4
Best Reward: 0.704225352112676
Completed Iteration #5
Best Reward: 0.704225352112676
Completed Iteration #6
Best Reward: 0.704225352112676
Completed Iteration #7
Best Reward: 0.704225352112676
Completed Iteration #8
Best Reward: 0.704225352112676
Completed Iteration #9
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb32358> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 4.225352112676056 7
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 8.450704225352112 13
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 9.859154929577464 24
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 10.915492957746478 31
Completed Iteration #10
Best Reward: 0.704225352112676
Completed Iteration #11
Best Reward: 0.704225352112676
Completed Iteration #12
Best Reward: 0.704225352112676
Completed Iteration #13
Best Reward: 0.704225352112676
Completed Iteration #14
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8cb70> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 4.929577464788732 8
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 9.154929577464788 14
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 10.56338028169014 25
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 11.619718309859154 32
Completed Iteration #15
Best Reward: 0.704225352112676
Completed Iteration #16
Best Reward: 0.704225352112676
Completed Iteration #17
Best Reward: 0.704225352112676
Completed Iteration #18
Best Reward: 0.704225352112676
Completed Iteration #19
Best Reward: 0.704225352112676
Completed Iteration #20
Best Reward: 0.704225352112676
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70b38> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23828> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 2.112676056338028 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 5.633802816901408 9
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 9.859154929577464 15
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 11.267605633802816 26
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 12.32394366197183 33
Completed Iteration #21
Best Reward: 0.704225352112676
Completed Iteration #22
Best Reward: 0.704225352112676
Completed Iteration #23
Best Reward: 0.704225352112676
Completed Iteration #24
Best Reward: 0.704225352112676
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 3.1690140845070403 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 6.69014084507042 10
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 10.915492957746476 16
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 12.323943661971828 27
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 13.380281690140842 34
Completed Iteration #25
Best Reward: 1.0563380281690122
Completed MCTS Level/Depth: #3
root->6->8->8
Best Reward: 1.0563380281690122
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e10> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 4.2253521126760525 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 7.7464788732394325 11
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 11.971830985915489 17
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 13.38028169014084 28
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 14.436619718309855 35
Completed Iteration #0
Best Reward: 1.0563380281690122
Completed Iteration #1
Best Reward: 1.0563380281690122
Completed Iteration #2
Best Reward: 1.0563380281690122
Completed Iteration #3
Best Reward: 1.0563380281690122
Completed Iteration #4
Best Reward: 1.0563380281690122
Completed Iteration #5
Best Reward: 1.0563380281690122
Completed Iteration #6
Best Reward: 1.0563380281690122
Completed Iteration #7
Best Reward: 1.0563380281690122
Completed Iteration #8
Best Reward: 1.0563380281690122
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb4bc88> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23828> 2.112676056338028 4
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 4.9295774647887285 7
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 8.450704225352109 12
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 12.676056338028165 18
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 14.084507042253517 29
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 15.14084507042253 36
Completed Iteration #9
Best Reward: 1.0563380281690122
Completed Iteration #10
Best Reward: 1.0563380281690122
Completed Iteration #11
Best Reward: 1.0563380281690122
Completed Iteration #12
Best Reward: 1.0563380281690122
Reward: 1.4084507042253502
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0400> 1.4084507042253502 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 2.4647887323943625 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 3.5211267605633747 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 3.5211267605633747 4
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 6.338028169014079 8
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 9.859154929577459 13
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 14.084507042253515 19
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 15.492957746478867 30
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 16.54929577464788 37
Completed Iteration #13
Best Reward: 1.4084507042253502
Completed Iteration #14
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb54d68> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb54eb8> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e10> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 3.5211267605633747 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 4.577464788732387 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 4.577464788732387 5
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 7.394366197183091 9
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 10.915492957746471 14
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 15.140845070422527 20
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 16.54929577464788 31
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 17.605633802816893 38
Completed Iteration #15
Best Reward: 1.4084507042253502
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0d30> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 5.281690140845063 6
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 8.098591549295767 10
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 11.619718309859147 15
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 15.845070422535203 21
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 17.253521126760557 32
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 18.30985915492957 39
Completed Iteration #16
Best Reward: 1.4084507042253502
Completed Iteration #17
Best Reward: 1.4084507042253502
Completed Iteration #18
Best Reward: 1.4084507042253502
Completed Iteration #19
Best Reward: 1.4084507042253502
Completed Iteration #20
Best Reward: 1.4084507042253502
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb32c18> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 5.985915492957739 7
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 8.802816901408443 11
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 12.323943661971823 16
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 16.54929577464788 22
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 17.957746478873233 33
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 19.014084507042245 40
Completed Iteration #21
Best Reward: 1.4084507042253502
Completed Iteration #22
Best Reward: 1.4084507042253502
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06ba8c940> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4eac8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb4bc88> 1.408450704225352 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb23828> 2.816901408450704 5
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 9.507042253521119 12
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 13.028169014084499 17
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 17.253521126760557 23
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 18.66197183098591 34
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 19.71830985915492 41
Completed Iteration #23
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70940> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 7.042253521126751 8
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 10.563380281690131 13
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 14.084507042253511 18
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 18.30985915492957 24
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 19.71830985915492 35
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 20.774647887323933 42
Completed Iteration #24
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3f390> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 8.098591549295763 9
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 11.619718309859143 14
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 15.140845070422523 19
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 19.36619718309858 25
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 20.774647887323933 36
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 21.830985915492946 43
Completed Iteration #25
Best Reward: 1.4084507042253502
Completed MCTS Level/Depth: #4
root->6->8->8->4
Best Reward: 1.4084507042253502
Completed Iteration #0
Best Reward: 1.4084507042253502
Completed Iteration #1
Best Reward: 1.4084507042253502
Completed Iteration #2
Best Reward: 1.4084507042253502
Completed Iteration #3
Best Reward: 1.4084507042253502
Completed Iteration #4
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60f28> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70240> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0d30> 1.7605633802816882 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 9.154929577464776 10
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 12.676056338028156 15
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 16.197183098591537 20
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 20.422535211267594 26
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 21.830985915492946 37
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 22.887323943661958 44
Completed Iteration #5
Best Reward: 1.4084507042253502
Completed Iteration #6
Best Reward: 1.4084507042253502
Reward: 1.4084507042253502
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 1.4084507042253502 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0cc0> 1.4084507042253502 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0400> 2.8169014084507005 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 4.929577464788725 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 5.985915492957737 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 10.563380281690126 11
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 14.084507042253506 16
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 17.60563380281689 21
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 21.830985915492946 27
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 23.239436619718298 38
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 24.295774647887306 45
Completed Iteration #7
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95588> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70240> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0d30> 2.8169014084507005 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 11.619718309859138 12
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 15.140845070422518 17
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 18.6619718309859 22
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 22.887323943661958 28
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 24.29577464788731 39
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 25.35211267605632 46
Completed Iteration #8
Best Reward: 1.4084507042253502
Completed Iteration #9
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95048> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0cc0> 2.4647887323943625 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0400> 3.8732394366197127 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 5.985915492957737 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 7.042253521126749 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 12.67605633802815 13
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 16.19718309859153 18
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 19.718309859154914 23
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 23.94366197183097 29
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 25.352112676056322 40
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 26.40845070422533 47
Completed Iteration #10
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0c88> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70240> 3.1690140845070367 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0d30> 3.8732394366197127 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 13.732394366197163 14
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 17.253521126760543 19
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 20.774647887323926 24
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 24.999999999999982 30
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 26.408450704225334 41
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 27.464788732394343 48
Completed Iteration #11
Best Reward: 1.4084507042253502
Completed Iteration #12
Best Reward: 1.4084507042253502
Completed Iteration #13
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0860> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb54eb8> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e10> 3.1690140845070367 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 7.042253521126749 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 8.098591549295762 8
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 14.788732394366175 15
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 18.309859154929555 20
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 21.83098591549294 25
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 26.056338028168994 31
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 27.464788732394346 42
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 28.521126760563355 49
Completed Iteration #14
Best Reward: 1.4084507042253502
Completed Iteration #15
Best Reward: 1.4084507042253502
Completed Iteration #16
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06ba12518> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70240> 4.225352112676049 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0d30> 4.929577464788725 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 15.845070422535187 16
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 19.366197183098567 21
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 22.88732394366195 26
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 27.112676056338007 32
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 28.52112676056336 43
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 29.577464788732367 50
Completed Iteration #17
Best Reward: 1.4084507042253502
Reward: 0.704225352112676
backprop <src.mcts.MCTS_Node object at 0x7fd06bb605f8> 0.704225352112676 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70240> 4.929577464788725 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0d30> 5.633802816901401 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 16.549295774647863 17
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 20.070422535211243 22
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 23.591549295774627 27
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 27.816901408450683 33
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 29.225352112676035 44
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 30.281690140845043 51
Completed Iteration #18
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb3feb8> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb54eb8> 3.1690140845070367 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e10> 4.225352112676049 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 8.098591549295762 8
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 9.154929577464774 9
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 17.605633802816875 18
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 21.126760563380255 23
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 24.64788732394364 28
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 28.873239436619695 34
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 30.281690140845047 45
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 31.338028169014056 52
Completed Iteration #19
Best Reward: 1.4084507042253502
Completed Iteration #20
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60f98> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 9.154929577464774 9
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 10.211267605633786 10
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 18.661971830985888 19
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 22.183098591549268 24
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 25.70422535211265 29
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 29.929577464788707 35
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 31.33802816901406 46
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 32.39436619718307 53
Completed Iteration #21
Best Reward: 1.4084507042253502
Completed Iteration #22
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0fd0> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0668> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 11.267605633802798 11
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 19.7183098591549 20
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 23.23943661971828 25
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 26.760563380281663 30
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 30.98591549295772 36
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 32.394366197183075 47
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 33.450704225352084 54
Completed Iteration #23
Best Reward: 1.4084507042253502
Completed Iteration #24
Best Reward: 1.4084507042253502
Completed Iteration #25
Best Reward: 1.4084507042253502
Completed MCTS Level/Depth: #5
root->6->8->8->4->8
Best Reward: 1.4084507042253502
Completed Iteration #0
Best Reward: 1.4084507042253502
Completed Iteration #1
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95630> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 10.211267605633786 10
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 12.32394366197181 12
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 20.774647887323912 21
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 24.295774647887292 26
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 27.816901408450676 31
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 32.04225352112673 37
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 33.450704225352084 48
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 34.50704225352109 55
Completed Iteration #2
Best Reward: 1.4084507042253502
Completed Iteration #3
Best Reward: 1.4084507042253502
Completed Iteration #4
Best Reward: 1.4084507042253502
Completed Iteration #5
Best Reward: 1.4084507042253502
Completed Iteration #6
Best Reward: 1.4084507042253502
Completed Iteration #7
Best Reward: 1.4084507042253502
Completed Iteration #8
Best Reward: 1.4084507042253502
Completed Iteration #9
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb15198> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088198> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb54d68> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb54eb8> 4.225352112676049 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e10> 5.281690140845061 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 11.267605633802798 11
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 13.380281690140823 13
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 21.830985915492924 22
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 25.352112676056304 27
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 28.873239436619688 32
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 33.09859154929575 38
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 34.50704225352109 49
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 35.5633802816901 56
Completed Iteration #10
Best Reward: 1.4084507042253502
Completed Iteration #11
Best Reward: 1.4084507042253502
Completed Iteration #12
Best Reward: 1.4084507042253502
Completed Iteration #13
Best Reward: 1.4084507042253502
Completed Iteration #14
Best Reward: 1.4084507042253502
Completed Iteration #15
Best Reward: 1.4084507042253502
Completed Iteration #16
Best Reward: 1.4084507042253502
Completed Iteration #17
Best Reward: 1.4084507042253502
Completed Iteration #18
Best Reward: 1.4084507042253502
Completed Iteration #19
Best Reward: 1.4084507042253502
coverage_call_count 1700
Completed Iteration #20
Best Reward: 1.4084507042253502
Completed Iteration #21
Best Reward: 1.4084507042253502
Completed Iteration #22
Best Reward: 1.4084507042253502
Completed Iteration #23
Best Reward: 1.4084507042253502
Completed Iteration #24
Best Reward: 1.4084507042253502
Completed Iteration #25
Best Reward: 1.4084507042253502
Completed MCTS Level/Depth: #6
root->6->8->8->4->8->9
Best Reward: 1.4084507042253502
Completed Iteration #0
Best Reward: 1.4084507042253502
Completed Iteration #1
Best Reward: 1.4084507042253502
Completed Iteration #2
Best Reward: 1.4084507042253502
Completed Iteration #3
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3ac8> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3860> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60f98> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 12.32394366197181 12
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 14.436619718309835 14
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 22.887323943661936 23
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 26.408450704225316 28
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 29.9295774647887 33
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 34.154929577464756 39
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 35.5633802816901 50
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 36.61971830985911 57
Completed Iteration #4
Best Reward: 1.4084507042253502
Completed Iteration #5
Best Reward: 1.4084507042253502
Completed Iteration #6
Best Reward: 1.4084507042253502
Completed Iteration #7
Best Reward: 1.4084507042253502
Completed Iteration #8
Best Reward: 1.4084507042253502
Completed Iteration #9
Best Reward: 1.4084507042253502
Completed Iteration #10
Best Reward: 1.4084507042253502
Completed Iteration #11
Best Reward: 1.4084507042253502
Completed Iteration #12
Best Reward: 1.4084507042253502
Completed Iteration #13
Best Reward: 1.4084507042253502
Completed Iteration #14
Best Reward: 1.4084507042253502
Completed Iteration #15
Best Reward: 1.4084507042253502
Completed Iteration #16
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95978> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 13.380281690140823 13
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 15.492957746478847 15
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 23.94366197183095 24
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 27.46478873239433 29
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 30.985915492957712 34
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 35.211267605633765 40
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 36.61971830985911 51
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 37.67605633802812 58
Completed Iteration #17
Best Reward: 1.4084507042253502
Completed Iteration #18
Best Reward: 1.4084507042253502
Completed Iteration #19
Best Reward: 1.4084507042253502
Reward: 1.4084507042253502
backprop <src.mcts.MCTS_Node object at 0x7fd06bbefdd8> 1.4084507042253502 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0cc0> 3.8732394366197127 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0400> 5.281690140845063 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 14.788732394366173 14
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 16.901408450704196 16
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 25.3521126760563 25
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 28.873239436619677 30
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 32.39436619718306 35
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 36.61971830985912 41
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 38.02816901408446 52
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 39.08450704225347 59
Completed Iteration #20
Best Reward: 1.4084507042253502
Completed Iteration #21
Best Reward: 1.4084507042253502
Completed Iteration #22
Best Reward: 1.4084507042253502
Completed Iteration #23
Best Reward: 1.4084507042253502
Completed Iteration #24
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb02e8> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbef4e0> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3ac8> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3860> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60f98> 3.1690140845070367 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 15.845070422535185 15
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 17.957746478873208 17
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 26.408450704225313 26
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 29.92957746478869 31
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 33.45070422535207 36
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 37.67605633802813 42
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 39.08450704225348 53
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 40.140845070422486 60
Completed Iteration #25
Best Reward: 1.4084507042253502
Completed MCTS Level/Depth: #7
root->6->8->8->4->8->9->6
Best Reward: 1.4084507042253502
Completed Iteration #0
Best Reward: 1.4084507042253502
Completed Iteration #1
Best Reward: 1.4084507042253502
Completed Iteration #2
Best Reward: 1.4084507042253502
Completed Iteration #3
Best Reward: 1.4084507042253502
Completed Iteration #4
Best Reward: 1.4084507042253502
Completed Iteration #5
Best Reward: 1.4084507042253502
Reward: 1.4084507042253502
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb710> 1.4084507042253502 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95c88> 1.4084507042253502 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba09b0> 2.8169014084507005 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0cc0> 5.281690140845063 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0400> 6.690140845070413 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 17.253521126760536 16
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 19.366197183098556 18
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 27.81690140845066 27
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 31.338028169014038 32
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 34.85915492957742 37
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 39.084507042253485 43
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 40.49295774647883 54
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 41.54929577464784 61
Completed Iteration #6
Best Reward: 1.4084507042253502
Completed Iteration #7
Best Reward: 1.4084507042253502
Reward: 1.4084507042253502
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058fd0> 1.4084507042253502 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058048> 1.4084507042253502 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0400> 8.098591549295763 7
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 18.661971830985884 17
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 20.77464788732391 19
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 29.225352112676013 28
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 32.74647887323939 33
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 36.26760563380277 38
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 40.49295774647884 44
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 41.90140845070418 55
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 42.95774647887319 62
Completed Iteration #8
Best Reward: 1.4084507042253502
Completed Iteration #9
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044a20> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044fd0> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058fd0> 2.4647887323943625 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058048> 2.4647887323943625 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0400> 9.154929577464776 8
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 19.718309859154896 18
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 21.83098591549292 20
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 30.281690140845026 29
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 33.802816901408406 34
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 37.32394366197178 39
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 41.549295774647845 45
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 42.95774647887319 56
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 44.0140845070422 63
Completed Iteration #10
Best Reward: 1.4084507042253502
Completed Iteration #11
Best Reward: 1.4084507042253502
Completed Iteration #12
Best Reward: 1.4084507042253502
Completed Iteration #13
Best Reward: 1.4084507042253502
Completed Iteration #14
Best Reward: 1.4084507042253502
Completed Iteration #15
Best Reward: 1.4084507042253502
Completed Iteration #16
Best Reward: 1.4084507042253502
Completed Iteration #17
Best Reward: 1.4084507042253502
Reward: 1.0563380281690122
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0a58> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3cf8> 1.0563380281690122 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044a20> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044fd0> 2.1126760563380245 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058fd0> 3.5211267605633747 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058048> 3.5211267605633747 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0400> 10.211267605633788 9
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60e80> 20.77464788732391 19
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70a58> 22.887323943661933 21
backprop <src.mcts.MCTS_Node object at 0x7fd06bb60fd0> 31.338028169014038 30
backprop <src.mcts.MCTS_Node object at 0x7fd06baf6f60> 34.859154929577414 35
backprop <src.mcts.MCTS_Node object at 0x7fd06ba9e9e8> 38.38028169014079 40
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f78d0> 42.605633802816854 46
backprop <src.mcts.MCTS_Node object at 0x7fd06ba4e780> 44.0140845070422 57
backprop <src.mcts.MCTS_Node object at 0x7fd06ba04e10> 45.07042253521121 64
Completed Iteration #18
Best Reward: 1.4084507042253502
Completed Iteration #19
Best Reward: 1.4084507042253502
Completed Iteration #20
Best Reward: 1.4084507042253502
Completed Iteration #21
Best Reward: 1.4084507042253502
Completed Iteration #22
Best Reward: 1.4084507042253502
Completed Iteration #23
Best Reward: 1.4084507042253502
Completed Iteration #24
Best Reward: 1.4084507042253502
Completed Iteration #25
Best Reward: 1.4084507042253502
Completed MCTS Level/Depth: #8
root->6->8->8->4->8->9->6->27
Best Reward: 1.4084507042253502
iteration: 25
found coverage increase 1.4084507042253502
Current Total Coverage 15.140845070422534
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00449b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00445c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00449b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcbef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bb4b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00449b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00589e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 15.140845070422534
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbfa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0044be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 16
Completed Iteration #15
Best Reward: 0
coverage_call_count 1800
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0088eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a01104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 15.140845070422534
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a01109e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01107b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01107b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01107b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 15.140845070422534
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01456a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a01366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01456a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0058128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 15.140845070422534
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a01459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176128> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 15.140845070422534
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00b3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb70898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbb0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a01100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb4b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c56d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5ac8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 15.140845070422534
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a0110978> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7a90> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.352112676056338 3
Completed Iteration #3
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0069898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.352112676056338 4
Completed Iteration #4
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7a90> 0.352112676056338 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.352112676056338 5
Completed Iteration #5
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.352112676056338 6
Completed Iteration #6
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7a90> 0.352112676056338 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.352112676056338 7
Completed Iteration #7
Best Reward: 0.352112676056338
Completed Iteration #8
Best Reward: 0.352112676056338
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151160> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7a90> 0.704225352112676 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.704225352112676 8
Completed Iteration #9
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.704225352112676 9
Completed Iteration #10
Best Reward: 0.352112676056338
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0176668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 0.704225352112676 10
Completed Iteration #11
Best Reward: 0.352112676056338
Reward: 1.4084507042253538
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2860> 1.4084507042253538 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5d30> 1.4084507042253538 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 2.11267605633803 11
Completed Iteration #12
Best Reward: 1.4084507042253538
Completed Iteration #13
Best Reward: 1.4084507042253538
Completed Iteration #14
Best Reward: 1.4084507042253538
Completed Iteration #15
Best Reward: 1.4084507042253538
Completed Iteration #16
Best Reward: 1.4084507042253538
Completed Iteration #17
Best Reward: 1.4084507042253538
Completed Iteration #18
Best Reward: 1.4084507042253538
Completed Iteration #19
Best Reward: 1.4084507042253538
Completed Iteration #20
Best Reward: 1.4084507042253538
Completed Iteration #21
Best Reward: 1.4084507042253538
Completed Iteration #22
Best Reward: 1.4084507042253538
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5d30> 1.4084507042253538 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 2.11267605633803 12
Completed Iteration #23
Best Reward: 1.4084507042253538
Completed Iteration #24
Best Reward: 1.4084507042253538
Reward: 0.352112676056338
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c470> 0.352112676056338 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f7a90> 1.056338028169014 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 2.464788732394368 13
Completed Iteration #25
Best Reward: 1.4084507042253538
Completed MCTS Level/Depth: #0
root
Best Reward: 1.4084507042253538
Completed Iteration #0
Best Reward: 1.4084507042253538
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5d30> 1.4084507042253538 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 2.464788732394368 14
Completed Iteration #1
Best Reward: 1.4084507042253538
Completed Iteration #2
Best Reward: 1.4084507042253538
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5d30> 1.4084507042253538 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 2.464788732394368 15
Completed Iteration #3
Best Reward: 1.4084507042253538
Completed Iteration #4
Best Reward: 1.4084507042253538
Completed Iteration #5
Best Reward: 1.4084507042253538
Completed Iteration #6
Best Reward: 1.4084507042253538
Completed Iteration #7
Best Reward: 1.4084507042253538
Completed Iteration #8
Best Reward: 1.4084507042253538
Completed Iteration #9
Best Reward: 1.4084507042253538
Completed Iteration #10
Best Reward: 1.4084507042253538
Completed Iteration #11
Best Reward: 1.4084507042253538
Completed Iteration #12
Best Reward: 1.4084507042253538
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5d30> 1.4084507042253538 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 2.464788732394368 16
Completed Iteration #13
Best Reward: 1.4084507042253538
Completed Iteration #14
Best Reward: 1.4084507042253538
Completed Iteration #15
Best Reward: 1.4084507042253538
Completed Iteration #16
Best Reward: 1.4084507042253538
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d80dbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5d30> 1.4084507042253538 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 2.464788732394368 17
Completed Iteration #17
Best Reward: 1.4084507042253538
Completed Iteration #18
Best Reward: 1.4084507042253538
Completed Iteration #19
Best Reward: 1.4084507042253538
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5d30> 1.4084507042253538 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 2.464788732394368 18
Completed Iteration #20
Best Reward: 1.4084507042253538
Completed Iteration #21
Best Reward: 1.4084507042253538
Completed Iteration #22
Best Reward: 1.4084507042253538
Completed Iteration #23
Best Reward: 1.4084507042253538
Completed Iteration #24
Best Reward: 1.4084507042253538
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5d30> 1.4084507042253538 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2278> 2.464788732394368 19
Completed Iteration #25
Best Reward: 1.4084507042253538
Completed MCTS Level/Depth: #1
root->7
Best Reward: 1.4084507042253538
Completed Iteration #0
Best Reward: 1.4084507042253538
Completed Iteration #1
Best Reward: 1.4084507042253538
Completed Iteration #2
Best Reward: 1.4084507042253538
Completed Iteration #3
Best Reward: 1.4084507042253538
Completed Iteration #4
Best Reward: 1.4084507042253538
Completed Iteration #5
Best Reward: 1.4084507042253538
Completed Iteration #6
Best Reward: 1.4084507042253538
Completed Iteration #7
Best Reward: 1.4084507042253538
Completed Iteration #8
Best Reward: 1.4084507042253538
Completed Iteration #9
Best Reward: 1.4084507042253538
Completed Iteration #10
Best Reward: 1.4084507042253538
Completed Iteration #11
Best Reward: 1.4084507042253538
Completed Iteration #12
Best Reward: 1.4084507042253538
Completed Iteration #13
Best Reward: 1.4084507042253538
Completed Iteration #14
Best Reward: 1.4084507042253538
Completed Iteration #15
Best Reward: 1.4084507042253538
Completed Iteration #16
Best Reward: 1.4084507042253538
Completed Iteration #17
Best Reward: 1.4084507042253538
Completed Iteration #18
Best Reward: 1.4084507042253538
Completed Iteration #19
Best Reward: 1.4084507042253538
Completed Iteration #20
Best Reward: 1.4084507042253538
Completed Iteration #21
Best Reward: 1.4084507042253538
Completed Iteration #22
Best Reward: 1.4084507042253538
Completed Iteration #23
Best Reward: 1.4084507042253538
Completed Iteration #24
Best Reward: 1.4084507042253538
Completed Iteration #25
Best Reward: 1.4084507042253538
Completed MCTS Level/Depth: #2
root->7->26
Best Reward: 1.4084507042253538
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 1.4084507042253538
Current Total Coverage 16.549295774647888
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d80db748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fe390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01517f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0136cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a01100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a016b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf6d8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 16.549295774647888
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd10c04a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bbcb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd10c0b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac9e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 16.549295774647888
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a01104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd15297c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd10c04a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0145ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 16.549295774647888
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bb95668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a01108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80fef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd10c04ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01517f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01517f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1acda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bba0550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a0151ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 16.549295774647888
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 6
Completed Iteration #9
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8168ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a00c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80838d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a811a198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 16.549295774647888
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80506a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.3521126760563362 10
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.3521126760563362 11
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.3521126760563362 12
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80505c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.3521126760563362 13
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.3521126760563362 14
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80505c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.3521126760563362 15
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8050198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.3521126760563362 16
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 0.3521126760563362 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.3521126760563362 17
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a806bd30> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4ef0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.7042253521126725 18
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.7042253521126725 19
Completed Iteration #23
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.7042253521126725 20
Completed Iteration #24
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a806bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 0.7042253521126725 21
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b4e0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4ef0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 22
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4ef0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 23
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 24
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 25
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 26
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 27
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 28
Completed Iteration #12
Best Reward: 0.3521126760563362
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd10c0b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 29
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a0129d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 30
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 31
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 32
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.0563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.0563380281690087 33
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a80c1be0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ac1ac208> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806bd30> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4ef0> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.408450704225345 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.408450704225345 34
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4dd8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4ef0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.7605633802816811 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.7605633802816811 35
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 1.7605633802816811 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 1.7605633802816811 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 1.7605633802816811 36
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043780> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 2.1126760563380174 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 2.1126760563380174 37
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2b70> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4710> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 2.4647887323943536 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 2.4647887323943536 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 2.4647887323943536 38
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b198> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bc88> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043780> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 2.81690140845069 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 2.81690140845069 39
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 3.169014084507026 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 3.169014084507026 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 3.169014084507026 40
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733d68> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c45c0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 3.5211267605633623 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 3.5211267605633623 41
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4710> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 3.5211267605633623 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 3.5211267605633623 42
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0ac193710> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a01108d0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b4e0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4ef0> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 3.8732394366196985 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 3.8732394366196985 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 3.8732394366196985 43
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5f98> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a811ac50> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 4.225352112676035 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 4.225352112676035 44
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a8083208> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c45c0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 4.577464788732371 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 4.577464788732371 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 4.577464788732371 45
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0c885c358> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4ef0> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 4.929577464788707 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 4.929577464788707 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 4.929577464788707 46
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #2
root->1->19
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b278> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 1.7605633802816811 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 5.281690140845043 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 5.281690140845043 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 5.281690140845043 47
Completed Iteration #2
Best Reward: 0.3521126760563362
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b518> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 5.63380281690138 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 5.63380281690138 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 5.63380281690138 48
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
coverage_call_count 2200
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bc88> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043780> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 5.63380281690138 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 5.63380281690138 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 5.63380281690138 49
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733390> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb208> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b518> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 2.4647887323943536 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 5.985915492957716 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 5.985915492957716 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 5.985915492957716 50
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b518> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 2.4647887323943536 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 5.985915492957716 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 5.985915492957716 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 5.985915492957716 51
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1be0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b278> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 6.338028169014052 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 6.338028169014052 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 6.338028169014052 52
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f780> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1ba8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b198> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bc88> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8043780> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 3.169014084507026 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 6.690140845070388 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 6.690140845070388 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 6.690140845070388 53
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb048> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 7.0422535211267245 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 7.0422535211267245 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 7.0422535211267245 54
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f048> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f358> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b278> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 3.8732394366196985 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 7.394366197183061 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 7.394366197183061 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 7.394366197183061 55
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2733828> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b278> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 3.8732394366196985 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 7.394366197183061 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 7.394366197183061 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 7.394366197183061 56
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #3
root->1->19->2
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b588> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 7.746478873239397 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 7.746478873239397 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 7.746478873239397 57
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb668> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 4.577464788732371 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 8.098591549295733 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 8.098591549295733 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 8.098591549295733 58
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a277fba8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277ffd0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 1.7605633802816811 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 4.929577464788707 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 8.45070422535207 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 8.45070422535207 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 8.45070422535207 59
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277ffd0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 4.929577464788707 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 8.45070422535207 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 8.45070422535207 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 8.45070422535207 60
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9630> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 5.281690140845043 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 8.802816901408406 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 8.802816901408406 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 8.802816901408406 61
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a279dda0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 2.4647887323943536 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 5.63380281690138 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 9.154929577464742 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 9.154929577464742 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 9.154929577464742 62
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb470> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277ffd0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 5.985915492957716 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 9.507042253521078 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 9.507042253521078 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 9.507042253521078 63
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 5.985915492957716 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 9.507042253521078 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 9.507042253521078 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 9.507042253521078 64
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a806b588> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 2.81690140845069 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 5.985915492957716 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 9.507042253521078 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 9.507042253521078 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 9.507042253521078 65
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 3.169014084507026 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 6.338028169014052 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 9.859154929577414 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 9.859154929577414 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 9.859154929577414 66
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 1.7605633802816811 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 3.169014084507026 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 6.338028169014052 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 9.859154929577414 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 9.859154929577414 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 9.859154929577414 67
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #4
root->1->19->2->18
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 1.7605633802816811 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 3.169014084507026 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 6.338028169014052 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 9.859154929577414 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 9.859154929577414 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 9.859154929577414 68
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d3c8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f828> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb668> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 2.1126760563380174 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 3.5211267605633623 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 6.690140845070388 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 10.21126760563375 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 10.21126760563375 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 10.21126760563375 69
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a279def0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 2.4647887323943536 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 3.8732394366196985 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 7.0422535211267245 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 10.563380281690087 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 10.563380281690087 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 10.563380281690087 70
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebd68> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d90f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9630> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 2.81690140845069 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 4.225352112676035 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 7.394366197183061 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 10.915492957746423 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 10.915492957746423 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 10.915492957746423 71
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a279def0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 2.81690140845069 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 4.225352112676035 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 7.394366197183061 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 10.915492957746423 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 10.915492957746423 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 10.915492957746423 72
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Completed Iteration #12
Best Reward: 0.3521126760563362
Completed Iteration #13
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a80f6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 2.81690140845069 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 4.225352112676035 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 7.394366197183061 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 10.915492957746423 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 10.915492957746423 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 10.915492957746423 73
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9208> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c88> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 3.169014084507026 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 4.577464788732371 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 7.746478873239397 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 11.26760563380276 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 11.26760563380276 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 11.26760563380276 74
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 3.5211267605633623 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 4.929577464788707 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 8.098591549295733 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 11.619718309859095 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 11.619718309859095 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 11.619718309859095 75
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 3.8732394366196985 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 5.281690140845043 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 8.45070422535207 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 11.971830985915432 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 11.971830985915432 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 11.971830985915432 76
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a271aa58> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a277f828> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb668> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 4.225352112676035 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 5.63380281690138 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 8.802816901408406 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 12.323943661971768 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 12.323943661971768 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 12.323943661971768 77
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a80cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d90f0> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9630> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 4.225352112676035 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 5.63380281690138 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 8.802816901408406 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 12.323943661971768 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 12.323943661971768 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 12.323943661971768 78
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #5
root->1->19->2->18->5
Best Reward: 0.3521126760563362
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27477f0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747668> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9208> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c88> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 1.7605633802816811 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 4.577464788732371 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 5.985915492957716 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 9.154929577464742 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 12.676056338028104 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 12.676056338028104 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 12.676056338028104 79
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac88> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 4.929577464788707 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 6.338028169014052 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 9.507042253521078 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 13.02816901408444 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 13.02816901408444 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 13.02816901408444 80
Completed Iteration #9
Best Reward: 0.3521126760563362
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c88> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 4.929577464788707 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 6.338028169014052 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 9.507042253521078 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 13.02816901408444 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 13.02816901408444 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 13.02816901408444 81
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27281d0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 2.4647887323943536 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 5.281690140845043 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 6.690140845070388 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 9.859154929577414 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 13.380281690140777 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 13.380281690140777 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 13.380281690140777 82
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c88> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 2.4647887323943536 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 5.281690140845043 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 6.690140845070388 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 9.859154929577414 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 13.380281690140777 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 13.380281690140777 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 13.380281690140777 83
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27529e8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c88> 1.0563380281690087 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 5.63380281690138 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 7.0422535211267245 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 10.21126760563375 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 13.732394366197113 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 13.732394366197113 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 13.732394366197113 84
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 2.81690140845069 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 5.63380281690138 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 7.0422535211267245 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 10.21126760563375 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 13.732394366197113 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 13.732394366197113 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 13.732394366197113 85
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774470> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9f98> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 3.169014084507026 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 5.985915492957716 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 7.394366197183061 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 10.563380281690087 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 14.084507042253449 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 14.084507042253449 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 14.084507042253449 86
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #6
root->1->19->2->18->5->0
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb160> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 6.338028169014052 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 7.746478873239397 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 10.915492957746423 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 14.436619718309785 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 14.436619718309785 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 14.436619718309785 87
Completed Iteration #0
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747da0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747320> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 3.8732394366196985 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 6.690140845070388 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 8.098591549295733 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 11.26760563380276 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 14.788732394366122 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 14.788732394366122 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 14.788732394366122 88
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a160> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271aeb8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 2.4647887323943536 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 7.0422535211267245 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 8.45070422535207 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 11.619718309859095 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 15.140845070422458 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 15.140845070422458 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 15.140845070422458 89
Completed Iteration #3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774668> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774748> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27eb160> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 4.577464788732371 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 7.394366197183061 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 8.802816901408406 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 11.971830985915432 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 15.492957746478794 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 15.492957746478794 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 15.492957746478794 90
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27479e8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 3.169014084507026 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 4.929577464788707 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 7.746478873239397 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 9.154929577464742 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 12.323943661971768 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 15.84507042253513 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 15.84507042253513 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 15.84507042253513 91
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728438> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747320> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752748> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 5.281690140845043 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 8.098591549295733 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 9.507042253521078 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 12.676056338028104 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 16.197183098591466 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 16.197183098591466 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 16.197183098591466 92
Completed Iteration #7
Best Reward: 0.3521126760563362
coverage_call_count 2300
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767ef0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c18> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 3.8732394366196985 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 5.63380281690138 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 8.45070422535207 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 9.859154929577414 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 13.02816901408444 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 16.549295774647803 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 16.549295774647803 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 16.549295774647803 93
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767ac8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 4.225352112676035 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 5.985915492957716 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 8.802816901408406 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 10.21126760563375 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 13.380281690140777 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 16.90140845070414 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 16.90140845070414 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 16.90140845070414 94
Completed Iteration #10
Best Reward: 0.3521126760563362
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff9b0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffd68> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767ac8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 4.577464788732371 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 6.338028169014052 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 9.154929577464742 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 10.563380281690087 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 13.732394366197113 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 17.253521126760475 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 17.253521126760475 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 17.253521126760475 95
Completed Iteration #12
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9470> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 4.929577464788707 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 6.690140845070388 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 9.507042253521078 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 10.915492957746423 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 14.084507042253449 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 17.60563380281681 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 17.60563380281681 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 17.60563380281681 96
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9470> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 4.929577464788707 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 6.690140845070388 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 9.507042253521078 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 10.915492957746423 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 14.084507042253449 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 17.60563380281681 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 17.60563380281681 82
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 17.60563380281681 97
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Completed Iteration #18
Best Reward: 0.3521126760563362
Completed Iteration #19
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767908> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 5.281690140845043 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 7.0422535211267245 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 9.859154929577414 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 11.26760563380276 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 14.436619718309785 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 17.957746478873148 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 17.957746478873148 83
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 17.957746478873148 98
Completed Iteration #20
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a271aac8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 5.63380281690138 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 7.394366197183061 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 10.21126760563375 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 11.619718309859095 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 14.788732394366122 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 18.309859154929484 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 18.309859154929484 84
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 18.309859154929484 99
Completed Iteration #21
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767a58> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d1588> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ac88> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 5.985915492957716 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 7.746478873239397 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 10.563380281690087 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 11.971830985915432 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 15.140845070422458 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 18.66197183098582 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 18.66197183098582 85
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 18.66197183098582 100
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #7
root->1->19->2->18->5->0->3
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff278> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffa20> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767ef0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c18> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 6.338028169014052 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 8.098591549295733 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 10.915492957746423 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 12.323943661971768 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 15.492957746478794 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 19.014084507042156 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 19.014084507042156 86
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 19.014084507042156 101
Completed Iteration #0
Best Reward: 0.3521126760563362
Completed Iteration #1
Best Reward: 0.3521126760563362
Completed Iteration #2
Best Reward: 0.3521126760563362
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff278> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffa20> 0.3521126760563362 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767ef0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c18> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 6.338028169014052 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 8.098591549295733 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 10.915492957746423 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 12.323943661971768 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 15.492957746478794 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 19.014084507042156 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 19.014084507042156 87
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 19.014084507042156 102
Completed Iteration #3
Best Reward: 0.3521126760563362
Completed Iteration #4
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66cc0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c18> 1.0563380281690087 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 6.690140845070388 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 8.45070422535207 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 11.26760563380276 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 12.676056338028104 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 15.84507042253513 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 19.366197183098492 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 19.366197183098492 88
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 19.366197183098492 103
Completed Iteration #5
Best Reward: 0.3521126760563362
Completed Iteration #6
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752f28> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ab00> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 7.0422535211267245 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 8.802816901408406 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 11.619718309859095 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 13.02816901408444 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 16.197183098591466 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 19.71830985915483 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 19.71830985915483 89
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 19.71830985915483 104
Completed Iteration #7
Best Reward: 0.3521126760563362
Completed Iteration #8
Best Reward: 0.3521126760563362
Completed Iteration #9
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d19b0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c18> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 2.4647887323943536 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 7.394366197183061 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 9.154929577464742 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 11.971830985915432 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 13.380281690140777 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 16.549295774647803 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 20.070422535211165 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 20.070422535211165 90
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 20.070422535211165 105
Completed Iteration #10
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767cc0> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ab00> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 7.746478873239397 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 9.507042253521078 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 12.323943661971768 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 13.732394366197113 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 16.90140845070414 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 20.4225352112675 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 20.4225352112675 91
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 20.4225352112675 106
Completed Iteration #11
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66898> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26fff28> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752f28> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a271ab00> 1.0563380281690087 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 3.169014084507026 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 8.098591549295733 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 9.859154929577414 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 12.676056338028104 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 14.084507042253449 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 17.253521126760475 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 20.774647887323837 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 20.774647887323837 92
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 20.774647887323837 107
Completed Iteration #12
Best Reward: 0.3521126760563362
Completed Iteration #13
Best Reward: 0.3521126760563362
Completed Iteration #14
Best Reward: 0.3521126760563362
Completed Iteration #15
Best Reward: 0.3521126760563362
Completed Iteration #16
Best Reward: 0.3521126760563362
Completed Iteration #17
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff390> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c18> 1.7605633802816811 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 8.45070422535207 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 10.21126760563375 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 13.02816901408444 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 14.436619718309785 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 17.60563380281681 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 21.126760563380174 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 21.126760563380174 93
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 21.126760563380174 108
Completed Iteration #18
Best Reward: 0.3521126760563362
Reward: 0.3521126760563362
backprop <src.mcts.MCTS_Node object at 0x7fd0a279d6d8> 0.3521126760563362 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752c18> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a27524e0> 3.8732394366196985 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752128> 8.802816901408406 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747a20> 10.563380281690087 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a815b908> 13.380281690140777 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a815bb00> 14.788732394366122 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a80436a0> 17.957746478873148 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c40f0> 21.47887323943651 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a27c4358> 21.47887323943651 94
backprop <src.mcts.MCTS_Node object at 0x7fd0a80a8630> 21.47887323943651 109
Completed Iteration #19
Best Reward: 0.3521126760563362
Completed Iteration #20
Best Reward: 0.3521126760563362
Completed Iteration #21
Best Reward: 0.3521126760563362
Completed Iteration #22
Best Reward: 0.3521126760563362
Completed Iteration #23
Best Reward: 0.3521126760563362
Completed Iteration #24
Best Reward: 0.3521126760563362
Completed Iteration #25
Best Reward: 0.3521126760563362
Completed MCTS Level/Depth: #8
root->1->19->2->18->5->0->3->1
Best Reward: 0.3521126760563362
iteration: 38
found coverage increase 0.3521126760563362
Current Total Coverage 16.901408450704224
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba372e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba454e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a279df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27746a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a271a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba454e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba454e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27746a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 16.901408450704224
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba458d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27676a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 16.901408450704224
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 2400
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2767898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2f828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 16.901408450704224
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06acae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06acae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06acae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b596198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06b596358> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 14
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca19e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 15
Completed Iteration #17
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 16
Completed Iteration #18
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 17
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba1ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 18
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 19
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aca15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 20
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 21
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 22
Completed Iteration #8
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 23
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b596358> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 24
Completed Iteration #10
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 25
Completed Iteration #11
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 26
Completed Iteration #12
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b596080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 27
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 28
Completed Iteration #15
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 29
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 30
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 31
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.3521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.3521126760563398 32
Completed Iteration #23
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.7042253521126796 19
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.7042253521126796 33
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.3521126760563398
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Completed Iteration #4
Best Reward: 0.3521126760563398
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06acae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 0.7042253521126796 20
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 0.7042253521126796 34
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 1.0563380281690193 21
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 1.0563380281690193 35
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06ac5a550> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.0563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 1.4084507042253591 22
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 1.4084507042253591 36
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #2
root->8->7
Best Reward: 0.3521126760563398
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.0563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 1.4084507042253591 23
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 1.4084507042253591 37
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Completed Iteration #4
Best Reward: 0.3521126760563398
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.0563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 1.4084507042253591 24
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 1.4084507042253591 38
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
coverage_call_count 2500
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 0.7042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.0563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 1.4084507042253591 25
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 1.4084507042253591 39
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06acae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 0.7042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.0563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 1.4084507042253591 26
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 1.4084507042253591 40
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06ac5a4a8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 1.0563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.4084507042253591 10
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 1.760563380281699 27
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 1.760563380281699 41
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06ac5a9e8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 1.4084507042253591 9
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 2.1126760563380387 28
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 2.1126760563380387 42
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ac7e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac7e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac5a4a8> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 1.4084507042253591 10
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 2.1126760563380387 29
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 2.1126760563380387 43
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ac7ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac7ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac5a9e8> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 1.4084507042253591 11
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 2.1126760563380387 30
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 2.1126760563380387 44
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #3
root->8->7->8
Best Reward: 0.3521126760563398
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac7e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 1.4084507042253591 12
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 1.760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 2.1126760563380387 31
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 2.1126760563380387 45
Completed Iteration #4
Best Reward: 0.3521126760563398
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18358> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 1.760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 2.1126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 2.4647887323943785 32
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 2.4647887323943785 46
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #4
root->8->7->8->7
Best Reward: 0.3521126760563398
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Completed Iteration #2
Best Reward: 0.3521126760563398
Completed Iteration #3
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba37160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 1.760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 2.1126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 2.4647887323943785 33
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 2.4647887323943785 47
Completed Iteration #4
Best Reward: 0.3521126760563398
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ac5a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 0.3521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 0.7042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 1.760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 2.1126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 2.4647887323943785 34
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 2.4647887323943785 48
Completed Iteration #7
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 1.0563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 2.1126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 2.4647887323943785 18
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 2.8169014084507182 35
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 2.8169014084507182 49
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba2fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18358> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 0.7042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 1.0563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 2.1126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 2.4647887323943785 19
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 2.8169014084507182 36
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 2.8169014084507182 50
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06ac7ee48> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.0563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 1.4084507042253591 9
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 2.4647887323943785 18
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 2.8169014084507182 20
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.169014084507058 37
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.169014084507058 51
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ac024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac5a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.0563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 1.4084507042253591 10
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 2.4647887323943785 19
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 2.8169014084507182 21
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.169014084507058 38
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.169014084507058 52
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #5
root->8->7->8->7->8
Best Reward: 0.3521126760563398
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Completed Iteration #2
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06acaee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06acae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.0563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 1.4084507042253591 11
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 2.4647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 2.8169014084507182 22
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.169014084507058 39
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.169014084507058 53
Completed Iteration #3
Best Reward: 0.3521126760563398
Completed Iteration #4
Best Reward: 0.3521126760563398
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66198> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 0.7042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.4084507042253591 10
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 1.760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 2.8169014084507182 21
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.169014084507058 23
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.521126760563398 40
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.521126760563398 54
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.4084507042253591 11
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 1.760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 2.8169014084507182 22
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.521126760563398 41
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.521126760563398 55
Completed Iteration #10
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.3521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 0.7042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.4084507042253591 12
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 1.760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 2.8169014084507182 23
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.169014084507058 25
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.521126760563398 42
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.521126760563398 56
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd06ac7ed30> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.7042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.0563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.1126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.521126760563398 26
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.8732394366197376 43
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.8732394366197376 57
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ac5a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.7042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.0563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.1126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.169014084507058 25
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.521126760563398 27
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.8732394366197376 44
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.8732394366197376 58
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #6
root->8->7->8->7->8->3
Best Reward: 0.3521126760563398
Completed Iteration #0
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.7042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.0563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.1126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.169014084507058 26
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.521126760563398 28
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.8732394366197376 45
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.8732394366197376 59
Completed Iteration #1
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.7042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.0563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.1126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.169014084507058 27
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.521126760563398 29
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.8732394366197376 46
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.8732394366197376 60
Completed Iteration #2
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.7042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.0563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.1126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.169014084507058 28
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.521126760563398 30
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.8732394366197376 47
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.8732394366197376 61
Completed Iteration #3
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.7042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.0563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.1126760563380387 20
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.169014084507058 29
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.521126760563398 31
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.8732394366197376 48
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.8732394366197376 62
Completed Iteration #4
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba72f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 0.7042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.0563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 1.760563380281699 19
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.1126760563380387 21
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.169014084507058 30
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.521126760563398 32
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 3.8732394366197376 49
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 3.8732394366197376 63
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27679e8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 1.0563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.4084507042253591 14
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 2.1126760563380387 20
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.4647887323943785 22
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.521126760563398 31
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.8732394366197376 33
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 4.225352112676077 50
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 4.225352112676077 64
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Completed Iteration #13
Best Reward: 0.3521126760563398
coverage_call_count 2600
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a271acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 1.0563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.4084507042253591 15
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 2.1126760563380387 21
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.4647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.521126760563398 32
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.8732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 4.225352112676077 51
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 4.225352112676077 65
Completed Iteration #16
Best Reward: 0.3521126760563398
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ac7e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 1.0563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.4084507042253591 16
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 2.1126760563380387 22
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.4647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.521126760563398 33
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.8732394366197376 35
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 4.225352112676077 52
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 4.225352112676077 66
Completed Iteration #23
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ba45588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06acae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66198> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 1.0563380281690193 15
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.4084507042253591 17
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 2.1126760563380387 23
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.4647887323943785 25
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.521126760563398 34
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 3.8732394366197376 36
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 4.225352112676077 53
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 4.225352112676077 67
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #7
root->8->7->8->7->8->3->0
Best Reward: 0.3521126760563398
Completed Iteration #0
Best Reward: 0.3521126760563398
Completed Iteration #1
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2728a20> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff320> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27679e8> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 1.4084507042253591 16
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 1.760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 2.4647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 2.8169014084507182 26
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 3.8732394366197376 35
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 4.225352112676077 37
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 4.577464788732417 54
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 4.577464788732417 68
Completed Iteration #2
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2774e48> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff320> 0.7042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a27679e8> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 1.760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 2.1126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 2.8169014084507182 25
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 3.169014084507058 27
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 4.225352112676077 36
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 4.577464788732417 38
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 4.929577464788757 55
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 4.929577464788757 69
Completed Iteration #3
Best Reward: 0.3521126760563398
Completed Iteration #4
Best Reward: 0.3521126760563398
Completed Iteration #5
Best Reward: 0.3521126760563398
Completed Iteration #6
Best Reward: 0.3521126760563398
Completed Iteration #7
Best Reward: 0.3521126760563398
Completed Iteration #8
Best Reward: 0.3521126760563398
Completed Iteration #9
Best Reward: 0.3521126760563398
Completed Iteration #10
Best Reward: 0.3521126760563398
Completed Iteration #11
Best Reward: 0.3521126760563398
Completed Iteration #12
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a90> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff320> 1.0563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a27679e8> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 2.1126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 2.4647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 3.169014084507058 26
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 3.521126760563398 28
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 4.577464788732417 37
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 4.929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 5.281690140845097 56
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 5.281690140845097 70
Completed Iteration #13
Best Reward: 0.3521126760563398
Completed Iteration #14
Best Reward: 0.3521126760563398
Completed Iteration #15
Best Reward: 0.3521126760563398
Completed Iteration #16
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a2752a20> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff320> 1.4084507042253591 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a27679e8> 1.760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 2.4647887323943785 19
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 2.8169014084507182 21
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 3.521126760563398 27
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 3.8732394366197376 29
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 4.929577464788757 38
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 5.281690140845097 40
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 5.6338028169014365 57
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 5.6338028169014365 71
Completed Iteration #17
Best Reward: 0.3521126760563398
Completed Iteration #18
Best Reward: 0.3521126760563398
Completed Iteration #19
Best Reward: 0.3521126760563398
Completed Iteration #20
Best Reward: 0.3521126760563398
Completed Iteration #21
Best Reward: 0.3521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a27470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a2747518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a27d9a90> 0.3521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff320> 1.4084507042253591 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a27679e8> 1.760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 2.4647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 2.8169014084507182 22
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 3.521126760563398 28
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 3.8732394366197376 30
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 4.929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 5.281690140845097 41
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 5.6338028169014365 58
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 5.6338028169014365 72
Completed Iteration #22
Best Reward: 0.3521126760563398
Reward: 0.3521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fd0a27522e8> 0.3521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a26ff320> 1.760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a27679e8> 2.1126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7fd06ac02b70> 2.8169014084507182 21
backprop <src.mcts.MCTS_Node object at 0x7fd06b596b00> 3.169014084507058 23
backprop <src.mcts.MCTS_Node object at 0x7fd06ac18128> 3.8732394366197376 29
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51a58> 4.225352112676077 31
backprop <src.mcts.MCTS_Node object at 0x7fd06ac51ac8> 5.281690140845097 40
backprop <src.mcts.MCTS_Node object at 0x7fd06ba66c88> 5.6338028169014365 42
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1da0> 5.985915492957776 59
backprop <src.mcts.MCTS_Node object at 0x7fd06aca1048> 5.985915492957776 73
Completed Iteration #23
Best Reward: 0.3521126760563398
Completed Iteration #24
Best Reward: 0.3521126760563398
Completed Iteration #25
Best Reward: 0.3521126760563398
Completed MCTS Level/Depth: #8
root->8->7->8->7->8->3->0->0
Best Reward: 0.3521126760563398
iteration: 42
found coverage increase 0.3521126760563398
Current Total Coverage 17.253521126760564
initial coverage: 9.50704
time passed (minutes): 62.2783
iterations: 43
number of new inputs: 576
final coverage: 17.2535
total coverage increase: 7.74648
