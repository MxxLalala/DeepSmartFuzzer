Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f2d1d3b6f28>, tc2=<function tc2 at 0x7f2d1d3c7048>, tc3=<function tc3 at 0x7f2d1d3c7158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 13.3803
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907002e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90785550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906856a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906989b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906989b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906989b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906987f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906987f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906987f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ebe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a72e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c881a75f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9076add8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881659e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881659e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881659e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eb00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e8d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880920f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880929e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ff28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 10
Completed Iteration #17
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e10> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880467b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880469e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880469e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880467b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d354867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d3548c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c980797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb8d0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9801ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9801f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880920f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880920f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce957c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 600
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce957c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880920f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c880922b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9801f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d3548c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb8b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 21
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90785908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906cef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 700
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90785a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907009b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c980797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb8d0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a76a0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90785898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d3548c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb9708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98065c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce957cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906858d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906858d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95eea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c98026f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c98026978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881650f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce957c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881652e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88185908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881650f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881650f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881650f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881652e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88185128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907005c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906986d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce957cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb9708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88059828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c88059438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 1000
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880596a0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c980267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480902b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c980267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce957cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480666a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480666d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480666d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e518> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1270f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1270f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0996d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b2e8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c34a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c34a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0145c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0995c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0995c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0995c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0995c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0995c0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c480661d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127daa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127daf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 1600
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb9708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b3c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98065b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c980260b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98009f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98009fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d354869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4da0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906cecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98009fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c980265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480904a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88165a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880920f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880920f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880920f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880920f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880920f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880925f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88092be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880925f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d354869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2d35486eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480662e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480662e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0990f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c48066518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d354869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e6a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0994e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0994e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90785898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099780> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480812e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b38> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0239b0> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 13.380281690140844
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817efd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0141d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1755c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1270f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0145f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1270f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1270f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880925f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0686d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113182e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eeb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113330b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11318128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068c88> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112867b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112866a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f93c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112866a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113181d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113181d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 2500
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9b38> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 5
Completed Iteration #11
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 11
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 12
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de50f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da35f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f1d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d484e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d106a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 2800
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c048> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0846a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0846a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1272e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1757f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90785898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880591d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d354869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014048> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 2900
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0145f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0148d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0148d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ee80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c113336d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113330f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0849e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881650f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881650f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 22
Completed Iteration #24
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88046f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113335c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881657b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113335c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881657b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881655f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c980268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881858d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881858d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb9708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881856d8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880463c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881657b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d109e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c113185f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a60b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e48> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c1759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13de48> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f588> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de58d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9c88> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48908> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 3600
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c11286390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104776a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ccf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104776a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104776a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ca90> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104214a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104214a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10414c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104142e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104218d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4390> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104213c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd44a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf466a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf559e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf466a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf468d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf558d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf558d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf467f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf674e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf674e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf675f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf674e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 13.380281690140844
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf264e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf264e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf364e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf364e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf363c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf363c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf364e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf364e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf364e0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf364e0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf368d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf555f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf267b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf267b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf555f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf677f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0becaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0becaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be819b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81518> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be817b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be817b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a8d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd68> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be813c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be813c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be813c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be813c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be813c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 4200
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccd68> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104216a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104216a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104216a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc3c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104147f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104147f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104147f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da33c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906f4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 4300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ce95ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c13d2e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c104145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8817ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1127ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11286be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4f98> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120da20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127dacc0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d8f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127daa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127dac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c084978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9e48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10414ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127da710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10421278> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 4500
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4803b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c14c048> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4803ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c068198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10414da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90685eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133ff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb9708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90685240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10da36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88185c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb8d0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9076a358> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90700358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88165438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 13
Completed Iteration #11
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48090b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c980797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88185630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90700400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907f56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c880a46d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9066e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11286b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c175f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88046198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c8810e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cb198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1133fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9065fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881b66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c90698c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c023a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90785898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10da36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c127ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2d35486b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2ceb954198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90785898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48081400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c90698c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88059908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dc40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b748> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9076ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c980267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c0c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9077d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c4809e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c10bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c112e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c480c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1120ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11318a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127da550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d103c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48081828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c11333080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c1133f4e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113332e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88059828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88092a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c113337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c1120d438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c88046978> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfd45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c88165390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1127cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c15b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9320> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9072eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46518> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9065f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10de57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10421898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c11d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10dd30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be81278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c099f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c98026cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c48066400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46630> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c112a6a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ee10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fbe0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c104774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11333320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c3c014630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d634a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c48066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca2b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c127e90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c11318f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf554a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c1126fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c127e90f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf262e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf262e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26c18> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb278> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c9071bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d10470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0becadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0becadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10db4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c881a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 18
Completed Iteration #19
Best Reward: 0
coverage_call_count 5100
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d3cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0ba8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf269e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3b048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b42b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b42b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ca90> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be2eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be3bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be8fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f7c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c10477470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c906b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf55c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c98026438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c907bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10d2d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0546a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c127e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0becae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bffd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0beca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0546a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b9f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfb09e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf67550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bea1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be5c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054e10> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 9
Completed Iteration #14
Best Reward: 0
coverage_call_count 5300
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b054550> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0615c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10477470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf0d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c10de5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0042e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0042e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abcc4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bbe0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab477b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab478d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab477b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab477b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab477b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0544a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0544a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abccb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b4e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 5500
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab779b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0612e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab039b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab776a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab032b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab772e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab032b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab032b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1f208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1feb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c880b4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b03b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab305c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab307f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47278> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf62b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0be7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf62b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b09dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ababfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bfeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abab240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa891d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab1fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47630> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab03908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0bf26390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaafd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b004550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30d30> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0abe7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab309b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa342e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa344a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa342e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab77400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa340f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa340f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa34f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aadf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab47ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab9d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa44438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa21748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa6b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0b0545c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30ef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0b06ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa215f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa89668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa345f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaaf278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aaf6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0aa345f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab30eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5c8e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5b34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0ab8b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2c0a5d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2c0a591e48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 13.380281690140844
initial coverage: 13.3803
time passed (minutes): 60.3205
iterations: 231
number of new inputs: 0
final coverage: 13.3803
total coverage increase: 0
