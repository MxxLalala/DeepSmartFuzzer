Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='snac', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'snac'], random_seed=None, runner='mcts', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7f297b9f4f28>, tc2=<function tc2 at 0x7f297ba05048>, tc3=<function tc3 at 0x7f297ba05158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 6.25
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 6.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29040dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29040ddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f29040ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29040ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f29040ddd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a017f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a197b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a190f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2904157390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a197b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a190f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 6.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a193c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2940089278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 6.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 2.083333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 2.083333333333332 18
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #0
root
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 2.083333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 2.083333333333332 19
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 2.083333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 2.083333333333332 20
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 4.166666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 4.166666666666664 21
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1813c8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181390> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 6.2499999999999964 10
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 6.2499999999999964 22
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1813c8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181390> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 6.2499999999999964 11
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 6.2499999999999964 23
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4dd8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181390> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 8.333333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 8.333333333333329 12
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 8.333333333333329 24
Completed Iteration #11
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 8.333333333333329 13
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 8.333333333333329 25
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c171f98> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1713c8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4dd8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181390> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 8.333333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 10.41666666666666 14
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 10.41666666666666 26
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4dd8> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181390> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 8.333333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 8.333333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 10.41666666666666 9
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 10.41666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 10.41666666666666 27
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 8.333333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 10.41666666666666 10
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 10.41666666666666 16
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 10.41666666666666 28
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1813c8> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181390> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 8.333333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 8.333333333333329 10
backprop <src.mcts.MCTS_Node object at 0x7f289c1712b0> 10.41666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 10.41666666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 10.41666666666666 29
Completed Iteration #19
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c118470> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 12.499999999999993 18
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 12.499999999999993 30
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 14.583333333333325 19
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 14.583333333333325 31
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #1
root->6
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 14.583333333333325 20
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 14.583333333333325 32
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c124710> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118588> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 16.666666666666657 21
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 16.666666666666657 33
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124710> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c118588> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 16.666666666666657 22
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 16.666666666666657 34
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118588> 2.083333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 4.166666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 16.666666666666657 23
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 16.666666666666657 35
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 18.74999999999999 24
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 18.74999999999999 36
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4080> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01cf8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 8.333333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 20.83333333333332 25
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 20.83333333333332 37
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1b62b0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6a90> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4080> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01cf8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 10.41666666666666 9
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 22.916666666666654 26
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 22.916666666666654 38
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 12.499999999999993 10
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 24.999999999999986 27
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 24.999999999999986 39
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c118128> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 14.583333333333325 11
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 27.083333333333318 28
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 27.083333333333318 40
Completed Iteration #11
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c15eb00> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01cf8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 16.666666666666657 12
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 29.16666666666665 29
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 29.16666666666665 41
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124710> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f289c118588> 2.083333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 16.666666666666657 13
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 29.16666666666665 30
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 29.16666666666665 42
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118128> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 12.499999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 16.666666666666657 14
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 29.16666666666665 31
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 29.16666666666665 43
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 14.583333333333325 9
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 18.74999999999999 15
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 31.249999999999982 32
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 31.249999999999982 44
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6c88> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 16.666666666666657 10
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 20.83333333333332 16
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 33.333333333333314 33
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 33.333333333333314 45
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c181c88> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a58> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6c88> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 18.74999999999999 11
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 22.916666666666654 17
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 35.41666666666664 34
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 35.41666666666664 46
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1245c0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124780> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4080> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01cf8> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 20.83333333333332 12
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 24.999999999999986 18
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 37.49999999999997 35
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 37.49999999999997 47
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c124ba8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181358> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c118128> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 10.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 22.916666666666654 13
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 27.083333333333318 19
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 39.5833333333333 36
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 39.5833333333333 48
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1245c0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c124780> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4080> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01cf8> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 10.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 22.916666666666654 14
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 27.083333333333318 20
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 39.5833333333333 37
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 39.5833333333333 49
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #2
root->6->17
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c171748> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181358> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c118128> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 10.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 12.499999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 24.999999999999986 15
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 29.16666666666665 21
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 41.66666666666663 38
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 41.66666666666663 50
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181c88> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a58> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6c88> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 24.999999999999986 16
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 29.16666666666665 22
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 41.66666666666663 39
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 41.66666666666663 51
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c118a90> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a018d0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 27.083333333333318 17
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 31.249999999999982 23
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 43.74999999999996 40
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 43.74999999999996 52
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c124470> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124198> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118a90> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a018d0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 29.16666666666665 18
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 33.333333333333314 24
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 45.833333333333286 41
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 45.833333333333286 53
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c118780> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124b70> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171748> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181358> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c118128> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 31.249999999999982 19
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 35.41666666666664 25
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 47.916666666666615 42
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 47.916666666666615 54
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab70> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea160> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 12.499999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 33.333333333333314 20
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 37.49999999999997 26
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 49.99999999999994 43
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 49.99999999999994 55
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c13aeb8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 16.666666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 35.41666666666664 21
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 39.5833333333333 27
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 52.08333333333327 44
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 52.08333333333327 56
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c13a9e8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1492e8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13aeb8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 16.666666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 18.74999999999999 12
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 37.49999999999997 22
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 41.66666666666663 28
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 54.1666666666666 45
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 54.1666666666666 57
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1495f8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4438> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab70> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea160> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 14.583333333333325 9
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 39.5833333333333 23
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 43.74999999999996 29
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 56.24999999999993 46
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 56.24999999999993 58
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a018d0> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 39.5833333333333 24
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 43.74999999999996 30
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 56.24999999999993 47
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 56.24999999999993 59
Completed Iteration #21
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b38> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 39.5833333333333 25
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 43.74999999999996 31
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 56.24999999999993 48
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 56.24999999999993 60
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c118160> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 41.66666666666663 26
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 45.833333333333286 32
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 58.33333333333326 49
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 58.33333333333326 61
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #3
root->6->17->3
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124ba8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181358> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7f289c118128> 8.333333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 16.666666666666657 12
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 18.74999999999999 13
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 41.66666666666663 27
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 45.833333333333286 33
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 58.33333333333326 50
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 58.33333333333326 62
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c13af28> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1184e0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 20.83333333333332 14
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 43.74999999999996 28
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 47.916666666666615 34
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 60.416666666666586 51
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 60.416666666666586 63
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13aeb8> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 16.666666666666657 13
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 20.83333333333332 15
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 43.74999999999996 29
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 47.916666666666615 35
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 60.416666666666586 52
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 60.416666666666586 64
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0d45f8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4390> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13af28> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1184e0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 22.916666666666654 16
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 45.833333333333286 30
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 49.99999999999994 36
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 62.499999999999915 53
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 62.499999999999915 65
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4c18> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4c88> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124ba8> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181358> 8.333333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f289c118128> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 18.74999999999999 14
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 24.999999999999986 17
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 47.916666666666615 31
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 52.08333333333327 37
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 64.58333333333324 54
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 64.58333333333324 66
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 20.83333333333332 15
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 27.083333333333318 18
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 49.99999999999994 32
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 54.1666666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 66.66666666666657 55
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 66.66666666666657 67
Completed Iteration #15
Best Reward: 2.083333333333332
coverage_call_count 200
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a9e8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1492e8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c13aeb8> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 20.83333333333332 16
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 27.083333333333318 19
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 49.99999999999994 33
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 54.1666666666666 39
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 66.66666666666657 56
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 66.66666666666657 68
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1184e0> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 27.083333333333318 20
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 49.99999999999994 34
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 54.1666666666666 40
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 66.66666666666657 57
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 66.66666666666657 69
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1184e0> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 27.083333333333318 21
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 49.99999999999994 35
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 54.1666666666666 41
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 66.66666666666657 58
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 66.66666666666657 70
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 22.916666666666654 17
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 29.16666666666665 22
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 52.08333333333327 36
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 56.24999999999993 42
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 68.7499999999999 59
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 68.7499999999999 71
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #4
root->6->17->3->0
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a58> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6c88> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 22.916666666666654 18
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 29.16666666666665 23
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 52.08333333333327 37
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 56.24999999999993 43
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 68.7499999999999 60
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 68.7499999999999 72
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4320> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1492e8> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c13aeb8> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 24.999999999999986 19
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 31.249999999999982 24
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 54.1666666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 58.33333333333326 44
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 70.83333333333323 61
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 70.83333333333323 73
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0f34a8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 27.083333333333318 20
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 33.333333333333314 25
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 56.24999999999993 39
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 60.416666666666586 45
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 72.91666666666656 62
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 72.91666666666656 74
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0f36d8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 29.16666666666665 21
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 35.41666666666664 26
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 58.33333333333326 40
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 62.499999999999915 46
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 74.99999999999989 63
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 74.99999999999989 75
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c149f60> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4c88> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c124ba8> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c181358> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f289c118128> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 31.249999999999982 22
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 37.49999999999997 27
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 60.416666666666586 41
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 64.58333333333324 47
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 77.08333333333321 64
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 77.08333333333321 76
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19fd0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4d30> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a9e8> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1492e8> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c13aeb8> 8.333333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 33.333333333333314 23
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 39.5833333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 62.499999999999915 42
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 66.66666666666657 48
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 79.16666666666654 65
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 79.16666666666654 77
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 33.333333333333314 24
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 39.5833333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 62.499999999999915 43
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 66.66666666666657 49
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 79.16666666666654 66
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 79.16666666666654 78
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa860> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa710> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a9e8> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1492e8> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f289c13aeb8> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 35.41666666666664 25
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 41.66666666666663 30
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 64.58333333333324 44
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 68.7499999999999 50
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 81.24999999999987 67
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 81.24999999999987 79
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c094518> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181358> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f289c118128> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 37.49999999999997 26
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 43.74999999999996 31
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 66.66666666666657 45
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 70.83333333333323 51
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 83.3333333333332 68
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 83.3333333333332 80
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3f28> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa550> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4320> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1492e8> 10.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f289c13aeb8> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 39.5833333333333 27
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 45.833333333333286 32
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 68.7499999999999 46
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 72.91666666666656 52
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 85.41666666666653 69
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 85.41666666666653 81
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa400> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa550> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4320> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1492e8> 12.499999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f289c13aeb8> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 41.66666666666663 28
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 47.916666666666615 33
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 70.83333333333323 47
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 74.99999999999989 53
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 87.49999999999986 70
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 87.49999999999986 82
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #5
root->6->17->3->0->3
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0d46d8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a080> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f34a8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 43.74999999999996 29
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 49.99999999999994 34
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 72.91666666666656 48
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 77.08333333333321 54
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 89.58333333333319 71
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 89.58333333333319 83
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d46d8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c13a080> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f34a8> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 10.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 43.74999999999996 30
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 49.99999999999994 35
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 72.91666666666656 49
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 77.08333333333321 55
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 89.58333333333319 72
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 89.58333333333319 84
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 8.333333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 43.74999999999996 31
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 49.99999999999994 36
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 72.91666666666656 50
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 77.08333333333321 56
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 89.58333333333319 73
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 89.58333333333319 85
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0ac8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0b38> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d46d8> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c13a080> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f34a8> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 45.833333333333286 32
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 52.08333333333327 37
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 74.99999999999989 51
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 79.16666666666654 57
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 91.66666666666652 74
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 91.66666666666652 86
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0b50f0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a080> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0f34a8> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 47.916666666666615 33
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 54.1666666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 77.08333333333321 52
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 81.24999999999987 58
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 93.74999999999984 75
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 93.74999999999984 87
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0b55f8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5438> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b50f0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c13a080> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f289c0f34a8> 10.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 16.666666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 49.99999999999994 34
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 56.24999999999993 39
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 79.16666666666654 53
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 83.3333333333332 59
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 95.83333333333317 76
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 95.83333333333317 88
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c1185f8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094828> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f36d8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 16.666666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 18.74999999999999 12
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 52.08333333333327 35
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 58.33333333333326 40
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 81.24999999999987 54
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 85.41666666666653 60
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 97.9166666666665 77
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 97.9166666666665 89
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c094358> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f31d0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1185f8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094828> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f36d8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 18.74999999999999 12
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 20.83333333333332 13
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 54.1666666666666 36
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 60.416666666666586 41
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 83.3333333333332 55
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 87.49999999999986 61
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 99.99999999999983 78
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 99.99999999999983 90
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 18.74999999999999 13
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 20.83333333333332 14
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 54.1666666666666 37
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 60.416666666666586 42
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 83.3333333333332 56
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 87.49999999999986 62
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 99.99999999999983 79
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 99.99999999999983 91
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #6
root->6->17->3->0->3->13
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0b51d0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0e80> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f34a8> 12.499999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 20.83333333333332 14
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 22.916666666666654 15
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 56.24999999999993 38
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 62.499999999999915 43
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 85.41666666666653 57
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 89.58333333333319 63
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 102.08333333333316 80
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 102.08333333333316 92
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c094320> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 22.916666666666654 15
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 24.999999999999986 16
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 58.33333333333326 39
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 64.58333333333324 44
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 87.49999999999986 58
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 91.66666666666652 64
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 104.16666666666649 81
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 104.16666666666649 93
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 22.916666666666654 16
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 24.999999999999986 17
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 58.33333333333326 40
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 64.58333333333324 45
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 87.49999999999986 59
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 91.66666666666652 65
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 104.16666666666649 82
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 104.16666666666649 94
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca4a8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 24.999999999999986 17
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 27.083333333333318 18
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 60.416666666666586 41
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 66.66666666666657 46
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 89.58333333333319 60
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 93.74999999999984 66
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 106.24999999999982 83
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 106.24999999999982 95
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca860> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094828> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f36d8> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 27.083333333333318 18
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 29.16666666666665 19
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 62.499999999999915 42
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 68.7499999999999 47
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 91.66666666666652 61
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 95.83333333333317 67
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 108.33333333333314 84
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 108.33333333333314 96
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0ba8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094828> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0f36d8> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 29.16666666666665 19
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 31.249999999999982 20
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 64.58333333333324 43
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 70.83333333333323 48
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 93.74999999999984 62
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 97.9166666666665 68
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 110.41666666666647 85
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 110.41666666666647 97
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca4a8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 29.16666666666665 20
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 31.249999999999982 21
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 64.58333333333324 44
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 70.83333333333323 49
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 93.74999999999984 63
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 97.9166666666665 69
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 110.41666666666647 86
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 110.41666666666647 98
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0b50b8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5c18> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b55f8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5438> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b50f0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c13a080> 10.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f289c0f34a8> 14.583333333333325 9
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 31.249999999999982 21
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 33.333333333333314 22
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 66.66666666666657 45
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 72.91666666666656 50
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 95.83333333333317 64
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 99.99999999999983 70
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 112.4999999999998 87
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 112.4999999999998 99
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca4a8> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 31.249999999999982 22
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 33.333333333333314 23
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 66.66666666666657 46
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 72.91666666666656 51
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 95.83333333333317 65
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 99.99999999999983 71
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 112.4999999999998 88
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 112.4999999999998 100
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #7
root->6->17->3->0->3->13->5
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e5c0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094358> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f31d0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1185f8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c094828> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f289c0f36d8> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 14.583333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 33.333333333333314 23
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 35.41666666666664 24
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 68.7499999999999 47
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 74.99999999999989 52
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 97.9166666666665 66
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 102.08333333333316 72
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 114.58333333333313 89
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 114.58333333333313 101
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e5c0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094358> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f31d0> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1185f8> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f289c094828> 10.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f289c0f36d8> 12.499999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 12.499999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 14.583333333333325 9
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 33.333333333333314 24
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 35.41666666666664 25
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 68.7499999999999 48
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 74.99999999999989 53
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 97.9166666666665 67
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 102.08333333333316 73
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 114.58333333333313 90
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 114.58333333333313 102
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094358> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0f31d0> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1185f8> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7f289c094828> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f289c0f36d8> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 33.333333333333314 25
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 35.41666666666664 26
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 68.7499999999999 49
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 74.99999999999989 54
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 97.9166666666665 68
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 102.08333333333316 74
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 114.58333333333313 91
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 114.58333333333313 103
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0b02b0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0860> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 16.666666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 35.41666666666664 26
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 37.49999999999997 27
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 70.83333333333323 50
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 77.08333333333321 55
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 99.99999999999983 69
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 104.16666666666649 75
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 116.66666666666646 92
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 116.66666666666646 104
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c094e48> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 18.74999999999999 12
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 37.49999999999997 27
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 39.5833333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 72.91666666666656 51
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 79.16666666666654 56
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 102.08333333333316 70
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 106.24999999999982 76
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 118.74999999999979 93
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 118.74999999999979 105
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c05ea58> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b70> 16.666666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 20.83333333333332 13
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 39.5833333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 41.66666666666663 29
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 74.99999999999989 52
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 81.24999999999987 57
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 104.16666666666649 71
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 108.33333333333314 77
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 120.83333333333312 94
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 120.83333333333312 106
Completed Iteration #18
Best Reward: 2.083333333333332
coverage_call_count 300
Completed Iteration #19
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c07c278> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c2e8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b02b0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0860> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 22.916666666666654 14
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 41.66666666666663 29
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 43.74999999999996 30
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 77.08333333333321 53
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 83.3333333333332 58
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 106.24999999999982 72
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 110.41666666666647 78
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 122.91666666666644 95
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 122.91666666666644 107
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3f60> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05ec88> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b02b0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0860> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 24.999999999999986 15
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 43.74999999999996 30
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 45.833333333333286 31
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 79.16666666666654 54
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 85.41666666666653 59
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 108.33333333333314 73
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 112.4999999999998 79
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 124.99999999999977 96
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 124.99999999999977 108
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ead30> 24.999999999999986 16
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 43.74999999999996 31
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 45.833333333333286 32
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 79.16666666666654 55
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 85.41666666666653 60
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 108.33333333333314 74
backprop <src.mcts.MCTS_Node object at 0x7f289c118748> 112.4999999999998 80
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44e0> 124.99999999999977 97
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6470> 124.99999999999977 109
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #8
root->6->17->3->0->3->13->5->29
Best Reward: 2.083333333333332
iteration: 3
found coverage increase 2.083333333333332
Current Total Coverage 8.333333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b52e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0caf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 8.333333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 2.0833333333333357 13
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 4.166666666666671 14
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4860> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 8.33333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 8.33333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 8.33333333333334 15
Completed Iteration #22
Best Reward: 4.166666666666668
Completed Iteration #23
Best Reward: 4.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 8.33333333333334 16
Completed Iteration #24
Best Reward: 4.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 4.166666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 6.2500000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 6.2500000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 8.33333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 8.33333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 8.33333333333334 17
Completed Iteration #25
Best Reward: 4.166666666666668
Completed MCTS Level/Depth: #0
root
Best Reward: 4.166666666666668
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4080> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa5f8> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4860> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 8.333333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 10.416666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 10.416666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 12.500000000000007 6
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 12.500000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 12.500000000000007 18
Completed Iteration #0
Best Reward: 4.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 12.500000000000007 8
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 12.500000000000007 19
Completed Iteration #1
Best Reward: 4.166666666666668
Completed Iteration #2
Best Reward: 4.166666666666668
Completed Iteration #3
Best Reward: 4.166666666666668
Completed Iteration #4
Best Reward: 4.166666666666668
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4ef0> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4f60> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4080> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa5f8> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4860> 12.500000000000004 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 12.500000000000004 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 14.58333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 14.58333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 16.666666666666675 7
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 16.666666666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 16.666666666666675 20
Completed Iteration #5
Best Reward: 4.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 16.666666666666675 10
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 16.666666666666675 21
Completed Iteration #6
Best Reward: 4.166666666666668
Completed Iteration #7
Best Reward: 4.166666666666668
Completed Iteration #8
Best Reward: 4.166666666666668
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aab80710> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 18.75000000000001 8
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 18.75000000000001 11
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 18.75000000000001 22
Completed Iteration #9
Best Reward: 4.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80710> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 18.75000000000001 9
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 18.75000000000001 12
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 18.75000000000001 23
Completed Iteration #10
Best Reward: 4.166666666666668
Completed Iteration #11
Best Reward: 4.166666666666668
Completed Iteration #12
Best Reward: 4.166666666666668
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab893c8> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 18.750000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 22.91666666666668 10
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 22.91666666666668 13
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 22.91666666666668 24
Completed Iteration #13
Best Reward: 4.166666666666668
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aab80fd0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 14.58333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 16.666666666666675 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 20.833333333333343 8
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 25.000000000000014 11
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 25.000000000000014 14
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 25.000000000000014 25
Completed Iteration #14
Best Reward: 4.166666666666668
Completed Iteration #15
Best Reward: 4.166666666666668
Completed Iteration #16
Best Reward: 4.166666666666668
Completed Iteration #17
Best Reward: 4.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 25.000000000000014 15
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 25.000000000000014 26
Completed Iteration #18
Best Reward: 4.166666666666668
Completed Iteration #19
Best Reward: 4.166666666666668
Completed Iteration #20
Best Reward: 4.166666666666668
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aab98518> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 27.08333333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 27.08333333333335 27
Completed Iteration #21
Best Reward: 4.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 27.08333333333335 17
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 27.08333333333335 28
Completed Iteration #22
Best Reward: 4.166666666666668
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab896d8> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa5f8> 12.500000000000004 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4860> 16.66666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 18.750000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 20.833333333333343 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 25.00000000000001 9
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 29.166666666666682 12
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 31.250000000000018 18
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 31.250000000000018 29
Completed Iteration #23
Best Reward: 4.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 31.250000000000018 19
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 31.250000000000018 30
Completed Iteration #24
Best Reward: 4.166666666666668
Completed Iteration #25
Best Reward: 4.166666666666668
Completed MCTS Level/Depth: #1
root->6
Best Reward: 4.166666666666668
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4d68> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4f28> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab893c8> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 27.083333333333346 10
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 31.250000000000018 13
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 33.33333333333336 20
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 33.33333333333336 31
Completed Iteration #0
Best Reward: 4.166666666666668
Completed Iteration #1
Best Reward: 4.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 31.250000000000018 14
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 33.33333333333336 21
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 33.33333333333336 32
Completed Iteration #2
Best Reward: 4.166666666666668
Completed Iteration #3
Best Reward: 4.166666666666668
Completed Iteration #4
Best Reward: 4.166666666666668
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ef0> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e780> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80710> 6.2500000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 6.2500000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 35.416666666666686 15
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 37.50000000000003 22
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 37.50000000000003 33
Completed Iteration #5
Best Reward: 4.166666666666668
Completed Iteration #6
Best Reward: 4.166666666666668
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab890f0> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4748> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4ef0> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4f60> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4080> 12.500000000000004 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa5f8> 16.66666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4860> 20.83333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 22.916666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 25.00000000000001 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 31.250000000000014 11
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 39.58333333333336 16
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 41.6666666666667 23
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 41.6666666666667 34
Completed Iteration #7
Best Reward: 4.166666666666668
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aab896a0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 8.33333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 41.66666666666669 17
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 43.750000000000036 24
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 43.750000000000036 35
Completed Iteration #8
Best Reward: 4.166666666666668
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aab987f0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4f60> 10.416666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4080> 14.58333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa5f8> 18.750000000000007 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4860> 22.916666666666675 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 25.00000000000001 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 27.083333333333346 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 33.33333333333335 12
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 43.75000000000003 18
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 45.83333333333337 25
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 45.83333333333337 36
Completed Iteration #9
Best Reward: 4.166666666666668
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c50> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98a90> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80fd0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 27.083333333333346 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 29.166666666666682 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 35.416666666666686 13
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 45.833333333333364 19
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 47.91666666666671 26
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 47.91666666666671 37
Completed Iteration #10
Best Reward: 4.166666666666668
Completed Iteration #11
Best Reward: 4.166666666666668
Completed Iteration #12
Best Reward: 4.166666666666668
Completed Iteration #13
Best Reward: 4.166666666666668
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 39.58333333333336 14
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 50.00000000000003 20
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 52.08333333333337 27
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 52.08333333333337 38
Completed Iteration #14
Best Reward: 4.166666666666668
coverage_call_count 400
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1748> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab800f0> 4.166666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 54.1666666666667 21
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 56.25000000000004 28
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 56.25000000000004 39
Completed Iteration #15
Best Reward: 4.166666666666668
Completed Iteration #16
Best Reward: 4.166666666666668
Completed Iteration #17
Best Reward: 4.166666666666668
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1da0> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ef0> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1748> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab800f0> 8.333333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 58.33333333333337 22
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 60.416666666666714 29
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 60.416666666666714 40
Completed Iteration #18
Best Reward: 4.166666666666668
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 41.66666666666669 15
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 60.41666666666671 23
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 62.50000000000005 30
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 62.50000000000005 41
Completed Iteration #19
Best Reward: 4.166666666666668
Completed Iteration #20
Best Reward: 4.166666666666668
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aabb19e8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 10.416666666666675 6
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 62.50000000000004 24
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 64.58333333333339 31
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 64.58333333333339 42
Completed Iteration #21
Best Reward: 4.166666666666668
Reward: 8.333333333333332
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 8.333333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 8.333333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 10.416666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 10.416666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 14.583333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 50.00000000000003 16
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 70.83333333333337 25
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 72.91666666666671 32
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 72.91666666666671 43
Completed Iteration #22
Best Reward: 8.333333333333332
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 18.750000000000004 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 54.1666666666667 17
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 75.00000000000004 26
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 77.08333333333339 33
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 77.08333333333339 44
Completed Iteration #23
Best Reward: 8.333333333333332
Completed Iteration #24
Best Reward: 8.333333333333332
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1710> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1c50> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c50> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98a90> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80fd0> 8.33333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 31.250000000000014 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 33.33333333333335 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 58.33333333333337 18
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 79.16666666666671 27
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 81.25000000000006 34
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 81.25000000000006 45
Completed Iteration #25
Best Reward: 8.333333333333332
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 8.333333333333332
Completed Iteration #0
Best Reward: 8.333333333333332
Completed Iteration #1
Best Reward: 8.333333333333332
Completed Iteration #2
Best Reward: 8.333333333333332
Completed Iteration #3
Best Reward: 8.333333333333332
Completed Iteration #4
Best Reward: 8.333333333333332
Completed Iteration #5
Best Reward: 8.333333333333332
Completed Iteration #6
Best Reward: 8.333333333333332
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 20.833333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 20.833333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 22.91666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 22.91666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 31.250000000000007 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 70.83333333333337 19
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 91.66666666666671 28
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 93.75000000000006 35
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 93.75000000000006 46
Completed Iteration #7
Best Reward: 12.500000000000004
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aabb13c8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 25.000000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 33.33333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 72.91666666666671 20
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 93.75000000000006 29
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 95.8333333333334 36
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 95.8333333333334 47
Completed Iteration #8
Best Reward: 12.500000000000004
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 37.500000000000014 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 77.08333333333339 21
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 97.91666666666673 30
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 100.00000000000007 37
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 100.00000000000007 48
Completed Iteration #9
Best Reward: 12.500000000000004
Completed Iteration #10
Best Reward: 12.500000000000004
Completed Iteration #11
Best Reward: 12.500000000000004
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc18> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 12.500000000000004 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 12.500000000000004 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 41.666666666666686 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 81.25000000000006 22
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 102.0833333333334 31
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 104.16666666666674 38
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 104.16666666666674 49
Completed Iteration #12
Best Reward: 12.500000000000004
Completed Iteration #13
Best Reward: 12.500000000000004
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d3c8> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 33.33333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 33.33333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 35.41666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 37.500000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 54.166666666666686 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 93.75000000000006 23
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 114.5833333333334 32
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 116.66666666666674 39
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 116.66666666666674 50
Completed Iteration #14
Best Reward: 12.500000000000004
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aab5da20> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d860> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab896d8> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa5f8> 20.833333333333343 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4860> 25.00000000000001 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 33.33333333333335 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 35.416666666666686 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 95.8333333333334 24
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 116.66666666666674 33
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 118.75000000000009 40
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 118.75000000000009 51
Completed Iteration #15
Best Reward: 12.500000000000004
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1a90> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cc0> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc18> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 8.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 12.500000000000004 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 12.500000000000004 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 16.66666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 16.66666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 58.33333333333336 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 100.00000000000007 25
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 120.83333333333341 34
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 122.91666666666676 41
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 122.91666666666676 52
Completed Iteration #16
Best Reward: 12.500000000000004
Reward: 6.250000000000002
backprop <src.mcts.MCTS_Node object at 0x7f28aab98748> 6.250000000000002 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab988d0> 6.250000000000002 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1a90> 10.41666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cc0> 10.41666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc18> 14.583333333333337 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 14.583333333333337 4
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 18.750000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 18.750000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 22.91666666666667 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 22.91666666666667 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 64.58333333333336 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 106.25000000000007 26
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 127.08333333333341 35
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 129.16666666666677 42
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 129.16666666666677 53
Completed Iteration #17
Best Reward: 12.500000000000004
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aab80128> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89470> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab987f0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4f60> 12.500000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4080> 16.666666666666675 6
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa5f8> 22.91666666666668 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4860> 27.083333333333346 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 35.416666666666686 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 37.50000000000002 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 108.3333333333334 27
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 129.16666666666674 36
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 131.2500000000001 43
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 131.2500000000001 54
Completed Iteration #18
Best Reward: 12.500000000000004
Completed Iteration #19
Best Reward: 12.500000000000004
Completed Iteration #20
Best Reward: 12.500000000000004
Completed Iteration #21
Best Reward: 12.500000000000004
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbef0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbf60> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab987f0> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4f60> 14.583333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4080> 18.75000000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa5f8> 25.000000000000014 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4860> 29.166666666666682 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 37.50000000000002 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 39.58333333333336 15
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 110.41666666666674 28
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 131.25000000000009 37
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 133.33333333333346 44
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 133.33333333333346 55
Completed Iteration #22
Best Reward: 12.500000000000004
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d630> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d6a0> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d3c8> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 45.83333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 45.83333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 47.91666666666667 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 50.000000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 77.08333333333336 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 122.91666666666674 29
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 143.75000000000009 38
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 145.83333333333346 45
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 145.83333333333346 56
Completed Iteration #23
Best Reward: 12.500000000000004
Completed Iteration #24
Best Reward: 12.500000000000004
Completed Iteration #25
Best Reward: 12.500000000000004
Completed MCTS Level/Depth: #3
root->6->19->3
Best Reward: 12.500000000000004
Completed Iteration #0
Best Reward: 12.500000000000004
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab68128> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 22.916666666666675 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 27.08333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 27.08333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 81.25000000000003 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 127.08333333333341 30
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 147.91666666666674 39
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 150.0000000000001 46
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 150.0000000000001 57
Completed Iteration #1
Best Reward: 12.500000000000004
Completed Iteration #2
Best Reward: 12.500000000000004
Reward: 6.250000000000002
backprop <src.mcts.MCTS_Node object at 0x7f28aab686d8> 6.250000000000002 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68748> 6.250000000000002 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98748> 12.500000000000004 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab988d0> 12.500000000000004 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1a90> 16.66666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cc0> 16.66666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc18> 20.83333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 20.83333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 25.000000000000007 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 29.16666666666668 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 33.33333333333334 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 33.33333333333334 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 87.50000000000003 15
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 133.33333333333343 31
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 154.16666666666674 40
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 156.2500000000001 47
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 156.2500000000001 58
Completed Iteration #3
Best Reward: 12.500000000000004
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1e80> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc50> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d630> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d6a0> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d3c8> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 50.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 50.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 58.33333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 58.33333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 60.41666666666667 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 62.500000000000014 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 100.00000000000003 16
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 145.83333333333343 32
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 166.66666666666674 41
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 168.7500000000001 48
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 168.7500000000001 59
Completed Iteration #4
Best Reward: 12.500000000000004
Completed Iteration #5
Best Reward: 12.500000000000004
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab89400> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 25.000000000000007 6
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 29.166666666666675 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 33.33333333333334 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 37.500000000000014 9
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 37.500000000000014 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 104.1666666666667 17
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 150.00000000000009 33
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 170.8333333333334 42
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 172.91666666666677 49
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 172.91666666666677 60
Completed Iteration #6
Best Reward: 12.500000000000004
Completed Iteration #7
Best Reward: 12.500000000000004
Reward: 6.250000000000002
backprop <src.mcts.MCTS_Node object at 0x7f28aab5df98> 6.250000000000002 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98940> 6.250000000000002 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab686d8> 12.500000000000004 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68748> 12.500000000000004 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98748> 18.750000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab988d0> 18.750000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1a90> 22.91666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cc0> 22.91666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc18> 27.083333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 31.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 35.41666666666668 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 39.58333333333334 9
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 43.750000000000014 10
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 43.750000000000014 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 110.4166666666667 18
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 156.25000000000009 34
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 177.0833333333334 43
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 179.16666666666677 50
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 179.16666666666677 61
Completed Iteration #8
Best Reward: 12.500000000000004
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 50.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 62.500000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 62.500000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 70.83333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 70.83333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 72.91666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 75.00000000000001 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 122.9166666666667 19
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 168.75000000000009 35
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 189.5833333333334 44
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 191.66666666666677 51
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 191.66666666666677 62
Completed Iteration #9
Best Reward: 12.500000000000004
Reward: 10.416666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab68710> 10.416666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68198> 10.416666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5df98> 16.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98940> 16.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab686d8> 22.91666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab68748> 22.91666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98748> 29.166666666666675 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab988d0> 29.166666666666675 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1a90> 33.33333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cc0> 33.33333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc18> 37.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 41.66666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 45.83333333333334 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 50.000000000000014 10
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 54.166666666666686 11
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 54.166666666666686 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 133.33333333333337 20
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 179.16666666666674 36
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 200.00000000000006 45
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 202.08333333333343 52
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 202.08333333333343 63
Completed Iteration #10
Best Reward: 12.500000000000004
Completed Iteration #11
Best Reward: 12.500000000000004
Completed Iteration #12
Best Reward: 12.500000000000004
Completed Iteration #13
Best Reward: 12.500000000000004
Completed Iteration #14
Best Reward: 12.500000000000004
Completed Iteration #15
Best Reward: 12.500000000000004
Completed Iteration #16
Best Reward: 12.500000000000004
Completed Iteration #17
Best Reward: 12.500000000000004
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 62.500000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 75.00000000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 75.00000000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 83.33333333333334 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 83.33333333333334 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 85.41666666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 87.50000000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 145.83333333333337 21
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 191.66666666666674 37
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 212.50000000000006 46
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 214.58333333333343 53
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 214.58333333333343 64
Completed Iteration #18
Best Reward: 12.500000000000004
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab80240> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 58.33333333333336 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 150.00000000000003 22
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 195.8333333333334 38
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 216.6666666666667 47
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 218.75000000000009 54
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 218.75000000000009 65
Completed Iteration #19
Best Reward: 12.500000000000004
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb470> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1c18> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 154.16666666666669 23
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 200.00000000000006 39
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 220.83333333333337 48
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 222.91666666666674 55
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 222.91666666666674 66
Completed Iteration #20
Best Reward: 12.500000000000004
Completed Iteration #21
Best Reward: 12.500000000000004
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab68898> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 91.66666666666669 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 158.33333333333334 24
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 204.1666666666667 40
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 225.00000000000003 49
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 227.0833333333334 56
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 227.0833333333334 67
Completed Iteration #22
Best Reward: 12.500000000000004
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab68e10> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68ac8> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68710> 22.91666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68198> 22.91666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5df98> 29.166666666666675 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98940> 29.166666666666675 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab686d8> 35.41666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab68748> 35.41666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab98748> 41.66666666666668 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab988d0> 41.66666666666668 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1a90> 45.83333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cc0> 45.83333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc18> 50.000000000000014 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 54.16666666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 58.33333333333334 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabb12e8> 62.500000000000014 11
backprop <src.mcts.MCTS_Node object at 0x7f28aab80438> 66.66666666666669 12
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ba8> 70.83333333333336 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 170.83333333333334 25
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 216.6666666666667 41
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 237.50000000000003 50
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 239.5833333333334 57
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 239.5833333333334 68
Completed Iteration #23
Best Reward: 12.500000000000004
Completed Iteration #24
Best Reward: 12.500000000000004
Completed Iteration #25
Best Reward: 12.500000000000004
Completed MCTS Level/Depth: #4
root->6->19->3->16
Best Reward: 12.500000000000004
Completed Iteration #0
Best Reward: 12.500000000000004
Completed Iteration #1
Best Reward: 12.500000000000004
Completed Iteration #2
Best Reward: 12.500000000000004
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 75.00000000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 87.50000000000001 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 87.50000000000001 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 95.83333333333334 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 95.83333333333334 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 97.91666666666667 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 104.16666666666669 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 183.33333333333334 26
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 229.1666666666667 42
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 250.00000000000003 51
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 252.0833333333334 58
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 252.0833333333334 69
Completed Iteration #3
Best Reward: 12.500000000000004
Completed Iteration #4
Best Reward: 12.500000000000004
Completed Iteration #5
Best Reward: 12.500000000000004
Completed Iteration #6
Best Reward: 12.500000000000004
Reward: 16.666666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab17908> 16.666666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab171d0> 16.666666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 29.16666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 29.16666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 41.66666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 41.66666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 54.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 91.66666666666669 8
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 104.16666666666669 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 104.16666666666669 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 112.50000000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 112.50000000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 114.58333333333334 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 120.83333333333336 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 200.0 27
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 245.83333333333337 43
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 266.6666666666667 52
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 268.75000000000006 59
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 268.75000000000006 70
Completed Iteration #7
Best Reward: 16.666666666666668
Completed Iteration #8
Best Reward: 16.666666666666668
Completed Iteration #9
Best Reward: 16.666666666666668
Completed Iteration #10
Best Reward: 16.666666666666668
Completed Iteration #11
Best Reward: 16.666666666666668
Completed Iteration #12
Best Reward: 16.666666666666668
Reward: 16.666666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab246a0> 16.666666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17278> 16.666666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17908> 33.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab171d0> 33.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 45.83333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 45.83333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 58.33333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 58.33333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 70.83333333333336 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 108.33333333333336 9
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 120.83333333333336 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 120.83333333333336 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 129.16666666666669 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 129.16666666666669 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 131.25 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 137.50000000000003 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 216.66666666666666 28
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 262.50000000000006 44
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 283.33333333333337 53
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 285.41666666666674 60
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 285.41666666666674 71
Completed Iteration #13
Best Reward: 16.666666666666668
Completed Iteration #14
Best Reward: 16.666666666666668
Reward: 4.166666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d0b8> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1eb8> 4.166666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 135.41666666666666 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 141.66666666666669 15
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 220.83333333333331 29
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 266.66666666666674 45
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 287.50000000000006 54
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 289.5833333333334 61
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 289.5833333333334 72
Completed Iteration #15
Best Reward: 16.666666666666668
Completed Iteration #16
Best Reward: 16.666666666666668
Completed Iteration #17
Best Reward: 16.666666666666668
Completed Iteration #18
Best Reward: 16.666666666666668
Completed Iteration #19
Best Reward: 16.666666666666668
Completed Iteration #20
Best Reward: 16.666666666666668
Completed Iteration #21
Best Reward: 16.666666666666668
Completed Iteration #22
Best Reward: 16.666666666666668
Completed Iteration #23
Best Reward: 16.666666666666668
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab17550> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68b00> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1e80> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc50> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d630> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d6a0> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d3c8> 50.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 120.83333333333336 10
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 133.33333333333337 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 133.33333333333337 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 141.66666666666669 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 141.66666666666669 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 147.91666666666666 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 154.16666666666669 16
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 233.33333333333331 30
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 279.16666666666674 46
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 300.00000000000006 55
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 302.0833333333334 62
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 302.0833333333334 73
Completed Iteration #24
Best Reward: 16.666666666666668
Completed Iteration #25
Best Reward: 16.666666666666668
Completed MCTS Level/Depth: #5
root->6->19->3->16->2
Best Reward: 16.666666666666668
Completed Iteration #0
Best Reward: 16.666666666666668
Completed Iteration #1
Best Reward: 16.666666666666668
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab24eb8> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d6a0> 50.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d3c8> 62.500000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 133.33333333333337 11
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 145.83333333333337 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 145.83333333333337 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 154.16666666666669 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 154.16666666666669 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 160.41666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 166.66666666666669 17
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 245.83333333333331 31
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 291.66666666666674 47
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 312.50000000000006 56
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 314.5833333333334 63
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 314.5833333333334 74
Completed Iteration #2
Best Reward: 16.666666666666668
Completed Iteration #3
Best Reward: 16.666666666666668
Reward: 16.666666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c88> 16.666666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4668> 16.666666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab246a0> 33.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab17278> 33.333333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab17908> 50.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab171d0> 50.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 62.500000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 62.500000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 75.00000000000001 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 75.00000000000001 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 87.50000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 150.00000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 162.50000000000003 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 162.50000000000003 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 170.83333333333334 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 170.83333333333334 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 177.08333333333331 16
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 183.33333333333334 18
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 262.5 32
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 308.3333333333334 48
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 329.16666666666674 57
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 331.2500000000001 64
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 331.2500000000001 75
Completed Iteration #4
Best Reward: 16.666666666666668
Reward: 18.75
backprop <src.mcts.MCTS_Node object at 0x7f28aaac48d0> 18.75 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4780> 18.75 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c88> 35.41666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4668> 35.41666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab246a0> 52.083333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab17278> 52.083333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab17908> 68.75 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab171d0> 68.75 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 81.25000000000001 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 81.25000000000001 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 93.75000000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 93.75000000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 106.25000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 168.75000000000003 13
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 181.25000000000003 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 181.25000000000003 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 189.58333333333334 15
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 189.58333333333334 15
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 195.83333333333331 17
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 202.08333333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 281.25 33
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 327.0833333333334 49
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 347.91666666666674 58
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 350.0000000000001 65
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 350.0000000000001 76
Completed Iteration #5
Best Reward: 18.75
Reward: 6.250000000000002
backprop <src.mcts.MCTS_Node object at 0x7f28aab68550> 6.250000000000002 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98eb8> 6.250000000000002 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d0b8> 10.41666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1eb8> 10.41666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 202.08333333333331 18
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 208.33333333333334 20
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 287.5 34
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 333.3333333333334 50
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 354.16666666666674 59
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 356.2500000000001 66
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 356.2500000000001 77
Completed Iteration #6
Best Reward: 18.75
Reward: 14.583333333333332
backprop <src.mcts.MCTS_Node object at 0x7f28aab17c50> 14.583333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 183.33333333333337 14
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 195.83333333333337 15
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 195.83333333333337 15
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 204.16666666666669 16
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 204.16666666666669 16
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 216.66666666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 222.91666666666669 21
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 302.0833333333333 35
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 347.91666666666674 51
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 368.75000000000006 60
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 370.8333333333334 67
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 370.8333333333334 78
Completed Iteration #7
Best Reward: 18.75
Completed Iteration #8
Best Reward: 18.75
Completed Iteration #9
Best Reward: 18.75
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d240> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 208.33333333333337 16
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 216.66666666666669 17
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 216.66666666666669 17
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 229.16666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 235.41666666666669 22
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 314.5833333333333 36
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 360.41666666666674 52
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 381.25000000000006 61
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 383.3333333333334 68
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 383.3333333333334 79
Completed Iteration #10
Best Reward: 18.75
Completed Iteration #11
Best Reward: 18.75
Completed Iteration #12
Best Reward: 18.75
coverage_call_count 500
Completed Iteration #13
Best Reward: 18.75
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aaac40b8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1eb8> 12.500000000000005 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 231.25 21
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 237.50000000000003 23
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 316.66666666666663 37
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 362.50000000000006 53
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 383.33333333333337 62
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 385.41666666666674 69
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 385.41666666666674 80
Completed Iteration #14
Best Reward: 18.75
Completed Iteration #15
Best Reward: 18.75
Completed Iteration #16
Best Reward: 18.75
Completed Iteration #17
Best Reward: 18.75
Completed Iteration #18
Best Reward: 18.75
Completed Iteration #19
Best Reward: 18.75
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4c18> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb470> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17550> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68b00> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1e80> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc50> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d630> 50.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d6a0> 62.500000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d3c8> 75.00000000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 195.83333333333337 15
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 208.33333333333337 16
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 220.83333333333337 17
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 229.16666666666669 18
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 229.16666666666669 18
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 243.75 22
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 250.00000000000003 24
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 329.16666666666663 38
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 375.00000000000006 54
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 395.83333333333337 63
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 397.91666666666674 70
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 397.91666666666674 81
Completed Iteration #20
Best Reward: 18.75
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab76320> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ca58> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d240> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 233.33333333333337 18
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 241.66666666666669 19
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 241.66666666666669 19
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 256.25 23
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 262.50000000000006 25
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 341.66666666666663 39
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 387.50000000000006 55
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 408.33333333333337 64
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 410.41666666666674 71
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 410.41666666666674 82
Completed Iteration #21
Best Reward: 18.75
Completed Iteration #22
Best Reward: 18.75
Completed Iteration #23
Best Reward: 18.75
Completed Iteration #24
Best Reward: 18.75
Completed Iteration #25
Best Reward: 18.75
Completed MCTS Level/Depth: #6
root->6->19->3->16->2->14
Best Reward: 18.75
Completed Iteration #0
Best Reward: 18.75
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7160> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbfd0> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76320> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f289c07ca58> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d240> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 245.83333333333337 19
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 254.16666666666669 20
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 254.16666666666669 20
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 268.75 24
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 275.00000000000006 26
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 354.16666666666663 40
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 400.00000000000006 56
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 420.83333333333337 65
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 422.91666666666674 72
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 422.91666666666674 83
Completed Iteration #1
Best Reward: 18.75
Completed Iteration #2
Best Reward: 18.75
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4c88> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 256.25 21
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 270.8333333333333 25
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 277.08333333333337 27
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 356.24999999999994 41
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 402.08333333333337 57
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 422.9166666666667 66
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 425.00000000000006 73
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 425.00000000000006 84
Completed Iteration #3
Best Reward: 18.75
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab175f8> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4908> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24eb8> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d6a0> 75.00000000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d3c8> 87.50000000000001 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 208.33333333333337 16
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 220.83333333333337 17
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 258.33333333333337 20
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 266.6666666666667 21
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 268.75 22
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 283.3333333333333 26
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 289.58333333333337 28
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 368.74999999999994 42
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 414.58333333333337 58
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 435.4166666666667 67
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 437.50000000000006 74
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 437.50000000000006 85
Completed Iteration #4
Best Reward: 18.75
Completed Iteration #5
Best Reward: 18.75
Reward: 10.416666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ef0> 10.416666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 268.75000000000006 21
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 277.08333333333337 22
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 279.1666666666667 23
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 293.75 27
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 300.00000000000006 29
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 379.16666666666663 43
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 425.00000000000006 59
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 445.83333333333337 68
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 447.91666666666674 75
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 447.91666666666674 86
Completed Iteration #6
Best Reward: 18.75
Completed Iteration #7
Best Reward: 18.75
Completed Iteration #8
Best Reward: 18.75
Completed Iteration #9
Best Reward: 18.75
Completed Iteration #10
Best Reward: 18.75
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbfd0> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76320> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f289c07ca58> 37.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d240> 50.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 281.25000000000006 22
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 289.58333333333337 23
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 291.6666666666667 24
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 306.25 28
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 312.50000000000006 30
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 391.66666666666663 44
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 437.50000000000006 60
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 458.33333333333337 69
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 460.41666666666674 76
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 460.41666666666674 87
Completed Iteration #11
Best Reward: 18.75
Completed Iteration #12
Best Reward: 18.75
Completed Iteration #13
Best Reward: 18.75
Completed Iteration #14
Best Reward: 18.75
Completed Iteration #15
Best Reward: 18.75
Completed Iteration #16
Best Reward: 18.75
Reward: 10.416666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7c50> 10.416666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 302.08333333333337 25
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 316.6666666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 322.91666666666674 31
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 402.0833333333333 45
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 447.91666666666674 61
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 468.75000000000006 70
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 470.8333333333334 77
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 470.8333333333334 88
Completed Iteration #17
Best Reward: 18.75
Completed Iteration #18
Best Reward: 18.75
Reward: 20.833333333333336
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7390> 20.833333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7940> 20.833333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac48d0> 39.583333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4780> 39.583333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c88> 56.25000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4668> 56.25000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab246a0> 72.91666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab17278> 72.91666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab17908> 89.58333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab171d0> 89.58333333333334 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 102.08333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 102.08333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 114.58333333333334 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 114.58333333333334 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 127.08333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 229.1666666666667 17
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 241.6666666666667 18
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 302.08333333333337 23
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 310.4166666666667 24
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 322.9166666666667 26
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 337.5 30
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 343.75000000000006 32
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 422.91666666666663 46
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 468.75000000000006 62
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 489.58333333333337 71
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 491.66666666666674 78
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 491.66666666666674 89
Completed Iteration #19
Best Reward: 20.833333333333336
Completed Iteration #20
Best Reward: 20.833333333333336
Completed Iteration #21
Best Reward: 20.833333333333336
Reward: 20.833333333333336
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d7f0> 20.833333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76be0> 20.833333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7390> 41.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7940> 41.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac48d0> 60.41666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4780> 60.41666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c88> 77.08333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4668> 77.08333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab246a0> 93.75 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab17278> 93.75 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab17908> 110.41666666666669 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab171d0> 110.41666666666669 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 122.91666666666669 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 122.91666666666669 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 135.41666666666669 9
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 135.41666666666669 9
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 147.9166666666667 10
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 250.00000000000006 18
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 262.50000000000006 19
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 322.9166666666667 24
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 331.25 25
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 343.75 27
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 358.3333333333333 31
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 364.58333333333337 33
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 443.74999999999994 47
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 489.58333333333337 63
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 510.4166666666667 72
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 512.5000000000001 79
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 512.5000000000001 90
Completed Iteration #22
Best Reward: 20.833333333333336
Reward: 10.416666666666668
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7860> 10.416666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4710> 10.416666666666668 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ef0> 20.833333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 333.33333333333337 25
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 341.6666666666667 26
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 354.1666666666667 28
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 368.75 32
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 375.00000000000006 34
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 454.16666666666663 48
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 500.00000000000006 64
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 520.8333333333334 73
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 522.9166666666667 80
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 522.9166666666667 91
Completed Iteration #23
Best Reward: 20.833333333333336
Completed Iteration #24
Best Reward: 20.833333333333336
Completed Iteration #25
Best Reward: 20.833333333333336
Completed MCTS Level/Depth: #7
root->6->19->3->16->2->14->0
Best Reward: 20.833333333333336
Completed Iteration #0
Best Reward: 20.833333333333336
Reward: 20.833333333333336
backprop <src.mcts.MCTS_Node object at 0x7f28aab687b8> 20.833333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4588> 20.833333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d7f0> 41.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76be0> 41.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7390> 62.50000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7940> 62.50000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac48d0> 81.25 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4780> 81.25 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c88> 97.91666666666669 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4668> 97.91666666666669 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab246a0> 114.58333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab17278> 114.58333333333334 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab17908> 131.25000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab171d0> 131.25000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 143.75000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 143.75000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 156.25000000000003 10
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 156.25000000000003 10
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 168.75000000000006 11
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 270.83333333333337 19
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 283.33333333333337 20
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 354.1666666666667 26
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 362.5 27
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 375.0 29
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 389.5833333333333 33
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 395.83333333333337 35
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 474.99999999999994 49
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 520.8333333333334 65
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 541.6666666666667 74
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 543.7500000000001 81
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 543.7500000000001 92
Completed Iteration #1
Best Reward: 20.833333333333336
Completed Iteration #2
Best Reward: 20.833333333333336
Completed Iteration #3
Best Reward: 20.833333333333336
Completed Iteration #4
Best Reward: 20.833333333333336
Completed Iteration #5
Best Reward: 20.833333333333336
Completed Iteration #6
Best Reward: 20.833333333333336
Completed Iteration #7
Best Reward: 20.833333333333336
Completed Iteration #8
Best Reward: 20.833333333333336
Completed Iteration #9
Best Reward: 20.833333333333336
Completed Iteration #10
Best Reward: 20.833333333333336
Completed Iteration #11
Best Reward: 20.833333333333336
Completed Iteration #12
Best Reward: 20.833333333333336
Completed Iteration #13
Best Reward: 20.833333333333336
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96128> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 156.25000000000003 10
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 168.75000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 168.75000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 181.25000000000006 12
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 283.33333333333337 20
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 295.83333333333337 21
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 366.6666666666667 27
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 375.0 28
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 387.5 30
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 402.0833333333333 34
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 408.33333333333337 36
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 487.49999999999994 50
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 533.3333333333334 66
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 554.1666666666667 75
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 556.2500000000001 82
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 556.2500000000001 93
Completed Iteration #14
Best Reward: 20.833333333333336
Completed Iteration #15
Best Reward: 20.833333333333336
Completed Iteration #16
Best Reward: 20.833333333333336
Completed Iteration #17
Best Reward: 20.833333333333336
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbd68> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4be0> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96128> 25.000000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab766d8> 168.75000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 181.25000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 181.25000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 193.75000000000006 13
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 295.83333333333337 21
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 308.33333333333337 22
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 379.1666666666667 28
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 387.5 29
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 400.0 31
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 414.5833333333333 35
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 420.83333333333337 37
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 499.99999999999994 51
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 545.8333333333334 67
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 566.6666666666667 76
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 568.7500000000001 83
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 568.7500000000001 94
Completed Iteration #18
Best Reward: 20.833333333333336
Completed Iteration #19
Best Reward: 20.833333333333336
Completed Iteration #20
Best Reward: 20.833333333333336
Completed Iteration #21
Best Reward: 20.833333333333336
Completed Iteration #22
Best Reward: 20.833333333333336
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86f28> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 308.33333333333337 22
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4e0> 320.83333333333337 23
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 391.6666666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 400.0 30
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 412.5 32
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 427.0833333333333 36
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 433.33333333333337 38
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 512.5 52
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 558.3333333333334 68
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 579.1666666666667 77
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 581.2500000000001 84
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 581.2500000000001 95
Completed Iteration #23
Best Reward: 20.833333333333336
Reward: 12.500000000000004
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86cc0> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa869e8> 12.500000000000004 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7860> 22.91666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4710> 22.91666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ef0> 33.33333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 404.1666666666667 30
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 412.5 31
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 425.0 33
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 439.5833333333333 37
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 445.83333333333337 39
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 525.0 53
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4438> 570.8333333333334 69
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 591.6666666666667 78
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 593.7500000000001 85
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 593.7500000000001 96
Completed Iteration #24
Best Reward: 20.833333333333336
Completed Iteration #25
Best Reward: 20.833333333333336
Completed MCTS Level/Depth: #8
root->6->19->3->16->2->14->0->18
Best Reward: 20.833333333333336
iteration: 5
found coverage increase 20.833333333333336
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa967f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa969b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa967f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa969b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96630> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 600
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf80f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf80f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 10
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 700
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 4.166666666666661 2
Completed Iteration #0
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 8.333333333333321 3
Completed Iteration #1
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9e80> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c94a8> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 12.499999999999982 4
Completed Iteration #2
Best Reward: 4.166666666666661
Completed Iteration #3
Best Reward: 4.166666666666661
Completed Iteration #4
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 16.666666666666643 5
Completed Iteration #5
Best Reward: 4.166666666666661
Completed Iteration #6
Best Reward: 4.166666666666661
Completed Iteration #7
Best Reward: 4.166666666666661
Completed Iteration #8
Best Reward: 4.166666666666661
Completed Iteration #9
Best Reward: 4.166666666666661
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 16.666666666666643 6
Completed Iteration #10
Best Reward: 4.166666666666661
Completed Iteration #11
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8390> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c94a8> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 20.833333333333304 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 20.833333333333304 7
Completed Iteration #12
Best Reward: 4.166666666666661
Completed Iteration #13
Best Reward: 4.166666666666661
Completed Iteration #14
Best Reward: 4.166666666666661
Completed Iteration #15
Best Reward: 4.166666666666661
Completed Iteration #16
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aaa496d8> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c94a8> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 24.999999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 24.999999999999964 8
Completed Iteration #17
Best Reward: 4.166666666666661
Completed Iteration #18
Best Reward: 4.166666666666661
Completed Iteration #19
Best Reward: 4.166666666666661
Completed Iteration #20
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d94a8> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9518> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa496d8> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c94a8> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 20.833333333333304 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 29.166666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 29.166666666666625 9
Completed Iteration #21
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96e80> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9518> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa496d8> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c94a8> 20.833333333333304 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 24.999999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 33.333333333333286 9
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 33.333333333333286 10
Completed Iteration #22
Best Reward: 4.166666666666661
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 33.333333333333286 11
Completed Iteration #23
Best Reward: 4.166666666666661
Completed Iteration #24
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9d68> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 37.49999999999994 10
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 37.49999999999994 12
Completed Iteration #25
Best Reward: 4.166666666666661
Completed MCTS Level/Depth: #0
root
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb2b0> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0f0> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9d68> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 41.6666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 41.6666666666666 13
Completed Iteration #0
Best Reward: 4.166666666666661
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb748> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb588> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb2b0> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0f0> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9d68> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 20.833333333333304 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 45.83333333333326 12
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 45.83333333333326 14
Completed Iteration #1
Best Reward: 4.166666666666661
Completed Iteration #2
Best Reward: 4.166666666666661
Completed Iteration #3
Best Reward: 4.166666666666661
Completed Iteration #4
Best Reward: 4.166666666666661
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 45.83333333333326 13
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 45.83333333333326 15
Completed Iteration #5
Best Reward: 4.166666666666661
Completed Iteration #6
Best Reward: 4.166666666666661
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 45.83333333333326 14
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 45.83333333333326 16
Completed Iteration #7
Best Reward: 4.166666666666661
Completed Iteration #8
Best Reward: 4.166666666666661
Completed Iteration #9
Best Reward: 4.166666666666661
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 45.83333333333326 15
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 45.83333333333326 17
Completed Iteration #10
Best Reward: 4.166666666666661
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 22.916666666666647 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 27.083333333333307 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 52.08333333333326 16
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 52.08333333333326 18
Completed Iteration #11
Best Reward: 6.2500000000000036
Completed Iteration #12
Best Reward: 6.2500000000000036
Completed Iteration #13
Best Reward: 6.2500000000000036
Completed Iteration #14
Best Reward: 6.2500000000000036
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 52.08333333333326 17
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 52.08333333333326 19
Completed Iteration #15
Best Reward: 6.2500000000000036
Completed Iteration #16
Best Reward: 6.2500000000000036
Completed Iteration #17
Best Reward: 6.2500000000000036
Completed Iteration #18
Best Reward: 6.2500000000000036
Completed Iteration #19
Best Reward: 6.2500000000000036
Completed Iteration #20
Best Reward: 6.2500000000000036
Completed Iteration #21
Best Reward: 6.2500000000000036
Completed Iteration #22
Best Reward: 6.2500000000000036
Completed Iteration #23
Best Reward: 6.2500000000000036
Completed Iteration #24
Best Reward: 6.2500000000000036
Completed Iteration #25
Best Reward: 6.2500000000000036
Completed MCTS Level/Depth: #1
root->6
Best Reward: 6.2500000000000036
Completed Iteration #0
Best Reward: 6.2500000000000036
Completed Iteration #1
Best Reward: 6.2500000000000036
Completed Iteration #2
Best Reward: 6.2500000000000036
Completed Iteration #3
Best Reward: 6.2500000000000036
Completed Iteration #4
Best Reward: 6.2500000000000036
Completed Iteration #5
Best Reward: 6.2500000000000036
Completed Iteration #6
Best Reward: 6.2500000000000036
Completed Iteration #7
Best Reward: 6.2500000000000036
Completed Iteration #8
Best Reward: 6.2500000000000036
Completed Iteration #9
Best Reward: 6.2500000000000036
Completed Iteration #10
Best Reward: 6.2500000000000036
Completed Iteration #11
Best Reward: 6.2500000000000036
Completed Iteration #12
Best Reward: 6.2500000000000036
Completed Iteration #13
Best Reward: 6.2500000000000036
Completed Iteration #14
Best Reward: 6.2500000000000036
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0f0> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9d68> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 20.833333333333304 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 27.083333333333307 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 31.249999999999968 8
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 56.249999999999915 18
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 56.249999999999915 20
Completed Iteration #15
Best Reward: 6.2500000000000036
Completed Iteration #16
Best Reward: 6.2500000000000036
Completed Iteration #17
Best Reward: 6.2500000000000036
Completed Iteration #18
Best Reward: 6.2500000000000036
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa90> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3358> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0f0> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 20.833333333333304 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9d68> 20.833333333333304 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 24.999999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 31.249999999999968 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 35.41666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 60.41666666666657 19
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 60.41666666666657 21
Completed Iteration #19
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 37.49999999999997 9
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 41.66666666666663 10
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 66.66666666666657 20
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 66.66666666666657 22
Completed Iteration #20
Best Reward: 6.2500000000000036
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2d30> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3358> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0f0> 20.833333333333304 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 24.999999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9d68> 24.999999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 29.166666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 41.66666666666663 10
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 45.833333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 70.83333333333323 21
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 70.83333333333323 23
Completed Iteration #21
Best Reward: 6.2500000000000036
Completed Iteration #22
Best Reward: 6.2500000000000036
Completed Iteration #23
Best Reward: 6.2500000000000036
Completed Iteration #24
Best Reward: 6.2500000000000036
Completed Iteration #25
Best Reward: 6.2500000000000036
Completed MCTS Level/Depth: #2
root->6->7
Best Reward: 6.2500000000000036
Completed Iteration #0
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2c18> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 47.91666666666663 11
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 52.083333333333286 12
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 77.08333333333323 22
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 77.08333333333323 24
Completed Iteration #1
Best Reward: 6.2500000000000036
Completed Iteration #2
Best Reward: 6.2500000000000036
Completed Iteration #3
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 54.16666666666663 12
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 58.333333333333286 13
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 83.33333333333323 23
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 83.33333333333323 25
Completed Iteration #4
Best Reward: 6.2500000000000036
Completed Iteration #5
Best Reward: 6.2500000000000036
coverage_call_count 800
Completed Iteration #6
Best Reward: 6.2500000000000036
Completed Iteration #7
Best Reward: 6.2500000000000036
Completed Iteration #8
Best Reward: 6.2500000000000036
Completed Iteration #9
Best Reward: 6.2500000000000036
Completed Iteration #10
Best Reward: 6.2500000000000036
Completed Iteration #11
Best Reward: 6.2500000000000036
Completed Iteration #12
Best Reward: 6.2500000000000036
Completed Iteration #13
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bd30> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 60.41666666666663 13
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 64.58333333333329 14
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 89.58333333333323 24
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 89.58333333333323 26
Completed Iteration #14
Best Reward: 6.2500000000000036
Completed Iteration #15
Best Reward: 6.2500000000000036
Completed Iteration #16
Best Reward: 6.2500000000000036
Completed Iteration #17
Best Reward: 6.2500000000000036
Completed Iteration #18
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a90> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 66.66666666666663 14
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 70.83333333333329 15
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 95.83333333333323 25
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 95.83333333333323 27
Completed Iteration #19
Best Reward: 6.2500000000000036
Completed Iteration #20
Best Reward: 6.2500000000000036
Completed Iteration #21
Best Reward: 6.2500000000000036
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3ba8> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0f0> 24.999999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 29.166666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9d68> 29.166666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 33.333333333333286 9
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 70.83333333333329 15
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 74.99999999999994 16
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 99.99999999999989 26
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 99.99999999999989 28
Completed Iteration #22
Best Reward: 6.2500000000000036
Completed Iteration #23
Best Reward: 6.2500000000000036
Completed Iteration #24
Best Reward: 6.2500000000000036
Reward: 4.166666666666661
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3c88> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf3c8> 4.166666666666661 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2d30> 8.333333333333321 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3358> 12.499999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 16.666666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0f0> 29.166666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 33.333333333333286 9
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9d68> 33.333333333333286 9
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 37.49999999999994 10
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 74.99999999999994 16
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 79.1666666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 104.16666666666654 27
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 104.16666666666654 29
Completed Iteration #25
Best Reward: 6.2500000000000036
Completed MCTS Level/Depth: #3
root->6->7->2
Best Reward: 6.2500000000000036
Completed Iteration #0
Best Reward: 6.2500000000000036
Completed Iteration #1
Best Reward: 6.2500000000000036
Completed Iteration #2
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b9b0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf240> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a90> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 43.75000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 81.24999999999994 17
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 85.4166666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 110.41666666666654 28
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 110.41666666666654 30
Completed Iteration #3
Best Reward: 6.2500000000000036
Completed Iteration #4
Best Reward: 6.2500000000000036
Completed Iteration #5
Best Reward: 6.2500000000000036
Completed Iteration #6
Best Reward: 6.2500000000000036
Completed Iteration #7
Best Reward: 6.2500000000000036
Completed Iteration #8
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa561400> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf240> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a90> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 43.75000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 43.75000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 50.00000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 87.49999999999994 18
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 91.6666666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 116.66666666666654 29
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 116.66666666666654 31
Completed Iteration #9
Best Reward: 6.2500000000000036
Completed Iteration #10
Best Reward: 6.2500000000000036
Completed Iteration #11
Best Reward: 6.2500000000000036
Completed Iteration #12
Best Reward: 6.2500000000000036
Completed Iteration #13
Best Reward: 6.2500000000000036
Completed Iteration #14
Best Reward: 6.2500000000000036
Completed Iteration #15
Best Reward: 6.2500000000000036
Completed Iteration #16
Best Reward: 6.2500000000000036
Completed Iteration #17
Best Reward: 6.2500000000000036
Completed Iteration #18
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cac8> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b860> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2c18> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 43.75000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 50.00000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 50.00000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 56.25000000000003 10
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 93.74999999999994 19
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 97.9166666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 122.91666666666654 30
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 122.91666666666654 32
Completed Iteration #19
Best Reward: 6.2500000000000036
Completed Iteration #20
Best Reward: 6.2500000000000036
Completed Iteration #21
Best Reward: 6.2500000000000036
Completed Iteration #22
Best Reward: 6.2500000000000036
Completed Iteration #23
Best Reward: 6.2500000000000036
Completed Iteration #24
Best Reward: 6.2500000000000036
Completed Iteration #25
Best Reward: 6.2500000000000036
Completed MCTS Level/Depth: #4
root->6->7->2->8
Best Reward: 6.2500000000000036
Completed Iteration #0
Best Reward: 6.2500000000000036
Completed Iteration #1
Best Reward: 6.2500000000000036
Completed Iteration #2
Best Reward: 6.2500000000000036
Completed Iteration #3
Best Reward: 6.2500000000000036
Completed Iteration #4
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9b00> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 50.00000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 56.25000000000003 10
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 56.25000000000003 10
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 62.50000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 99.99999999999994 20
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 104.1666666666666 21
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 129.16666666666654 31
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 129.16666666666654 33
Completed Iteration #5
Best Reward: 6.2500000000000036
Completed Iteration #6
Best Reward: 6.2500000000000036
Completed Iteration #7
Best Reward: 6.2500000000000036
Completed Iteration #8
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5610f0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bd30> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 56.25000000000003 10
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 62.50000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 62.50000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 68.75000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 106.24999999999994 21
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 110.4166666666666 22
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 135.41666666666654 32
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 135.41666666666654 34
Completed Iteration #9
Best Reward: 6.2500000000000036
Completed Iteration #10
Best Reward: 6.2500000000000036
Completed Iteration #11
Best Reward: 6.2500000000000036
Completed Iteration #12
Best Reward: 6.2500000000000036
Completed Iteration #13
Best Reward: 6.2500000000000036
Completed Iteration #14
Best Reward: 6.2500000000000036
Completed Iteration #15
Best Reward: 6.2500000000000036
Completed Iteration #16
Best Reward: 6.2500000000000036
Completed Iteration #17
Best Reward: 6.2500000000000036
Completed Iteration #18
Best Reward: 6.2500000000000036
Completed Iteration #19
Best Reward: 6.2500000000000036
Completed Iteration #20
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa578eb8> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578b70> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cac8> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b860> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2c18> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 62.50000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 68.75000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 68.75000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 75.00000000000003 13
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 112.49999999999994 22
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 116.6666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 141.66666666666654 33
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 141.66666666666654 35
Completed Iteration #21
Best Reward: 6.2500000000000036
Completed Iteration #22
Best Reward: 6.2500000000000036
Completed Iteration #23
Best Reward: 6.2500000000000036
Completed Iteration #24
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5235c0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523630> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578eb8> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa578b70> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cac8> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b860> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2c18> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 68.75000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 75.00000000000003 13
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 75.00000000000003 13
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 81.25000000000003 14
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 118.74999999999994 23
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 122.9166666666666 24
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 147.91666666666654 34
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 147.91666666666654 36
Completed Iteration #25
Best Reward: 6.2500000000000036
Completed MCTS Level/Depth: #5
root->6->7->2->8->6
Best Reward: 6.2500000000000036
Completed Iteration #0
Best Reward: 6.2500000000000036
Completed Iteration #1
Best Reward: 6.2500000000000036
Completed Iteration #2
Best Reward: 6.2500000000000036
Completed Iteration #3
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 75.00000000000003 13
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 81.25000000000003 14
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 81.25000000000003 14
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 87.50000000000003 15
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 124.99999999999994 24
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 129.1666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 154.16666666666654 35
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 154.16666666666654 37
Completed Iteration #4
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295c0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561e80> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5610f0> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bd30> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 81.25000000000003 14
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 87.50000000000003 15
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 87.50000000000003 15
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 93.75000000000003 16
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 131.24999999999994 25
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 135.4166666666666 26
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 160.41666666666654 36
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 160.41666666666654 38
Completed Iteration #5
Best Reward: 6.2500000000000036
Completed Iteration #6
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa529c50> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578b70> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cac8> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b860> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2c18> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 87.50000000000003 15
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 93.75000000000003 16
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 93.75000000000003 16
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 100.00000000000003 17
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 137.49999999999994 26
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 141.6666666666666 27
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 166.66666666666654 37
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 166.66666666666654 39
Completed Iteration #7
Best Reward: 6.2500000000000036
Completed Iteration #8
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3b38> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bd30> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 93.75000000000003 16
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 100.00000000000003 17
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 100.00000000000003 17
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 106.25000000000003 18
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 143.74999999999994 27
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 147.9166666666666 28
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 172.91666666666654 38
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 172.91666666666654 40
Completed Iteration #9
Best Reward: 6.2500000000000036
Completed Iteration #10
Best Reward: 6.2500000000000036
Completed Iteration #11
Best Reward: 6.2500000000000036
Completed Iteration #12
Best Reward: 6.2500000000000036
Completed Iteration #13
Best Reward: 6.2500000000000036
Completed Iteration #14
Best Reward: 6.2500000000000036
Completed Iteration #15
Best Reward: 6.2500000000000036
Completed Iteration #16
Best Reward: 6.2500000000000036
Completed Iteration #17
Best Reward: 6.2500000000000036
Completed Iteration #18
Best Reward: 6.2500000000000036
Completed Iteration #19
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa523d30> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bd30> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 100.00000000000003 17
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 106.25000000000003 18
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 106.25000000000003 18
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 112.50000000000003 19
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 149.99999999999994 28
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 154.1666666666666 29
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 179.16666666666654 39
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 179.16666666666654 41
Completed Iteration #20
Best Reward: 6.2500000000000036
Completed Iteration #21
Best Reward: 6.2500000000000036
Completed Iteration #22
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2780> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf240> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a90> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 43.75000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 106.25000000000003 18
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 112.50000000000003 19
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 112.50000000000003 19
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 118.75000000000003 20
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 156.24999999999994 29
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 160.4166666666666 30
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 185.41666666666654 40
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 185.41666666666654 42
Completed Iteration #23
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa5297f0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578b70> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cac8> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b860> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2c18> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 112.50000000000003 19
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 118.75000000000003 20
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 118.75000000000003 20
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 125.00000000000003 21
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 162.49999999999994 30
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 166.6666666666666 31
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 191.66666666666654 41
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 191.66666666666654 43
Completed Iteration #24
Best Reward: 6.2500000000000036
Completed Iteration #25
Best Reward: 6.2500000000000036
Completed MCTS Level/Depth: #6
root->6->7->2->8->6->8
Best Reward: 6.2500000000000036
Completed Iteration #0
Best Reward: 6.2500000000000036
Completed Iteration #1
Best Reward: 6.2500000000000036
Completed Iteration #2
Best Reward: 6.2500000000000036
coverage_call_count 900
Completed Iteration #3
Best Reward: 6.2500000000000036
Completed Iteration #4
Best Reward: 6.2500000000000036
Completed Iteration #5
Best Reward: 6.2500000000000036
Completed Iteration #6
Best Reward: 6.2500000000000036
Completed Iteration #7
Best Reward: 6.2500000000000036
Completed Iteration #8
Best Reward: 6.2500000000000036
Completed Iteration #9
Best Reward: 6.2500000000000036
Completed Iteration #10
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0940> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0438> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295c0> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561e80> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5610f0> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bd30> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 118.75000000000003 20
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 125.00000000000003 21
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 125.00000000000003 21
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 131.25000000000003 22
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 168.74999999999994 31
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 172.9166666666666 32
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 197.91666666666654 42
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 197.91666666666654 44
Completed Iteration #11
Best Reward: 6.2500000000000036
Completed Iteration #12
Best Reward: 6.2500000000000036
Completed Iteration #13
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8d30> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8da0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5235c0> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa523630> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa578eb8> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa578b70> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cac8> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b860> 37.50000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2c18> 43.75000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 125.00000000000003 21
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 131.25000000000003 22
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 131.25000000000003 22
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 137.50000000000003 23
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 174.99999999999994 32
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 179.1666666666666 33
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 204.16666666666654 43
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 204.16666666666654 45
Completed Iteration #14
Best Reward: 6.2500000000000036
Completed Iteration #15
Best Reward: 6.2500000000000036
Completed Iteration #16
Best Reward: 6.2500000000000036
Completed Iteration #17
Best Reward: 6.2500000000000036
Completed Iteration #18
Best Reward: 6.2500000000000036
Completed Iteration #19
Best Reward: 6.2500000000000036
Completed Iteration #20
Best Reward: 6.2500000000000036
Completed Iteration #21
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d09b0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 43.75000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 50.00000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 131.25000000000003 22
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 137.50000000000003 23
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 137.50000000000003 23
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 143.75000000000003 24
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 181.24999999999994 33
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 185.4166666666666 34
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 210.41666666666654 44
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 210.41666666666654 46
Completed Iteration #22
Best Reward: 6.2500000000000036
Completed Iteration #23
Best Reward: 6.2500000000000036
Completed Iteration #24
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa529c88> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f60> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561400> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf240> 25.000000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a90> 31.250000000000018 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 50.00000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 56.25000000000003 10
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 137.50000000000003 23
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 143.75000000000003 24
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 143.75000000000003 24
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 150.00000000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 187.49999999999994 34
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 191.6666666666666 35
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 216.66666666666654 45
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 216.66666666666654 47
Completed Iteration #25
Best Reward: 6.2500000000000036
Completed MCTS Level/Depth: #7
root->6->7->2->8->6->8->2
Best Reward: 6.2500000000000036
Completed Iteration #0
Best Reward: 6.2500000000000036
Completed Iteration #1
Best Reward: 6.2500000000000036
Completed Iteration #2
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8e10> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8ef0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d09b0> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 56.25000000000003 10
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 62.50000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 143.75000000000003 24
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 150.00000000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 150.00000000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 156.25000000000003 26
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 193.74999999999994 35
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 197.9166666666666 36
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 222.91666666666654 46
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 222.91666666666654 48
Completed Iteration #3
Best Reward: 6.2500000000000036
Completed Iteration #4
Best Reward: 6.2500000000000036
Completed Iteration #5
Best Reward: 6.2500000000000036
Completed Iteration #6
Best Reward: 6.2500000000000036
Completed Iteration #7
Best Reward: 6.2500000000000036
Completed Iteration #8
Best Reward: 6.2500000000000036
Completed Iteration #9
Best Reward: 6.2500000000000036
Completed Iteration #10
Best Reward: 6.2500000000000036
Completed Iteration #11
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa4eceb8> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8ef0> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d09b0> 18.75000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 62.50000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 68.75000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 150.00000000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 156.25000000000003 26
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 156.25000000000003 26
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 162.50000000000003 27
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 199.99999999999994 36
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 204.1666666666666 37
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 229.16666666666654 47
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 229.16666666666654 49
Completed Iteration #12
Best Reward: 6.2500000000000036
Completed Iteration #13
Best Reward: 6.2500000000000036
Completed Iteration #14
Best Reward: 6.2500000000000036
Completed Iteration #15
Best Reward: 6.2500000000000036
Completed Iteration #16
Best Reward: 6.2500000000000036
Completed Iteration #17
Best Reward: 6.2500000000000036
Completed Iteration #18
Best Reward: 6.2500000000000036
Completed Iteration #19
Best Reward: 6.2500000000000036
Completed Iteration #20
Best Reward: 6.2500000000000036
Completed Iteration #21
Best Reward: 6.2500000000000036
Completed Iteration #22
Best Reward: 6.2500000000000036
Completed Iteration #23
Best Reward: 6.2500000000000036
Reward: 6.2500000000000036
backprop <src.mcts.MCTS_Node object at 0x7f28aa488860> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4888d0> 6.2500000000000036 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9b00> 12.500000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 68.75000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 75.00000000000003 13
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9b0> 156.25000000000003 26
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 162.50000000000003 27
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 162.50000000000003 27
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 168.75000000000003 28
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 206.24999999999994 37
backprop <src.mcts.MCTS_Node object at 0x7f28aab17ba8> 210.4166666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 235.41666666666654 48
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195f8> 235.41666666666654 50
Completed Iteration #24
Best Reward: 6.2500000000000036
Completed Iteration #25
Best Reward: 6.2500000000000036
Completed MCTS Level/Depth: #8
root->6->7->2->8->6->8->2->9
Best Reward: 6.2500000000000036
iteration: 12
found coverage increase 6.2500000000000036
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4883c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4932e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4932e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4932e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4932e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4931d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 22
Completed Iteration #24
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5784e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa578630> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5290f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5231d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5231d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5292e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5298d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa788d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa788d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78e80> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5230f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5787f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5290f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5235c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5235c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa198d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19860> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529278> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3978> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa499e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa499e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5787f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5787f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa499e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5787f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2beb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c95f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c95f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa963c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa963c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab172e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab172e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e48> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab687f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab177b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab17128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa962b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab803c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab803c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab17710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf40f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab762e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab804e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab801d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4080> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab98358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab89358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab986a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab986a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98c18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c094278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab899b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0faef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0faef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab680b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d438> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1493c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1493c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1491d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1491d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab98278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1249b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1249b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1186a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1810b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1810b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0945c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0945c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c07ceb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c149a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 35.41666666666667
coverage_call_count 2000
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c47f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4208> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29400864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0cabe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffdd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5297f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2550> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a39b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab17748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 2300
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab983c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab175c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4935f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab895f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa781d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa781d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3198> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa518> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4939e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 8
Completed Iteration #12
Best Reward: 0
coverage_call_count 2500
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab687f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab687f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0896d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab892e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac42b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab80780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1811d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1492b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1189b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1812b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 5
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 6
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 7
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 8
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 9
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 10
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a196d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19860> 0.0 11
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab765c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab765c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab765c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 2800
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29040ddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f29040ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29040ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4889e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01dd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5610b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5610b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5615c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d81d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 3000
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f289532ac18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952efb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952806d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952d99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952efe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef630> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecd30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952aee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952526a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952526a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952527b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952439b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 3200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc908> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aeac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252b00> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945807f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945dc0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945ea3c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28945a25f8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 35.41666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 9
Completed Iteration #15
Best Reward: 0
coverage_call_count 3300
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945494a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549c50> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c07cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa523550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab242b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29040dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f29040ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab242b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5239b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 35.41666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 2.0833333333333286 5
Completed Iteration #5
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 2.0833333333333286 6
Completed Iteration #6
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 2.0833333333333286 7
Completed Iteration #7
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 2.0833333333333286 8
Completed Iteration #8
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 2.0833333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 2.0833333333333286 9
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 2.0833333333333286 10
Completed Iteration #11
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 2.0833333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 2.0833333333333286 11
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c1812e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 4.166666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 4.166666666666657 12
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c13a2e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a7f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812e8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 6.249999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 6.249999999999986 8
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 13
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 6.249999999999986 9
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 14
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 6.249999999999986 10
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 15
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 16
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a2e8> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c13a7f0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1812e8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 6.249999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 6.249999999999986 11
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 17
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #0
root
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 6.249999999999986 12
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 18
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 6.249999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 19
Completed Iteration #1
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 6.249999999999986 14
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 20
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 6.249999999999986 15
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 21
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 6.249999999999986 16
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 6.249999999999986 22
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d0b8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d908> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812e8> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 8.333333333333314 8
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 8.333333333333314 17
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 8.333333333333314 23
Completed Iteration #6
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa488860> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a940> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a2e8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f289c13a7f0> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1812e8> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 10.416666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 10.416666666666643 18
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 10.416666666666643 24
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 12.499999999999972 10
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 12.499999999999972 19
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 12.499999999999972 25
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 12.499999999999972 11
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 12.499999999999972 20
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 12.499999999999972 26
Completed Iteration #13
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 12.499999999999972 21
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 12.499999999999972 27
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c18> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 12.499999999999972 9
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 14.5833333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 14.5833333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 14.5833333333333 28
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f2894549518> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 16.66666666666663 23
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 16.66666666666663 29
Completed Iteration #16
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 14.5833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 16.66666666666663 24
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 16.66666666666663 30
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 16.66666666666663 25
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 16.66666666666663 31
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 16.66666666666663 26
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 16.66666666666663 32
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549518> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 16.66666666666663 27
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 16.66666666666663 33
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 16.66666666666663 28
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 16.66666666666663 34
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 14.5833333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 16.66666666666663 14
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 18.749999999999957 29
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 18.749999999999957 35
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 18.749999999999957 30
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 18.749999999999957 36
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #1
root->0
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a20> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 16.66666666666663 11
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 18.749999999999957 15
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 20.833333333333286 31
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 20.833333333333286 37
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c0894a8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 18.749999999999957 12
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 20.833333333333286 16
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 22.916666666666615 32
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 22.916666666666615 38
Completed Iteration #4
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1812e8> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 18.749999999999957 13
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 20.833333333333286 17
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 22.916666666666615 33
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 22.916666666666615 39
Completed Iteration #5
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c1249e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a20> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 20.833333333333286 14
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 22.916666666666615 18
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 24.999999999999943 34
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 24.999999999999943 40
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa488358> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c05eac8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a2e8> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f289c13a7f0> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1812e8> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 22.916666666666615 15
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 24.999999999999943 19
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 27.08333333333327 35
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 27.08333333333327 41
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4e48> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1817f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 27.08333333333327 20
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 29.1666666666666 36
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 29.1666666666666 42
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aabe46a0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 24.999999999999943 16
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 29.1666666666666 21
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 31.24999999999993 37
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 31.24999999999993 43
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28a1a199b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488080> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 31.24999999999993 22
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 33.33333333333326 38
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 33.33333333333326 44
Completed Iteration #13
Best Reward: 2.0833333333333286
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a199b0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa488080> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 31.24999999999993 23
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 33.33333333333326 39
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 33.33333333333326 45
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c18> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 24.999999999999943 17
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 31.24999999999993 24
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 33.33333333333326 40
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 33.33333333333326 46
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f2894549ba8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 27.08333333333327 18
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 33.33333333333326 25
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 35.416666666666586 41
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 35.416666666666586 47
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28a1a016a0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24a58> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4e48> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1817f0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 35.416666666666586 26
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 37.499999999999915 42
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 37.499999999999915 48
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3ba8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3630> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a199b0> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa488080> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 37.499999999999915 27
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 39.58333333333324 43
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 39.58333333333324 49
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #2
root->0->17
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c094e80> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4198> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549ba8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 29.1666666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 39.58333333333324 28
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 41.66666666666657 44
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 41.66666666666657 50
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c0944a8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4198> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f2894549ba8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 31.24999999999993 20
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 41.66666666666657 29
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 43.7499999999999 45
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 43.7499999999999 51
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488358> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c05eac8> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c13a2e8> 6.249999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7f289c13a7f0> 6.249999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7f289c1812e8> 10.416666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 31.24999999999993 21
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 41.66666666666657 30
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 43.7499999999999 46
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 43.7499999999999 52
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19ac8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0944a8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4198> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f2894549ba8> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 33.33333333333326 22
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 43.7499999999999 31
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 45.83333333333323 47
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 45.83333333333323 53
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b278> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19ac8> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0944a8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4198> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f2894549ba8> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 33.33333333333326 23
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 43.7499999999999 32
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 45.83333333333323 48
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 45.83333333333323 54
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49b70> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49588> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1249e8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012e8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a20> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 35.416666666666586 24
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 45.83333333333323 33
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 47.91666666666656 49
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 47.91666666666656 55
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c094198> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4518> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 12.499999999999972 9
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 37.499999999999915 25
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 47.91666666666656 34
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 49.999999999999886 50
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 49.999999999999886 56
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49b70> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49588> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1249e8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012e8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a20> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 37.499999999999915 26
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 47.91666666666656 35
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 49.999999999999886 51
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 49.999999999999886 57
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #3
root->0->17->8
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4748> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094198> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4518> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 14.5833333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 39.58333333333324 27
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 49.999999999999886 36
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 52.083333333333215 52
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 52.083333333333215 58
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c18> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 14.5833333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 39.58333333333324 28
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 49.999999999999886 37
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 52.083333333333215 53
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 52.083333333333215 59
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aab76080> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab760f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe46a0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 6.249999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 16.66666666666663 12
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 41.66666666666657 29
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 52.083333333333215 38
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 54.16666666666654 54
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 54.16666666666654 60
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a128> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4518> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 18.749999999999957 13
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 43.7499999999999 30
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 54.16666666666654 39
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 56.24999999999987 55
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 56.24999999999987 61
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0894a8> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 18.749999999999957 14
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 43.7499999999999 31
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 54.16666666666654 40
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 56.24999999999987 56
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 56.24999999999987 62
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c0faef0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4908> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a128> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4518> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 12.499999999999972 8
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 20.833333333333286 15
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 45.83333333333323 32
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 56.24999999999987 41
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 58.3333333333332 57
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 58.3333333333332 63
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3c18> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094438> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76080> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab760f0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabe46a0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f289c124438> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 22.916666666666615 16
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 47.91666666666656 33
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 58.3333333333332 42
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 60.41666666666653 58
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 60.41666666666653 64
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 14.5833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 24.999999999999943 17
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 49.999999999999886 34
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 60.41666666666653 43
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 62.49999999999986 59
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 62.49999999999986 65
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0faef0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4908> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a128> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4518> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 14.5833333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 24.999999999999943 18
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 49.999999999999886 35
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 60.41666666666653 44
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 62.49999999999986 60
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 62.49999999999986 66
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #4
root->0->17->8->4
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbb38> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89eb8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 12.499999999999972 8
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 16.66666666666663 11
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 27.08333333333327 19
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 52.083333333333215 36
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 62.49999999999986 45
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 64.58333333333319 61
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 64.58333333333319 67
Completed Iteration #7
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aab89978> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb5f8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbb38> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab89eb8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 14.5833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 18.749999999999957 12
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 29.1666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 54.16666666666654 37
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 64.58333333333319 46
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 66.66666666666652 62
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 66.66666666666652 68
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b28d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 20.833333333333286 13
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 31.24999999999993 21
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 56.24999999999987 38
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 66.66666666666652 47
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 68.74999999999984 63
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 68.74999999999984 69
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c0faf98> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ac8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b28d0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 22.916666666666615 14
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 33.33333333333326 22
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 58.3333333333332 39
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 68.74999999999984 48
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 70.83333333333317 64
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 70.83333333333317 70
Completed Iteration #13
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aabf47b8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89eb8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 16.66666666666663 10
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 24.999999999999943 15
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 35.416666666666586 23
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 60.41666666666653 40
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 70.83333333333317 49
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 72.9166666666665 65
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 72.9166666666665 71
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa4937b8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493ef0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 18.749999999999957 11
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 27.08333333333327 16
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 37.499999999999915 24
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 62.49999999999986 41
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 72.9166666666665 50
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 74.99999999999983 66
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 74.99999999999983 72
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495c0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ac8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b28d0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 29.1666666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 39.58333333333324 25
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 64.58333333333319 42
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 74.99999999999983 51
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 77.08333333333316 67
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 77.08333333333316 73
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4748> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c094198> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4518> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f289c181080> 18.749999999999957 12
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 29.1666666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 39.58333333333324 26
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 64.58333333333319 43
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 74.99999999999983 52
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 77.08333333333316 68
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 77.08333333333316 74
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b29e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5ad30> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0894a8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 31.24999999999993 19
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 41.66666666666657 27
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 66.66666666666652 44
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 77.08333333333316 53
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 79.16666666666649 69
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 79.16666666666649 75
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #5
root->0->17->8->4->2
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5785f8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa529400> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495c0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ac8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b28d0> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 33.33333333333326 20
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 43.7499999999999 28
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 68.74999999999984 45
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 79.16666666666649 54
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 81.24999999999982 70
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 81.24999999999982 76
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf390> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d93c8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5785f8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa529400> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495c0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ac8> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b28d0> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 35.416666666666586 21
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 45.83333333333323 29
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 70.83333333333317 46
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 81.24999999999982 55
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 83.33333333333314 71
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 83.33333333333314 77
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 37.499999999999915 22
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 47.91666666666656 30
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 72.9166666666665 47
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 83.33333333333314 56
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 85.41666666666647 72
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 85.41666666666647 78
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7048> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7c50> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 16.66666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 39.58333333333324 23
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 49.999999999999886 31
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 74.99999999999983 48
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 85.41666666666647 57
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 87.4999999999998 73
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 87.4999999999998 79
Completed Iteration #11
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa493cf8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 18.749999999999957 10
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 41.66666666666657 24
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 52.083333333333215 32
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 77.08333333333316 49
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 87.4999999999998 58
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 89.58333333333313 74
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 89.58333333333313 80
Completed Iteration #12
Best Reward: 2.0833333333333286
coverage_call_count 3500
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aab98438> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96160> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493cf8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 16.66666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 20.833333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 43.7499999999999 25
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 54.16666666666654 33
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 79.16666666666649 50
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 89.58333333333313 59
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 91.66666666666646 75
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 91.66666666666646 81
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 18.749999999999957 10
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 22.916666666666615 12
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 45.83333333333323 26
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 56.24999999999987 34
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 81.24999999999982 51
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 91.66666666666646 60
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 93.74999999999979 76
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 93.74999999999979 82
Completed Iteration #16
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9ac8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9e10> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 20.833333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 24.999999999999943 13
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 47.91666666666656 27
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 58.3333333333332 35
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 83.33333333333314 52
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 93.74999999999979 61
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 95.83333333333312 77
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 95.83333333333312 83
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfa58> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4933c8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 22.916666666666615 12
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 27.08333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 49.999999999999886 28
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 60.41666666666653 36
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 85.41666666666647 53
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 95.83333333333312 62
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 97.91666666666644 78
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 97.91666666666644 84
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 24.999999999999943 13
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 29.1666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 52.083333333333215 29
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 62.49999999999986 37
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 87.4999999999998 54
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 97.91666666666644 63
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 99.99999999999977 79
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 99.99999999999977 85
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #6
root->0->17->8->4->2->14
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c0940b8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb11d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 27.08333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 31.24999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 54.16666666666654 30
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 64.58333333333319 38
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 89.58333333333313 55
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 99.99999999999977 64
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 102.0833333333331 80
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 102.0833333333331 86
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb11d0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 29.1666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 33.33333333333326 17
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 56.24999999999987 31
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 66.66666666666652 39
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 91.66666666666646 56
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 102.0833333333331 65
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 104.16666666666643 81
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 104.16666666666643 87
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86668> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d93c8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5785f8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa529400> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa495c0> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ac8> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b28d0> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 31.24999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 35.416666666666586 18
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 58.3333333333332 32
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 68.74999999999984 40
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 93.74999999999979 57
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 104.16666666666643 66
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 106.24999999999976 82
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 106.24999999999976 88
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8940> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 33.33333333333326 17
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 37.499999999999915 19
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 60.41666666666653 33
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 70.83333333333317 41
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 95.83333333333312 58
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 106.24999999999976 67
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 108.33333333333309 83
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 108.33333333333309 89
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9ac8> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9e10> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 33.33333333333326 18
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 37.499999999999915 20
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 60.41666666666653 34
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 70.83333333333317 42
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 95.83333333333312 59
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 106.24999999999976 68
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 108.33333333333309 84
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 108.33333333333309 90
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19a20> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1ac8> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b28d0> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 35.416666666666586 19
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 39.58333333333324 21
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 62.49999999999986 35
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 72.9166666666665 43
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 97.91666666666644 60
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 108.33333333333309 69
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 110.41666666666642 85
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 110.41666666666642 91
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9550> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c92e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9ac8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9e10> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa578cc0> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 37.499999999999915 20
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 41.66666666666657 22
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 64.58333333333319 36
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 74.99999999999983 44
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 99.99999999999977 61
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 110.41666666666642 70
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 112.49999999999974 86
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 112.49999999999974 92
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #7
root->0->17->8->4->2->14->2
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa488e10> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2d30> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 16.66666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 39.58333333333324 21
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 43.7499999999999 23
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 66.66666666666652 37
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 77.08333333333316 45
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 102.0833333333331 62
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 112.49999999999974 71
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 114.58333333333307 87
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 114.58333333333307 93
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8be0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b390> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 18.749999999999957 10
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 41.66666666666657 22
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 45.83333333333323 24
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 68.74999999999984 38
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 79.16666666666649 46
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 104.16666666666643 63
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 114.58333333333307 72
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 116.6666666666664 88
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 116.6666666666664 94
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa56ccf8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0b8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8940> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 16.66666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 20.833333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 43.7499999999999 23
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 47.91666666666656 25
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 70.83333333333317 39
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 81.24999999999982 47
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 106.24999999999976 64
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 116.6666666666664 73
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 118.74999999999973 89
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 118.74999999999973 95
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff940> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff898> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488e10> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2d30> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 18.749999999999957 10
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 22.916666666666615 12
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 45.83333333333323 24
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 49.999999999999886 26
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 72.9166666666665 40
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 83.33333333333314 48
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 108.33333333333309 65
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 118.74999999999973 74
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 120.83333333333306 90
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 120.83333333333306 96
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c15eb38> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b390> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 24.999999999999943 13
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 47.91666666666656 25
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 52.083333333333215 27
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 74.99999999999983 41
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 85.41666666666647 49
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 110.41666666666642 66
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 120.83333333333306 75
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 122.91666666666639 91
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 122.91666666666639 97
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff5f8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9630> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15eb38> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b390> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 27.08333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 49.999999999999886 26
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 54.16666666666654 28
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 77.08333333333316 42
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 87.4999999999998 50
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 112.49999999999974 67
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 122.91666666666639 76
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 124.99999999999972 92
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 124.99999999999972 98
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca080> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb0b8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8940> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 20.833333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 29.1666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 52.083333333333215 27
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 56.24999999999987 29
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 79.16666666666649 43
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 89.58333333333313 51
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 114.58333333333307 68
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 124.99999999999972 77
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 127.08333333333304 93
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 127.08333333333304 99
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa578e80> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493780> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98438> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96160> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa493cf8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 22.916666666666615 12
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 31.24999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 54.16666666666654 28
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 58.3333333333332 30
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 81.24999999999982 44
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 91.66666666666646 52
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 116.6666666666664 69
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 127.08333333333304 78
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 129.16666666666637 94
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 129.16666666666637 100
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9c88> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c630> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabb11d0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bb38> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 24.999999999999943 13
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 33.33333333333326 17
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 56.24999999999987 29
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 60.41666666666653 31
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 83.33333333333314 45
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 93.74999999999979 53
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 118.74999999999973 70
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 129.16666666666637 79
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 131.24999999999972 95
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 131.24999999999972 101
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f28aaa862e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96160> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa493cf8> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f28945b6198> 27.08333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7f289c1241d0> 35.416666666666586 18
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 58.3333333333332 30
backprop <src.mcts.MCTS_Node object at 0x7f28aab765f8> 62.49999999999986 32
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 85.41666666666647 46
backprop <src.mcts.MCTS_Node object at 0x7f289c13ab38> 95.83333333333312 54
backprop <src.mcts.MCTS_Node object at 0x7f289c181048> 120.83333333333306 71
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5a8d0> 131.24999999999972 80
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 133.33333333333303 96
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8be0> 133.33333333333303 102
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #8
root->0->17->8->4->2->14->2->0
Best Reward: 2.0833333333333286
iteration: 106
found coverage increase 2.0833333333333286
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2993b31208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2993b31208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c47f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff390> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa861d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a21d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa867f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952efeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28952ef438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5619e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 3700
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952efa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952efa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eaa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5616a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ecf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952526d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952804e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952804e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952804e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252550> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab68f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952809e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab684a8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945eab70> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c118860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa861d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952ae400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2be10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 19
Completed Iteration #22
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bda0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb62b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c118978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952436a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccdba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfcd68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d85c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d85c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d85c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc125c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b208> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc21080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc21240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc121d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc12c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b4e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc210f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc21cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc21fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc21dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7d86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7eae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d86a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d86a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8c18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc21940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7eac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc21eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7f81d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb65c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb65c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 4300
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb65c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7af240> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 2.0833333333333286 6
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7af860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7af240> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 2.0833333333333286 7
Completed Iteration #7
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 2.0833333333333286 8
Completed Iteration #8
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7afc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 2.0833333333333286 9
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7afd30> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7462b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7af240> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 4.166666666666657 10
Completed Iteration #11
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 4.166666666666657 6
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 4.166666666666657 11
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f746470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 4.166666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 4.166666666666657 12
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 6.249999999999986 8
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 6.249999999999986 13
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f746c50> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746748> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 8.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 8.333333333333314 14
Completed Iteration #16
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f746f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 8.333333333333314 10
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 8.333333333333314 15
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7502b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f750198> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746c50> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746748> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 10.416666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 10.416666666666643 16
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f750908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f750898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 10.416666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 10.416666666666643 17
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 10.416666666666643 18
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f750c50> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746080> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7afd30> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7462b0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7af240> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 12.499999999999972 13
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 12.499999999999972 19
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #0
root
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f750c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 12.499999999999972 14
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 12.499999999999972 20
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f75c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7af240> 6.249999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 12.499999999999972 15
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 12.499999999999972 21
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f746278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7502b0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f750198> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746c50> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746748> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 6.249999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 12.499999999999972 16
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 12.499999999999972 22
Completed Iteration #8
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f750c50> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746080> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7afd30> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7462b0> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7af240> 6.249999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 12.499999999999972 17
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 12.499999999999972 23
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7504e0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 14.5833333333333 18
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 14.5833333333333 24
Completed Iteration #11
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f750f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f750ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 14.5833333333333 19
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 14.5833333333333 25
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f75c898> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f750e48> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7504e0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 16.66666666666663 20
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 16.66666666666663 26
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f75cf98> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7462b0> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7af240> 8.333333333333314 8
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 18.749999999999957 21
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 18.749999999999957 27
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f750630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75cf98> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7462b0> 6.249999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7f286f7af240> 8.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 18.749999999999957 22
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 18.749999999999957 28
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 18.749999999999957 23
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 18.749999999999957 29
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 18.749999999999957 24
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 18.749999999999957 30
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f750198> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746c50> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746748> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 10.416666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 18.749999999999957 25
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 18.749999999999957 31
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7af240> 8.333333333333314 10
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 18.749999999999957 26
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 18.749999999999957 32
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #1
root->2
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f750198> 2.0833333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746c50> 4.166666666666657 6
backprop <src.mcts.MCTS_Node object at 0x7f286f746748> 4.166666666666657 6
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 10.416666666666643 10
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 18.749999999999957 27
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 18.749999999999957 33
Completed Iteration #1
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 12.499999999999972 11
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 20.833333333333286 28
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 20.833333333333286 34
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 14.5833333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 22.916666666666615 29
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 22.916666666666615 35
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f75c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7504e0> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 14.5833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 22.916666666666615 30
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 22.916666666666615 36
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f750278> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f750e48> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7504e0> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 16.66666666666663 14
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 24.999999999999943 31
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 24.999999999999943 37
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7af048> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21940> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 12.499999999999972 8
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 18.749999999999957 15
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 27.08333333333327 32
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 27.08333333333327 38
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286fccd710> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 14.5833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 20.833333333333286 16
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 29.1666666666666 33
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 29.1666666666666 39
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8e80> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78dac8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c898> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f750e48> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7504e0> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 16.66666666666663 10
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 22.916666666666615 17
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 31.24999999999993 34
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 31.24999999999993 40
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7783c8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21940> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 18.749999999999957 11
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 24.999999999999943 18
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 33.33333333333326 35
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 33.33333333333326 41
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 24.999999999999943 19
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 33.33333333333326 36
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 33.33333333333326 42
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc21828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 24.999999999999943 20
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 33.33333333333326 37
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 33.33333333333326 43
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #2
root->2->17
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd710> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 18.749999999999957 12
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 24.999999999999943 21
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 33.33333333333326 38
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 33.33333333333326 44
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f778b70> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7169e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8e80> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f78dac8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f75c898> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f750e48> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7504e0> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 20.833333333333286 13
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 27.08333333333327 22
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 35.416666666666586 39
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 35.416666666666586 45
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f71e358> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e3c8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 22.916666666666615 14
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 29.1666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 37.499999999999915 40
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 37.499999999999915 46
Completed Iteration #11
Best Reward: 2.0833333333333286
coverage_call_count 4400
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f71e8d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e6d8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e358> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e3c8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 24.999999999999943 15
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 31.24999999999993 24
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 39.58333333333324 41
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 39.58333333333324 47
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f75cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7af048> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc21940> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 24.999999999999943 16
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 31.24999999999993 25
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 39.58333333333324 42
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 39.58333333333324 48
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8a58> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 27.08333333333327 17
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 33.33333333333326 26
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 41.66666666666657 43
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 41.66666666666657 49
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f778ac8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778898> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccd710> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286fccda58> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 29.1666666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 35.416666666666586 27
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 43.7499999999999 44
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 43.7499999999999 50
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8a58> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 29.1666666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 35.416666666666586 28
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 43.7499999999999 45
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 43.7499999999999 51
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f746b00> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f716e48> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7783c8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc21940> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 12.499999999999972 8
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 31.24999999999993 20
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 37.499999999999915 29
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 45.83333333333323 46
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 45.83333333333323 52
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8a58> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 31.24999999999993 21
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 37.499999999999915 30
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 45.83333333333323 47
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 45.83333333333323 53
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #3
root->2->17->8
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f71eeb8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e3c8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 14.5833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 33.33333333333326 22
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 39.58333333333324 31
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 47.91666666666656 48
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 47.91666666666656 54
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 16.66666666666663 10
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 35.416666666666586 23
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 41.66666666666657 32
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 49.999999999999886 49
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 49.999999999999886 55
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e8d0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e6d8> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e358> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71e3c8> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 16.66666666666663 11
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 35.416666666666586 24
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 41.66666666666657 33
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 49.999999999999886 50
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 49.999999999999886 56
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6c20f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21940> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 18.749999999999957 12
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 37.499999999999915 25
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 43.7499999999999 34
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 52.083333333333215 51
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 52.083333333333215 57
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6c24a8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 20.833333333333286 13
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 39.58333333333324 26
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 45.83333333333323 35
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 54.16666666666654 52
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 54.16666666666654 58
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f75cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21940> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 20.833333333333286 14
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 39.58333333333324 27
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 45.83333333333323 36
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 54.16666666666654 53
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 54.16666666666654 59
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f750550> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 22.916666666666615 15
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 41.66666666666657 28
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 47.91666666666656 37
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 56.24999999999987 54
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 56.24999999999987 60
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 24.999999999999943 16
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 43.7499999999999 29
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 49.999999999999886 38
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 58.3333333333332 55
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 58.3333333333332 61
Completed Iteration #21
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f736550> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e3c8> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 27.08333333333327 17
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 45.83333333333323 30
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 52.083333333333215 39
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 60.41666666666653 56
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 60.41666666666653 62
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2128> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e3c8> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 29.1666666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 47.91666666666656 31
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 54.16666666666654 40
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 62.49999999999986 57
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 62.49999999999986 63
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2630> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e3c8> 12.499999999999972 8
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 31.24999999999993 19
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 49.999999999999886 32
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 56.24999999999987 41
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 64.58333333333319 58
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 64.58333333333319 64
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #4
root->2->17->8->16
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 33.33333333333326 20
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 52.083333333333215 33
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 58.3333333333332 42
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 66.66666666666652 59
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 66.66666666666652 65
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6df2b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df0f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 35.416666666666586 21
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 54.16666666666654 34
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 60.41666666666653 43
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 68.74999999999984 60
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 68.74999999999984 66
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c24a8> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 12.499999999999972 8
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 35.416666666666586 22
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 54.16666666666654 35
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 60.41666666666653 44
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 68.74999999999984 61
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 68.74999999999984 67
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8240> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 14.5833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 37.499999999999915 23
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 56.24999999999987 36
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 62.49999999999986 45
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 70.83333333333317 62
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 70.83333333333317 68
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f78d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df2b0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6df0f0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 14.5833333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 37.499999999999915 24
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 56.24999999999987 37
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 62.49999999999986 46
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 70.83333333333317 63
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 70.83333333333317 69
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f736080> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df0f0> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 16.66666666666663 11
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 39.58333333333324 25
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 58.3333333333332 38
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 64.58333333333319 47
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 72.9166666666665 64
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 72.9166666666665 70
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f716a20> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7167b8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c24a8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 18.749999999999957 12
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 41.66666666666657 26
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 60.41666666666653 39
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 66.66666666666652 48
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 74.99999999999983 65
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 74.99999999999983 71
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #5
root->2->17->8->16->6
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8ef0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df0f0> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 10.416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 12.499999999999972 8
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 20.833333333333286 13
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 43.7499999999999 27
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 62.49999999999986 40
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 68.74999999999984 49
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 77.08333333333316 66
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 77.08333333333316 72
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 12.499999999999972 9
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 20.833333333333286 14
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 43.7499999999999 28
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 62.49999999999986 41
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 68.74999999999984 50
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 77.08333333333316 67
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 77.08333333333316 73
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 10.416666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 12.499999999999972 10
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 20.833333333333286 15
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 43.7499999999999 29
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 62.49999999999986 42
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 68.74999999999984 51
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 77.08333333333316 68
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 77.08333333333316 74
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f68a080> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 12.499999999999972 10
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 14.5833333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 22.916666666666615 16
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 45.83333333333323 30
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 64.58333333333319 43
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 70.83333333333317 52
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 79.16666666666649 69
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 79.16666666666649 75
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286fccd6a0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc9b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8ef0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6df0f0> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 12.499999999999972 9
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 14.5833333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 16.66666666666663 12
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 24.999999999999943 17
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 47.91666666666656 31
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 66.66666666666652 44
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 72.9166666666665 53
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 81.24999999999982 70
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 81.24999999999982 76
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc21710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc9b0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8ef0> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6df0f0> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 10.416666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 10.416666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 12.499999999999972 10
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 14.5833333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 16.66666666666663 13
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 24.999999999999943 18
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 47.91666666666656 32
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 66.66666666666652 45
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 72.9166666666665 54
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 81.24999999999982 71
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 81.24999999999982 77
Completed Iteration #16
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6e80b8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c27f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df2b0> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6df0f0> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 12.499999999999972 10
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 12.499999999999972 10
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 14.5833333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 16.66666666666663 13
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 18.749999999999957 14
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 27.08333333333327 19
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 49.999999999999886 33
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 68.74999999999984 46
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 74.99999999999983 55
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 83.33333333333314 72
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 83.33333333333314 78
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6df4a8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 18.749999999999957 14
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 20.833333333333286 15
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 29.1666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 52.083333333333215 34
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 70.83333333333317 47
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 77.08333333333316 56
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 85.41666666666647 73
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 85.41666666666647 79
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6842e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684358> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df4a8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 20.833333333333286 15
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 22.916666666666615 16
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 31.24999999999993 21
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 54.16666666666654 35
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 72.9166666666665 48
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 79.16666666666649 57
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 87.4999999999998 74
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 87.4999999999998 80
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6df5c0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df0f0> 12.499999999999972 9
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 14.5833333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 14.5833333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 16.66666666666663 12
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 22.916666666666615 16
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 24.999999999999943 17
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 33.33333333333326 22
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 56.24999999999987 36
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 74.99999999999983 49
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 81.24999999999982 58
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 89.58333333333313 75
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 89.58333333333313 81
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a080> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 22.916666666666615 17
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 24.999999999999943 18
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 33.33333333333326 23
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 56.24999999999987 37
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 74.99999999999983 50
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 81.24999999999982 59
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 89.58333333333313 76
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 89.58333333333313 82
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 22.916666666666615 18
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 24.999999999999943 19
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 33.33333333333326 24
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 56.24999999999987 38
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 74.99999999999983 51
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 81.24999999999982 60
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 89.58333333333313 77
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 89.58333333333313 83
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #6
root->2->17->8->16->6->15
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f716978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6842e8> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f684358> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6df4a8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 22.916666666666615 19
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 24.999999999999943 20
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 33.33333333333326 25
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 56.24999999999987 39
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 74.99999999999983 52
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 81.24999999999982 61
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 89.58333333333313 78
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 89.58333333333313 84
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6842e8> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f286f684358> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6df4a8> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 22.916666666666615 20
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 24.999999999999943 21
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 33.33333333333326 26
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 56.24999999999987 40
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 74.99999999999983 53
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 81.24999999999982 62
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 89.58333333333313 79
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 89.58333333333313 85
Completed Iteration #4
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6df8d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2588> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 18.749999999999957 13
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 24.999999999999943 21
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 27.08333333333327 22
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 35.416666666666586 27
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 58.3333333333332 41
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 77.08333333333316 54
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 83.33333333333314 63
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 91.66666666666646 80
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 91.66666666666646 86
Completed Iteration #5
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8cc0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e82e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a080> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 27.08333333333327 22
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 29.1666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 37.499999999999915 28
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 60.41666666666653 42
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 79.16666666666649 55
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 85.41666666666647 64
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 93.74999999999979 81
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 93.74999999999979 87
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
coverage_call_count 4500
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f68ad30> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68ac88> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df8d0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2588> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 20.833333333333286 14
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 29.1666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 31.24999999999993 24
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 39.58333333333324 29
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 62.49999999999986 43
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 81.24999999999982 56
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 87.4999999999998 65
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 95.83333333333312 82
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 95.83333333333312 88
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 31.24999999999993 24
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 33.33333333333326 25
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 41.66666666666657 30
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 64.58333333333319 44
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 83.33333333333314 57
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 89.58333333333313 66
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 97.91666666666644 83
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 97.91666666666644 89
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f68a5f8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abb70> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8cc0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6e82e8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f68a080> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 33.33333333333326 25
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 35.416666666666586 26
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 43.7499999999999 31
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 66.66666666666652 45
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 85.41666666666647 58
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 91.66666666666646 67
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 99.99999999999977 84
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 99.99999999999977 90
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 33.33333333333326 26
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 35.416666666666586 27
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 43.7499999999999 32
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 66.66666666666652 46
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 85.41666666666647 59
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 91.66666666666646 68
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 99.99999999999977 85
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 99.99999999999977 91
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f7786d8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 35.416666666666586 27
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 37.499999999999915 28
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 45.83333333333323 33
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 68.74999999999984 47
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 87.4999999999998 60
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 93.74999999999979 69
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 102.0833333333331 86
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 102.0833333333331 92
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6846d8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684c50> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7786d8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 37.499999999999915 28
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 39.58333333333324 29
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 47.91666666666656 34
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 70.83333333333317 48
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 89.58333333333313 61
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 95.83333333333312 70
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 104.16666666666643 87
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 104.16666666666643 93
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736080> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6df0f0> 12.499999999999972 10
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 14.5833333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2b00> 14.5833333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f286f716d68> 20.833333333333286 15
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 37.499999999999915 29
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 39.58333333333324 30
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 47.91666666666656 35
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 70.83333333333317 49
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 89.58333333333313 62
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 95.83333333333312 71
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 104.16666666666643 88
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 104.16666666666643 94
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab390> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 39.58333333333324 30
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 41.66666666666657 31
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 49.999999999999886 36
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 72.9166666666665 50
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 91.66666666666646 63
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 97.91666666666644 72
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 106.24999999999976 89
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 106.24999999999976 95
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #7
root->2->17->8->16->6->15->7
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab390> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 8.333333333333314 6
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 39.58333333333324 31
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 41.66666666666657 32
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 49.999999999999886 37
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 72.9166666666665 51
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 91.66666666666646 64
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 97.91666666666644 73
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 106.24999999999976 90
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 106.24999999999976 96
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab390> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 6.249999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 39.58333333333324 32
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 41.66666666666657 33
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 49.999999999999886 38
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 72.9166666666665 52
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 91.66666666666646 65
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 97.91666666666644 74
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 106.24999999999976 91
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 106.24999999999976 97
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f650630> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6506a0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6846d8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f684c50> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7786d8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 8.333333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 10.416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 41.66666666666657 33
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 43.7499999999999 34
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 52.083333333333215 39
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 74.99999999999983 53
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 93.74999999999979 66
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 99.99999999999977 75
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 108.33333333333309 92
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 108.33333333333309 98
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7786d8> 6.249999999999986 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 8.333333333333314 8
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 10.416666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 41.66666666666657 34
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 43.7499999999999 35
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 52.083333333333215 40
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 74.99999999999983 54
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 93.74999999999979 67
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 99.99999999999977 76
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 108.33333333333309 93
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 108.33333333333309 99
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6506a0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6846d8> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f684c50> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7786d8> 6.249999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 8.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 10.416666666666643 10
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 41.66666666666657 35
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 43.7499999999999 36
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 52.083333333333215 41
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 74.99999999999983 55
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 93.74999999999979 68
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 99.99999999999977 77
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 108.33333333333309 94
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 108.33333333333309 100
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f68a860> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 10.416666666666643 10
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 12.499999999999972 11
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 43.7499999999999 36
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 45.83333333333323 37
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 54.16666666666654 42
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 77.08333333333316 56
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 95.83333333333312 69
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 102.0833333333331 78
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 110.41666666666642 95
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 110.41666666666642 101
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6506a0> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6846d8> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f286f684c50> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7786d8> 6.249999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 10.416666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 12.499999999999972 12
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 43.7499999999999 37
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 45.83333333333323 38
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 54.16666666666654 43
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 77.08333333333316 57
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 95.83333333333312 70
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 102.0833333333331 79
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 110.41666666666642 96
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 110.41666666666642 102
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab390> 2.0833333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 10.416666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 12.499999999999972 13
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 43.7499999999999 38
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 45.83333333333323 39
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 54.16666666666654 44
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 77.08333333333316 58
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 95.83333333333312 71
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 102.0833333333331 80
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 110.41666666666642 97
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 110.41666666666642 103
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 12.499999999999972 13
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 14.5833333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 45.83333333333323 39
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 47.91666666666656 40
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 56.24999999999987 45
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 79.16666666666649 59
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 97.91666666666644 72
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 104.16666666666643 81
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 112.49999999999974 98
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 112.49999999999974 104
Completed Iteration #21
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f66b278> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66b0b8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 14.5833333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 16.66666666666663 15
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 47.91666666666656 40
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 49.999999999999886 41
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 58.3333333333332 46
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 81.24999999999982 60
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 99.99999999999977 73
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 106.24999999999976 82
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 114.58333333333307 99
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 114.58333333333307 105
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f66b780> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 16.66666666666663 15
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 18.749999999999957 16
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 49.999999999999886 41
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 52.083333333333215 42
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 60.41666666666653 47
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 83.33333333333314 61
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 102.0833333333331 74
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 108.33333333333309 83
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 116.6666666666664 100
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 116.6666666666664 106
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a860> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 16.66666666666663 16
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 18.749999999999957 17
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 49.999999999999886 42
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 52.083333333333215 43
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 60.41666666666653 48
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 83.33333333333314 62
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 102.0833333333331 75
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 108.33333333333309 84
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 116.6666666666664 101
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 116.6666666666664 107
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f286f6b65c0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7364e0> 18.749999999999957 17
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab278> 20.833333333333286 18
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 52.083333333333215 43
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 54.16666666666654 44
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 62.49999999999986 49
backprop <src.mcts.MCTS_Node object at 0x7f286fc12940> 85.41666666666647 63
backprop <src.mcts.MCTS_Node object at 0x7f286f746400> 104.16666666666643 76
backprop <src.mcts.MCTS_Node object at 0x7f286f746828> 110.41666666666642 85
backprop <src.mcts.MCTS_Node object at 0x7f286f78de10> 118.74999999999973 102
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6940> 118.74999999999973 108
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #8
root->2->17->8->16->6->15->7->10
Best Reward: 2.0833333333333286
iteration: 136
found coverage increase 2.0833333333333286
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6027b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6029e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6029e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6020f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 39.58333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60edd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1db320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1db780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1db828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1db5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f60e518> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f62cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60ebe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1db470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6b67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1c0cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f736208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f66bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f62cba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db4a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1c03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18feb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f147160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f147588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f147748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b32e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 39.58333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6507f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6505c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f650550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f19b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6507f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6505c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f19b2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f736a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f736198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7369b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7369b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f736d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f716320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f716780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895280780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f716518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f716eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f716630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f716550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7afbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f716a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7afef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e7b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 39.58333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f75c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f75cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7f286f75c2e8> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca58> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 2.083333333333343 5
Completed Iteration #5
Best Reward: 2.083333333333343
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f75c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca58> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 2.083333333333343 6
Completed Iteration #6
Best Reward: 2.083333333333343
Completed Iteration #7
Best Reward: 2.083333333333343
Completed Iteration #8
Best Reward: 2.083333333333343
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7f286f75ce10> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c828> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c2e8> 4.166666666666686 3
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca58> 4.166666666666686 4
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 4.166666666666686 7
Completed Iteration #9
Best Reward: 2.083333333333343
Completed Iteration #10
Best Reward: 2.083333333333343
Completed Iteration #11
Best Reward: 2.083333333333343
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f716588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75ce10> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f75c828> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f75c2e8> 4.166666666666686 4
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca58> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 4.166666666666686 8
Completed Iteration #12
Best Reward: 2.083333333333343
Completed Iteration #13
Best Reward: 2.083333333333343
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 8.333333333333357 9
Completed Iteration #14
Best Reward: 4.166666666666671
Completed Iteration #15
Best Reward: 4.166666666666671
Completed Iteration #16
Best Reward: 4.166666666666671
Completed Iteration #17
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 8.333333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 12.500000000000028 10
Completed Iteration #18
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f75ce48> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c080> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 12.500000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 16.6666666666667 11
Completed Iteration #19
Best Reward: 4.166666666666671
Completed Iteration #20
Best Reward: 4.166666666666671
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 16.6666666666667 12
Completed Iteration #21
Best Reward: 4.166666666666671
Completed Iteration #22
Best Reward: 4.166666666666671
Completed Iteration #23
Best Reward: 4.166666666666671
Completed Iteration #24
Best Reward: 4.166666666666671
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7af588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c080> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 8.333333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 12.500000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 16.6666666666667 13
Completed Iteration #25
Best Reward: 4.166666666666671
Completed MCTS Level/Depth: #0
root
Best Reward: 4.166666666666671
Completed Iteration #0
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f2895280550> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f2895280630> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75ce48> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f75c080> 8.333333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 12.500000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 16.666666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 20.83333333333337 14
Completed Iteration #1
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 20.833333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 25.000000000000043 15
Completed Iteration #2
Best Reward: 4.166666666666671
Completed Iteration #3
Best Reward: 4.166666666666671
Completed Iteration #4
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0f0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c080> 12.500000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 16.666666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 25.00000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 29.166666666666714 16
Completed Iteration #5
Best Reward: 4.166666666666671
Completed Iteration #6
Best Reward: 4.166666666666671
Completed Iteration #7
Best Reward: 4.166666666666671
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7f286f71ee48> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c0b8> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0f0> 6.250000000000014 3
backprop <src.mcts.MCTS_Node object at 0x7f286f75c080> 14.583333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 18.75000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 27.08333333333337 10
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 31.250000000000057 17
Completed Iteration #8
Best Reward: 4.166666666666671
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7f286f684d68> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684f28> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71ee48> 4.166666666666686 3
backprop <src.mcts.MCTS_Node object at 0x7f286f75c0b8> 4.166666666666686 3
backprop <src.mcts.MCTS_Node object at 0x7f286f71e0f0> 8.333333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f286f75c080> 16.6666666666667 7
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 20.83333333333337 8
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 29.166666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 33.3333333333334 18
Completed Iteration #9
Best Reward: 4.166666666666671
Completed Iteration #10
Best Reward: 4.166666666666671
Completed Iteration #11
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f6506d8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 33.333333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 37.50000000000007 19
Completed Iteration #12
Best Reward: 4.166666666666671
Completed Iteration #13
Best Reward: 4.166666666666671
Completed Iteration #14
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f19bc50> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 37.50000000000006 13
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 41.66666666666674 20
Completed Iteration #15
Best Reward: 4.166666666666671
Completed Iteration #16
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f746a90> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746eb8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6506d8> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 41.66666666666673 14
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 45.833333333333414 21
Completed Iteration #17
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f7468d0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746780> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746a90> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746eb8> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6506d8> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 45.8333333333334 15
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 50.000000000000085 22
Completed Iteration #18
Best Reward: 4.166666666666671
Completed Iteration #19
Best Reward: 4.166666666666671
Completed Iteration #20
Best Reward: 4.166666666666671
Completed Iteration #21
Best Reward: 4.166666666666671
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f746ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f75c080> 16.6666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f2895280470> 20.83333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 45.8333333333334 16
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 50.000000000000085 23
Completed Iteration #22
Best Reward: 4.166666666666671
Completed Iteration #23
Best Reward: 4.166666666666671
Completed Iteration #24
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f7162b0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 50.00000000000007 17
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 54.16666666666676 24
Completed Iteration #25
Best Reward: 4.166666666666671
Completed MCTS Level/Depth: #1
root->0
Best Reward: 4.166666666666671
Completed Iteration #0
Best Reward: 4.166666666666671
Completed Iteration #1
Best Reward: 4.166666666666671
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f71eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7162b0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 25.00000000000003 8
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 29.1666666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 50.00000000000007 18
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 54.16666666666676 25
Completed Iteration #2
Best Reward: 4.166666666666671
Completed Iteration #3
Best Reward: 4.166666666666671
Completed Iteration #4
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f684b38> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736e80> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7468d0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746780> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746a90> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746eb8> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6506d8> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 29.1666666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 33.33333333333337 10
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 54.16666666666674 19
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 58.33333333333343 26
Completed Iteration #5
Best Reward: 4.166666666666671
Completed Iteration #6
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f746518> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1b3748> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19bc50> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 33.33333333333337 10
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 37.50000000000004 11
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 58.333333333333414 20
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 62.5000000000001 27
Completed Iteration #7
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f650208> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746d68> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f684b38> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f736e80> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7468d0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746780> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746a90> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746eb8> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f6506d8> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 33.33333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 37.50000000000004 11
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 41.666666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 62.500000000000085 21
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 66.66666666666677 28
Completed Iteration #8
Best Reward: 4.166666666666671
Completed Iteration #9
Best Reward: 4.166666666666671
Completed Iteration #10
Best Reward: 4.166666666666671
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746780> 12.500000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746a90> 16.666666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f286f746eb8> 16.666666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f286f6506d8> 20.833333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 29.1666666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 33.33333333333337 10
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 37.50000000000004 12
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 41.666666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 62.500000000000085 22
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 66.66666666666677 29
Completed Iteration #11
Best Reward: 4.166666666666671
Completed Iteration #12
Best Reward: 4.166666666666671
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f78d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746d68> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f286f684b38> 8.333333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f286f736e80> 8.333333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7468d0> 12.500000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746780> 12.500000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f286f746a90> 16.666666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f286f746eb8> 16.666666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f286f6506d8> 20.833333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 29.1666666666667 10
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 33.33333333333337 11
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 37.50000000000004 13
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 41.666666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 62.500000000000085 23
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 66.66666666666677 30
Completed Iteration #13
Best Reward: 4.166666666666671
Completed Iteration #14
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f78d5c0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746d68> 8.333333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f286f684b38> 12.500000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f286f736e80> 12.500000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7468d0> 16.666666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f286f746780> 16.666666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f286f746a90> 20.833333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f286f746eb8> 20.833333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f286f6506d8> 25.00000000000003 9
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 33.33333333333337 11
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 37.50000000000004 12
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 41.666666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 45.833333333333385 15
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 66.66666666666676 24
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 70.83333333333344 31
Completed Iteration #15
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 45.833333333333385 15
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 50.00000000000006 16
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 70.83333333333343 25
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 75.00000000000011 32
Completed Iteration #16
Best Reward: 4.166666666666671
Completed Iteration #17
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f6840b8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 37.50000000000004 12
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 41.666666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 50.00000000000006 16
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 54.16666666666673 17
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 75.0000000000001 26
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 79.16666666666679 33
Completed Iteration #18
Best Reward: 4.166666666666671
Completed Iteration #19
Best Reward: 4.166666666666671
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f750898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f71e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 54.16666666666673 18
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 75.0000000000001 27
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 79.16666666666679 34
Completed Iteration #20
Best Reward: 4.166666666666671
Completed Iteration #21
Best Reward: 4.166666666666671
coverage_call_count 4900
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 54.16666666666673 17
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 58.3333333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 79.16666666666677 28
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 83.33333333333346 35
Completed Iteration #22
Best Reward: 4.166666666666671
Completed Iteration #23
Best Reward: 4.166666666666671
Completed Iteration #24
Best Reward: 4.166666666666671
Completed Iteration #25
Best Reward: 4.166666666666671
Completed MCTS Level/Depth: #2
root->0->9
Best Reward: 4.166666666666671
Completed Iteration #0
Best Reward: 4.166666666666671
Completed Iteration #1
Best Reward: 4.166666666666671
Completed Iteration #2
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f7f8da0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6502e8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f19bc50> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f650da0> 41.666666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f286f736c50> 45.833333333333385 14
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 58.3333333333334 18
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 62.50000000000007 20
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 83.33333333333344 29
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 87.50000000000013 36
Completed Iteration #3
Best Reward: 4.166666666666671
Completed Iteration #4
Best Reward: 4.166666666666671
Completed Iteration #5
Best Reward: 4.166666666666671
Completed Iteration #6
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 62.50000000000007 19
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 66.66666666666674 21
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 87.50000000000011 30
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 91.6666666666668 37
Completed Iteration #7
Best Reward: 4.166666666666671
Completed Iteration #8
Best Reward: 4.166666666666671
Completed Iteration #9
Best Reward: 4.166666666666671
Completed Iteration #10
Best Reward: 4.166666666666671
Completed Iteration #11
Best Reward: 4.166666666666671
Completed Iteration #12
Best Reward: 4.166666666666671
Completed Iteration #13
Best Reward: 4.166666666666671
Completed Iteration #14
Best Reward: 4.166666666666671
Completed Iteration #15
Best Reward: 4.166666666666671
Completed Iteration #16
Best Reward: 4.166666666666671
Completed Iteration #17
Best Reward: 4.166666666666671
Completed Iteration #18
Best Reward: 4.166666666666671
Completed Iteration #19
Best Reward: 4.166666666666671
Completed Iteration #20
Best Reward: 4.166666666666671
Completed Iteration #21
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b6d8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc6bda0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7162b0> 8.333333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 66.66666666666674 20
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 70.83333333333341 22
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 91.66666666666679 31
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 95.83333333333347 38
Completed Iteration #22
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc6b8d0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 70.83333333333341 21
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 75.00000000000009 23
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 95.83333333333346 32
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 100.00000000000014 39
Completed Iteration #23
Best Reward: 4.166666666666671
Completed Iteration #24
Best Reward: 4.166666666666671
Completed Iteration #25
Best Reward: 4.166666666666671
Completed MCTS Level/Depth: #3
root->0->9->2
Best Reward: 4.166666666666671
Completed Iteration #0
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8be0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 75.00000000000009 22
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 79.16666666666676 24
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 100.00000000000013 33
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 104.16666666666681 40
Completed Iteration #1
Best Reward: 4.166666666666671
Completed Iteration #2
Best Reward: 4.166666666666671
Completed Iteration #3
Best Reward: 4.166666666666671
Completed Iteration #4
Best Reward: 4.166666666666671
Completed Iteration #5
Best Reward: 4.166666666666671
Completed Iteration #6
Best Reward: 4.166666666666671
Completed Iteration #7
Best Reward: 4.166666666666671
Completed Iteration #8
Best Reward: 4.166666666666671
Completed Iteration #9
Best Reward: 4.166666666666671
Completed Iteration #10
Best Reward: 4.166666666666671
Completed Iteration #11
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 79.16666666666676 23
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 83.33333333333343 25
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 104.1666666666668 34
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 108.33333333333348 41
Completed Iteration #12
Best Reward: 4.166666666666671
Completed Iteration #13
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f746748> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6846d8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 83.33333333333343 24
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 87.5000000000001 26
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 108.33333333333347 35
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 112.50000000000016 42
Completed Iteration #14
Best Reward: 4.166666666666671
Completed Iteration #15
Best Reward: 4.166666666666671
Completed Iteration #16
Best Reward: 4.166666666666671
Completed Iteration #17
Best Reward: 4.166666666666671
Completed Iteration #18
Best Reward: 4.166666666666671
Completed Iteration #19
Best Reward: 4.166666666666671
Completed Iteration #20
Best Reward: 4.166666666666671
Completed Iteration #21
Best Reward: 4.166666666666671
Completed Iteration #22
Best Reward: 4.166666666666671
Completed Iteration #23
Best Reward: 4.166666666666671
Completed Iteration #24
Best Reward: 4.166666666666671
Completed Iteration #25
Best Reward: 4.166666666666671
Completed MCTS Level/Depth: #4
root->0->9->2->5
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc12cc0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 33.33333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 87.5000000000001 25
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 91.66666666666677 27
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 112.50000000000014 36
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 116.66666666666683 43
Completed Iteration #0
Best Reward: 4.166666666666671
Completed Iteration #1
Best Reward: 4.166666666666671
Completed Iteration #2
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc21ef0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79b38> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8be0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 37.50000000000004 10
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 91.66666666666677 26
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 95.83333333333344 28
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 116.66666666666681 37
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 120.8333333333335 44
Completed Iteration #3
Best Reward: 4.166666666666671
Completed Iteration #4
Best Reward: 4.166666666666671
Completed Iteration #5
Best Reward: 4.166666666666671
Completed Iteration #6
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc211d0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21748> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21ef0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc79b38> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8be0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 33.33333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 41.666666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 95.83333333333344 27
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 100.00000000000011 29
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 120.83333333333348 38
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 125.00000000000017 45
Completed Iteration #7
Best Reward: 4.166666666666671
Completed Iteration #8
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc668> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc550> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc211d0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc21748> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc21ef0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc79b38> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8be0> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 37.50000000000004 10
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 45.833333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 100.00000000000011 28
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 104.16666666666679 30
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 125.00000000000016 39
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 129.16666666666686 46
Completed Iteration #9
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6978> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6198> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 41.666666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 50.00000000000006 13
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 104.16666666666679 29
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 108.33333333333346 31
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 129.16666666666683 40
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 133.33333333333354 47
Completed Iteration #10
Best Reward: 4.166666666666671
Completed Iteration #11
Best Reward: 4.166666666666671
Completed Iteration #12
Best Reward: 4.166666666666671
Completed Iteration #13
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fcb60f0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6198> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 45.833333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 54.16666666666673 14
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 108.33333333333346 30
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 112.50000000000013 32
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 133.33333333333348 41
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 137.50000000000023 48
Completed Iteration #14
Best Reward: 4.166666666666671
Completed Iteration #15
Best Reward: 4.166666666666671
Completed Iteration #16
Best Reward: 4.166666666666671
Completed Iteration #17
Best Reward: 4.166666666666671
Completed Iteration #18
Best Reward: 4.166666666666671
Completed Iteration #19
Best Reward: 4.166666666666671
Completed Iteration #20
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f7500b8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f746358> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc668> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcfc550> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc211d0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc21748> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc21ef0> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc79b38> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8be0> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 50.00000000000006 13
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 58.3333333333334 15
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 112.50000000000013 31
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 116.6666666666668 33
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 137.50000000000017 42
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 141.6666666666669 49
Completed Iteration #21
Best Reward: 4.166666666666671
Completed Iteration #22
Best Reward: 4.166666666666671
Completed Iteration #23
Best Reward: 4.166666666666671
Completed Iteration #24
Best Reward: 4.166666666666671
Completed Iteration #25
Best Reward: 4.166666666666671
Completed MCTS Level/Depth: #5
root->0->9->2->5->6
Best Reward: 4.166666666666671
Completed Iteration #0
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6630> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6b70> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb60f0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6198> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 54.16666666666673 14
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 62.50000000000007 16
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 116.6666666666668 32
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 120.83333333333347 34
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 141.66666666666686 43
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 145.8333333333336 50
Completed Iteration #1
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8e10> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc12cc0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 33.33333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 58.3333333333334 15
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 66.66666666666674 17
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 120.83333333333347 33
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 125.00000000000014 35
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 145.83333333333354 44
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 150.00000000000028 51
Completed Iteration #2
Best Reward: 4.166666666666671
Completed Iteration #3
Best Reward: 4.166666666666671
Completed Iteration #4
Best Reward: 4.166666666666671
Completed Iteration #5
Best Reward: 4.166666666666671
Completed Iteration #6
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dd30> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b978> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6978> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6198> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 33.33333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 33.33333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 37.50000000000004 10
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 62.50000000000007 16
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 70.83333333333341 18
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 125.00000000000014 34
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 129.1666666666668 36
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 150.00000000000023 45
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 154.16666666666697 52
Completed Iteration #7
Best Reward: 4.166666666666671
Completed Iteration #8
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d240> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6b70> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb60f0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6198> 20.833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 33.33333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 37.50000000000004 10
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 37.50000000000004 10
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 41.666666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 66.66666666666674 17
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 75.00000000000009 19
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 129.1666666666668 35
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 133.33333333333348 37
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 154.1666666666669 46
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 158.33333333333366 53
Completed Iteration #9
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d438> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccdb70> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dd30> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b978> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6978> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6198> 25.00000000000003 7
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 37.50000000000004 10
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 41.666666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 41.666666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 45.833333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 70.83333333333341 18
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 79.16666666666676 20
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 133.33333333333348 36
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 137.50000000000017 38
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 158.3333333333336 47
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 162.50000000000034 54
Completed Iteration #10
Best Reward: 4.166666666666671
Completed Iteration #11
Best Reward: 4.166666666666671
Completed Iteration #12
Best Reward: 4.166666666666671
Completed Iteration #13
Best Reward: 4.166666666666671
Completed Iteration #14
Best Reward: 4.166666666666671
Completed Iteration #15
Best Reward: 4.166666666666671
Completed Iteration #16
Best Reward: 4.166666666666671
Completed Iteration #17
Best Reward: 4.166666666666671
Completed Iteration #18
Best Reward: 4.166666666666671
coverage_call_count 5000
Completed Iteration #19
Best Reward: 4.166666666666671
Completed Iteration #20
Best Reward: 4.166666666666671
Completed Iteration #21
Best Reward: 4.166666666666671
Completed Iteration #22
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dbe0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 41.666666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 45.833333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 45.833333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 50.00000000000006 13
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 75.00000000000009 19
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 83.33333333333343 21
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 137.50000000000017 37
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 141.66666666666686 39
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 162.50000000000028 48
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 166.66666666666703 55
Completed Iteration #23
Best Reward: 4.166666666666671
Completed Iteration #24
Best Reward: 4.166666666666671
Completed Iteration #25
Best Reward: 4.166666666666671
Completed MCTS Level/Depth: #6
root->0->9->2->5->6->3
Best Reward: 4.166666666666671
Completed Iteration #0
Best Reward: 4.166666666666671
Completed Iteration #1
Best Reward: 4.166666666666671
Completed Iteration #2
Best Reward: 4.166666666666671
Completed Iteration #3
Best Reward: 4.166666666666671
Completed Iteration #4
Best Reward: 4.166666666666671
Completed Iteration #5
Best Reward: 4.166666666666671
Completed Iteration #6
Best Reward: 4.166666666666671
Completed Iteration #7
Best Reward: 4.166666666666671
Completed Iteration #8
Best Reward: 4.166666666666671
Completed Iteration #9
Best Reward: 4.166666666666671
Completed Iteration #10
Best Reward: 4.166666666666671
Completed Iteration #11
Best Reward: 4.166666666666671
Completed Iteration #12
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fd2bdd8> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 50.00000000000006 13
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 54.16666666666673 14
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 79.16666666666676 20
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 87.5000000000001 22
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 141.66666666666686 38
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 145.83333333333354 40
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 166.66666666666697 49
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 170.8333333333337 56
Completed Iteration #13
Best Reward: 4.166666666666671
Completed Iteration #14
Best Reward: 4.166666666666671
Completed Iteration #15
Best Reward: 4.166666666666671
Completed Iteration #16
Best Reward: 4.166666666666671
Completed Iteration #17
Best Reward: 4.166666666666671
Completed Iteration #18
Best Reward: 4.166666666666671
Completed Iteration #19
Best Reward: 4.166666666666671
Completed Iteration #20
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286f736898> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b940> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8e10> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc12cc0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 45.833333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 50.00000000000006 13
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 54.16666666666673 14
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 58.3333333333334 15
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 83.33333333333343 21
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 91.66666666666677 23
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 145.83333333333354 39
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 150.00000000000023 41
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 170.83333333333366 50
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 175.0000000000004 57
Completed Iteration #21
Best Reward: 4.166666666666671
Completed Iteration #22
Best Reward: 4.166666666666671
Completed Iteration #23
Best Reward: 4.166666666666671
Completed Iteration #24
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f28a19eae10> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd400> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dbe0> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 50.00000000000006 13
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 54.16666666666673 14
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 58.3333333333334 15
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 62.50000000000007 16
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 87.5000000000001 22
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 95.83333333333344 24
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 150.00000000000023 40
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 154.1666666666669 42
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 175.00000000000034 51
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 179.16666666666708 58
Completed Iteration #25
Best Reward: 4.166666666666671
Completed MCTS Level/Depth: #7
root->0->9->2->5->6->3->6
Best Reward: 4.166666666666671
Completed Iteration #0
Best Reward: 4.166666666666671
Completed Iteration #1
Best Reward: 4.166666666666671
Completed Iteration #2
Best Reward: 4.166666666666671
Completed Iteration #3
Best Reward: 4.166666666666671
Completed Iteration #4
Best Reward: 4.166666666666671
Completed Iteration #5
Best Reward: 4.166666666666671
Completed Iteration #6
Best Reward: 4.166666666666671
Completed Iteration #7
Best Reward: 4.166666666666671
Completed Iteration #8
Best Reward: 4.166666666666671
Completed Iteration #9
Best Reward: 4.166666666666671
Completed Iteration #10
Best Reward: 4.166666666666671
Completed Iteration #11
Best Reward: 4.166666666666671
Completed Iteration #12
Best Reward: 4.166666666666671
Completed Iteration #13
Best Reward: 4.166666666666671
Completed Iteration #14
Best Reward: 4.166666666666671
Completed Iteration #15
Best Reward: 4.166666666666671
Completed Iteration #16
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9a58> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9400> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f28a19eae10> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccd400> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dbe0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 54.16666666666673 14
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 58.3333333333334 15
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 62.50000000000007 16
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 66.66666666666674 17
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 91.66666666666677 23
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 100.00000000000011 25
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 154.1666666666669 41
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 158.3333333333336 43
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 179.16666666666703 52
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 183.33333333333377 59
Completed Iteration #17
Best Reward: 4.166666666666671
Completed Iteration #18
Best Reward: 4.166666666666671
Completed Iteration #19
Best Reward: 4.166666666666671
Completed Iteration #20
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b518> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f28952438d0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286f736898> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b940> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286f7d8e10> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc218d0> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fc12cc0> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 58.3333333333334 15
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 62.50000000000007 16
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 66.66666666666674 17
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 70.83333333333341 18
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 95.83333333333344 24
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 104.16666666666679 26
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 158.3333333333336 42
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 162.50000000000028 44
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 183.3333333333337 53
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 187.50000000000045 60
Completed Iteration #21
Best Reward: 4.166666666666671
Completed Iteration #22
Best Reward: 4.166666666666671
Reward: 4.166666666666671
backprop <src.mcts.MCTS_Node object at 0x7f28a19ea748> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc798d0> 4.166666666666671 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc8d240> 8.333333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6b70> 12.500000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcb60f0> 16.666666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6198> 29.1666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f286fc79470> 33.33333333333337 9
backprop <src.mcts.MCTS_Node object at 0x7f286fc79a20> 62.50000000000007 16
backprop <src.mcts.MCTS_Node object at 0x7f286f7eacc0> 66.66666666666674 17
backprop <src.mcts.MCTS_Node object at 0x7f286f7f80b8> 70.83333333333341 18
backprop <src.mcts.MCTS_Node object at 0x7f286f746a20> 75.00000000000009 19
backprop <src.mcts.MCTS_Node object at 0x7f286f650908> 100.00000000000011 25
backprop <src.mcts.MCTS_Node object at 0x7f286f716048> 108.33333333333346 27
backprop <src.mcts.MCTS_Node object at 0x7f286f7369e8> 162.50000000000028 43
backprop <src.mcts.MCTS_Node object at 0x7f286f6e8748> 166.66666666666697 45
backprop <src.mcts.MCTS_Node object at 0x7f286f7afcf8> 187.5000000000004 54
backprop <src.mcts.MCTS_Node object at 0x7f286f75ca20> 191.66666666666714 61
Completed Iteration #23
Best Reward: 4.166666666666671
Completed Iteration #24
Best Reward: 4.166666666666671
Completed Iteration #25
Best Reward: 4.166666666666671
Completed MCTS Level/Depth: #8
root->0->9->2->5->6->3->6->26
Best Reward: 4.166666666666671
iteration: 148
found coverage increase 4.166666666666671
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c171358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab68860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289532aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fccda90> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9be80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ecc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3ec88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952529e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc799b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286fcb6a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2993b31208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f684208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2993b31208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945eacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952d9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952d99e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc21f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fccd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec0f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f28aa445320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895252cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0caba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895243f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc12f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 43.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 5200
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4978> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa529e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa964e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa86048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15e710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaab8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f97f0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd3e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952d9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd3eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa578ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ebe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29400864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa96d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c15ebe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff0f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 43.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc8da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952525f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952525f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952525f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa445828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 43.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab760f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa561ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab76898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 5300
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa4932b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fbd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab76ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab802e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa578ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab17518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945eafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a19eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab802e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa493668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab894e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa445908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5a35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab89cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb208> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab24550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 5400
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c124828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29040ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c149e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab24860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 43.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29040ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa19cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab5d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f29040ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0b0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0d4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c124e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289532a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaadb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895252828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab80f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa493630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab89a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaae79e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c05e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 43.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c13a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa56cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fc219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaadbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01780> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952602b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952602b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c07cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c13a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895243f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f98> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952525f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c171b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c089470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa488ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5fba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945807b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286fc9b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952525f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945dcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa2b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2904161f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaa497b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0aba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c181cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0faf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0faa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaaf8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa523550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c181748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945b69b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabe4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952aea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952ae0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894580978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab98550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28952aecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa488ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a5aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28952aecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aab5dac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa493630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c089550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa78908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28945a2f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2894549fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6abf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5d9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c149320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28aa5bfb38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f18fdd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 5700
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f66b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f66bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f68a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945492b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286fd2b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa0a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c15e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894549710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aab80f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f2895260f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f18fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f18fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f68a390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f286f6abd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabf4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f2894580b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabb1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f28945b6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28a1a01cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6ab2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f7780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa54b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aabbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28945a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c0fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aaac4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaa49160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c0f30f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1db240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7782e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7782e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1db898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1db470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f28aa5b2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6df5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f7782e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f289c1818d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 43.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f602b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f60e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6022b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f602710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f602a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f60ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6024e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db3c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 43.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289455b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28952aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f1db198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f289455b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28945a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f289c1816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aaae79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f778320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1dba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f778cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f1db898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f28aa4ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f286f6c2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f286f6df780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f286f1db668> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 43.75
initial coverage: 6.25
time passed (minutes): 60.0357
iterations: 179
number of new inputs: 384
final coverage: 43.75
total coverage increase: 37.5
