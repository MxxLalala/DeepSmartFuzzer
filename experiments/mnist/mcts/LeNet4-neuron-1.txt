Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f3fc4ccaf28>, tc2=<function tc2 at 0x7f3fc4cd9048>, tc3=<function tc3 at 0x7f3fc4cd9158>, tfc_threshold=3300000, time_period=3600, verbose=True)
initial coverage: 69.0141
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ceb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c42e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44765eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446915c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44765eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446915c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9048> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446a44e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6a20> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446655c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446655c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ece10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ece10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ece10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446655c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387aca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387aca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387aca20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387aca20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace10> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387550f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387550f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387550f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387441d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387441d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387447f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387656d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387194e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38719208> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387553c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e91d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386baef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447a3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f68021f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d60f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386baba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386baa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38755898> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44781e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44781e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44781e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebcc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44781e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac898> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387816d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446656a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446919b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44649400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38744828> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f68021f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 900
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447235f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac50> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387446a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f63c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f60b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6959b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6959b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f63c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 10
Completed Iteration #15
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c400> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44765eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6855f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6697b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6697b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6697b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6697b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf5b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c76a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c76a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 8
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 9
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 10
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 11
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 12
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ce10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a5c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.7042253521126725 14
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.7042253521126725 15
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.7042253521126725 16
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 0.7042253521126725 17
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 1.408450704225345 18
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 1.408450704225345 19
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 1.408450704225345 20
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 1.408450704225345 21
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 2.1126760563380174 22
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fc50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f8d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f390> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 2.81690140845069 23
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 2.81690140845069 24
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61748> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 2.81690140845069 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 2.81690140845069 25
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 2.81690140845069 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 2.81690140845069 26
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61748> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 3.5211267605633623 27
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 3.5211267605633623 15
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 3.5211267605633623 28
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 3.5211267605633623 16
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 3.5211267605633623 29
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd68> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61d30> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61748> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 17
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 30
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 18
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 31
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61d30> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61748> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 19
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 32
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 20
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 33
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 21
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 34
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61748> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 22
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 35
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 23
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 36
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 24
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 37
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 25
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 38
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fc50> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f8d0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f390> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.225352112676035 26
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.225352112676035 39
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 4.929577464788707 27
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 4.929577464788707 40
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 5.63380281690138 28
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 5.63380281690138 41
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fb00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 6.338028169014052 29
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 6.338028169014052 42
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 6.338028169014052 30
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 6.338028169014052 43
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 4.225352112676035 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 6.338028169014052 31
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 6.338028169014052 44
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4a20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c5f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fb00> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 7.0422535211267245 32
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 7.0422535211267245 45
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ca58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 7.746478873239397 33
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 7.746478873239397 46
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 5.63380281690138 15
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 7.746478873239397 34
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 7.746478873239397 47
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f68021f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 6.338028169014052 16
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 8.45070422535207 35
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 8.45070422535207 48
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fc50> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f8d0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f390> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 6.338028169014052 17
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 8.45070422535207 36
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 8.45070422535207 49
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ca58> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 6.338028169014052 18
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 8.45070422535207 37
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 8.45070422535207 50
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 6.338028169014052 19
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 8.45070422535207 38
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 8.45070422535207 51
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7da90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e9b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 6.338028169014052 15
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 7.0422535211267245 20
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 9.154929577464742 39
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 9.154929577464742 52
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ebe0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 7.746478873239397 21
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 9.859154929577414 40
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 9.859154929577414 53
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e9b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 7.746478873239397 17
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 8.45070422535207 22
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 10.563380281690087 41
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 10.563380281690087 54
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 9.154929577464742 23
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 11.26760563380276 42
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 11.26760563380276 55
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d2e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d34a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fc50> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f8d0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f390> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 9.859154929577414 24
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 11.971830985915432 43
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 11.971830985915432 56
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 10.563380281690087 25
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 12.676056338028104 44
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 12.676056338028104 57
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 10.563380281690087 21
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 11.26760563380276 26
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 13.380281690140777 45
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 13.380281690140777 58
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 10.563380281690087 22
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 11.26760563380276 27
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 13.380281690140777 46
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 13.380281690140777 59
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3550> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 10.563380281690087 23
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 11.26760563380276 28
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 13.380281690140777 47
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 13.380281690140777 60
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 11.26760563380276 24
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 11.971830985915432 29
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 14.084507042253449 48
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 14.084507042253449 61
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 11.971830985915432 25
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 12.676056338028104 30
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 14.788732394366122 49
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 14.788732394366122 62
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7da90> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e9b0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 12.676056338028104 26
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 13.380281690140777 31
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 15.492957746478794 50
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 15.492957746478794 63
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->6->19->5
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 13.380281690140777 27
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 14.084507042253449 32
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 16.197183098591466 51
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 16.197183098591466 64
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d409e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 14.084507042253449 28
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 14.788732394366122 33
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 16.90140845070414 52
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 16.90140845070414 65
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c5f8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fb00> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 14.084507042253449 29
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 14.788732394366122 34
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 16.90140845070414 53
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 16.90140845070414 66
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 14.788732394366122 30
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 15.492957746478794 35
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 17.60563380281681 54
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 17.60563380281681 67
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
coverage_call_count 1500
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aa90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fb00> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 15.492957746478794 31
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 16.197183098591466 36
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 18.309859154929484 55
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 18.309859154929484 68
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 16.197183098591466 32
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 19.014084507042156 56
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 19.014084507042156 69
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 16.90140845070414 33
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 17.60563380281681 38
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 19.71830985915483 57
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 19.71830985915483 70
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 17.60563380281681 34
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 18.309859154929484 39
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 20.4225352112675 58
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 20.4225352112675 71
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40a58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d550> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 18.309859154929484 35
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 19.014084507042156 40
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 21.126760563380174 59
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 21.126760563380174 72
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b2e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f68021f28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 19.014084507042156 36
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 19.71830985915483 41
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 21.830985915492846 60
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 21.830985915492846 73
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 19.71830985915483 37
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 20.4225352112675 42
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 22.53521126760552 61
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 22.53521126760552 74
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->6->19->5->10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce33c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 20.4225352112675 38
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 21.126760563380174 43
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 23.23943661971819 62
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 23.23943661971819 75
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 21.126760563380174 39
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 21.830985915492846 44
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 23.943661971830863 63
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 23.943661971830863 76
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 13.380281690140777 21
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 22.53521126760552 45
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 24.647887323943536 64
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 24.647887323943536 77
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce32e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3438> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 14.084507042253449 22
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 22.53521126760552 41
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 23.23943661971819 46
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 25.35211267605621 65
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 25.35211267605621 78
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d198> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 14.084507042253449 23
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 22.53521126760552 42
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 23.23943661971819 47
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 25.35211267605621 66
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 25.35211267605621 79
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bfd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b7f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d198> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 14.788732394366122 24
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 23.23943661971819 43
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 23.943661971830863 48
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 26.05633802816888 67
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 26.05633802816888 80
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bfd0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b7f0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d198> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 23.23943661971819 44
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 23.943661971830863 49
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 26.05633802816888 68
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 26.05633802816888 81
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf03c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40438> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 15.492957746478794 26
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 23.943661971830863 45
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 24.647887323943536 50
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 26.760563380281553 69
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 26.760563380281553 82
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f128> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 16.197183098591466 27
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 24.647887323943536 46
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 25.35211267605621 51
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 27.464788732394226 70
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 27.464788732394226 83
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->6->19->5->10->4
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 25.35211267605621 47
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 26.05633802816888 52
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 28.169014084506898 71
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 28.169014084506898 84
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 12.676056338028104 21
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 17.60563380281681 29
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 26.05633802816888 48
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 26.760563380281553 53
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 28.87323943661957 72
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 28.87323943661957 85
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 13.380281690140777 22
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 18.309859154929484 30
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 26.760563380281553 49
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 27.464788732394226 54
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 29.577464788732243 73
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 29.577464788732243 86
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d7b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf03c8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40438> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 14.084507042253449 23
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 19.014084507042156 31
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 27.464788732394226 50
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 28.169014084506898 55
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 30.281690140844916 74
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 30.281690140844916 87
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3f98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf08d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 14.788732394366122 24
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 19.71830985915483 32
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 28.169014084506898 51
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 28.87323943661957 56
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 30.985915492957588 75
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 30.985915492957588 88
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0d68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf08d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 15.492957746478794 25
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 20.4225352112675 33
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 28.87323943661957 52
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 29.577464788732243 57
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 31.69014084507026 76
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 31.69014084507026 89
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bcf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3438> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 11.26760563380276 17
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 16.197183098591466 26
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 21.126760563380174 34
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 29.577464788732243 53
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 30.281690140844916 58
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 32.39436619718293 77
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 32.39436619718293 90
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 11.971830985915432 18
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 16.90140845070414 27
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 21.830985915492846 35
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 30.281690140844916 54
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 30.985915492957588 59
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 33.098591549295605 78
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 33.098591549295605 91
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0320> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 21.830985915492846 36
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 30.281690140844916 55
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 30.985915492957588 60
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 33.098591549295605 79
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 33.098591549295605 92
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04cf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e8d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 17.60563380281681 29
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 22.53521126760552 37
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 30.985915492957588 56
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 31.69014084507026 61
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 33.80281690140828 80
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 33.80281690140828 93
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0da0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 13.380281690140777 21
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 18.309859154929484 30
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 23.23943661971819 38
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 31.69014084507026 57
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 32.39436619718293 62
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 34.50704225352095 81
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 34.50704225352095 94
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e8d0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 13.380281690140777 22
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 18.309859154929484 31
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 23.23943661971819 39
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 31.69014084507026 58
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 32.39436619718293 63
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 34.50704225352095 82
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 34.50704225352095 95
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->6->19->5->10->4->3
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04048> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 18.309859154929484 32
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 23.23943661971819 40
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 31.69014084507026 59
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 32.39436619718293 64
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 34.50704225352095 83
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 34.50704225352095 96
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 19.014084507042156 33
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 23.943661971830863 41
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 32.39436619718293 60
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 33.098591549295605 65
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 35.21126760563362 84
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 35.21126760563362 97
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96ac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96898> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0da0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 19.71830985915483 34
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 24.647887323943536 42
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 33.098591549295605 61
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 33.80281690140828 66
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 35.915492957746295 85
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 35.915492957746295 98
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f6a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f5c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d409e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 15.492957746478794 26
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 20.4225352112675 35
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 25.35211267605621 43
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 33.80281690140828 62
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 34.50704225352095 67
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 36.61971830985897 86
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 36.61971830985897 99
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fb38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f6a0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f5c0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d409e8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 16.197183098591466 27
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 21.126760563380174 36
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 26.05633802816888 44
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 34.50704225352095 63
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 35.21126760563362 68
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 37.32394366197164 87
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 37.32394366197164 100
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d409e8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 21.830985915492846 37
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 26.760563380281553 45
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 35.21126760563362 64
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 35.915492957746295 69
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 38.02816901408431 88
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 38.02816901408431 101
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0c88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc08d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b978> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 17.60563380281681 29
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 22.53521126760552 38
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 27.464788732394226 46
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 35.915492957746295 65
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 36.61971830985897 70
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 38.732394366196985 89
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 38.732394366196985 102
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc03c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52128> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be10> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 12.676056338028104 21
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 18.309859154929484 30
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 23.23943661971819 39
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 28.169014084506898 47
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 36.61971830985897 66
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 37.32394366197164 71
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 39.43661971830966 90
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 39.43661971830966 103
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->6->19->5->10->4->3->5
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be10> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 13.380281690140777 22
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 19.014084507042156 31
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 23.943661971830863 40
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 28.87323943661957 48
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 37.32394366197164 67
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 38.02816901408431 72
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 40.14084507042233 91
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 40.14084507042233 104
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fb00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be10> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 14.084507042253449 23
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 19.71830985915483 32
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 24.647887323943536 41
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 29.577464788732243 49
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 38.02816901408431 68
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 38.732394366196985 73
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 40.845070422535 92
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 40.845070422535 105
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be10> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 19.71830985915483 33
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 24.647887323943536 42
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 29.577464788732243 50
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 38.02816901408431 69
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 38.732394366196985 74
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 40.845070422535 93
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 40.845070422535 106
Completed Iteration #6
Best Reward: 0.7042253521126725
coverage_call_count 1600
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc07f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 20.4225352112675 34
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 25.35211267605621 43
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 30.281690140844916 51
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 38.732394366196985 70
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 39.43661971830966 75
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 41.549295774647675 94
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 41.549295774647675 107
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0320> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 15.492957746478794 26
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 21.126760563380174 35
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 26.05633802816888 44
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 30.985915492957588 52
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 39.43661971830966 71
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 40.14084507042233 76
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 42.25352112676035 95
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 42.25352112676035 108
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0320> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 16.197183098591466 27
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 21.830985915492846 36
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 26.760563380281553 45
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 31.69014084507026 53
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 40.14084507042233 72
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 40.845070422535 77
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 42.95774647887302 96
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 42.95774647887302 109
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b588> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be10> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 22.53521126760552 37
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 27.464788732394226 46
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 32.39436619718293 54
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 40.845070422535 73
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 41.549295774647675 78
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 43.66197183098569 97
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 43.66197183098569 110
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be10> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 17.60563380281681 29
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 23.23943661971819 38
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 28.169014084506898 47
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 33.098591549295605 55
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 41.549295774647675 74
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 42.25352112676035 79
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 44.366197183098365 98
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 44.366197183098365 111
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fa90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fa58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9d30> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0320> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 18.309859154929484 30
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de10> 23.943661971830863 39
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 28.87323943661957 48
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 33.80281690140828 56
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f898> 42.25352112676035 75
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612b0> 42.95774647887302 80
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 45.07042253521104 99
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d630> 45.07042253521104 112
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->6->19->5->10->4->3->5->0
Best Reward: 0.7042253521126725
iteration: 54
found coverage increase 0.7042253521126725
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc96d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce34e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cdd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c79e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d68> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 20
Completed Iteration #22
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d33c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dda0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6851d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6699e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4479ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447239b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 17
Completed Iteration #18
Best Reward: 0
coverage_call_count 2000
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447239b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f447231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6852b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6852b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6852b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfc18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44781ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387440f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387819b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446495c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446495c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446495c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d128> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5f28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e92e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e92e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.7042253521126725 11
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8d30> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.7042253521126725 12
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.7042253521126725 13
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8d30> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.7042253521126725 14
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.7042253521126725 15
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.7042253521126725 16
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.7042253521126725 17
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aa90> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8d30> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 1.408450704225345 18
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 1.408450704225345 19
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 1.408450704225345 20
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 1.408450704225345 21
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 1.408450704225345 9
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 1.408450704225345 22
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 1.408450704225345 10
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 1.408450704225345 23
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4198> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aa90> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8d30> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 2.1126760563380174 11
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 2.1126760563380174 24
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8d30> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 2.1126760563380174 12
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 2.1126760563380174 25
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 2.1126760563380174 13
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 2.1126760563380174 26
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f38755f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386baa90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9fd0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 2.81690140845069 14
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 2.81690140845069 27
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aa90> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8d30> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 2.81690140845069 15
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 2.81690140845069 28
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 2.81690140845069 16
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 2.81690140845069 29
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 2.81690140845069 17
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 2.81690140845069 30
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 3.5211267605633623 18
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 3.5211267605633623 31
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8d30> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 3.5211267605633623 19
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 3.5211267605633623 32
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 3.5211267605633623 20
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 3.5211267605633623 33
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 3.5211267605633623 21
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 3.5211267605633623 34
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 3.5211267605633623 22
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 3.5211267605633623 35
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 3.5211267605633623 23
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 3.5211267605633623 36
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 4.225352112676035 24
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 4.225352112676035 37
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 4.929577464788707 25
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 4.929577464788707 38
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f3869eeb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 5.63380281690138 26
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 5.63380281690138 39
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f93242ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869eeb8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 6.338028169014052 27
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 6.338028169014052 40
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 6.338028169014052 28
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 6.338028169014052 41
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f38719278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 7.0422535211267245 29
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 7.0422535211267245 42
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f38719ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 7.746478873239397 30
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 7.746478873239397 43
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 8.45070422535207 31
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 8.45070422535207 44
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f386baac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 9.154929577464742 32
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 9.154929577464742 45
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719ba8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 9.859154929577414 33
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 9.859154929577414 46
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96860> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719ba8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 9.859154929577414 34
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 9.859154929577414 47
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f386e94e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 10.563380281690087 35
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 10.563380281690087 48
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f38755e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386baac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 11.26760563380276 36
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 11.26760563380276 49
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d2e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719278> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 11.971830985915432 37
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 11.971830985915432 50
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 11.971830985915432 38
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 11.971830985915432 51
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba9b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869eeb8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 12.676056338028104 39
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 12.676056338028104 52
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c18> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 9.859154929577414 19
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 12.676056338028104 40
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 12.676056338028104 53
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f386bae48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 10.563380281690087 20
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 13.380281690140777 41
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 13.380281690140777 54
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f90eeb9e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d358> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719278> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 11.26760563380276 21
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 14.084507042253449 42
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 14.084507042253449 55
Completed Iteration #12
Best Reward: 0.7042253521126725
coverage_call_count 2300
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 14.788732394366122 43
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 14.788732394366122 56
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04cf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04518> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 15.492957746478794 44
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 15.492957746478794 57
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04518> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 13.380281690140777 24
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 16.197183098591466 45
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 16.197183098591466 58
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 16.90140845070414 46
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 16.90140845070414 59
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f048> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3869eeb8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 17.60563380281681 47
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 17.60563380281681 60
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f44665f60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387558d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 12.676056338028104 21
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 18.309859154929484 48
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 18.309859154929484 61
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->6->19->8
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f3867df98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 13.380281690140777 22
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 16.197183098591466 28
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 19.014084507042156 49
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 19.014084507042156 62
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 16.197183098591466 29
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 19.014084507042156 50
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 19.014084507042156 63
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 6.338028169014052 12
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 16.90140845070414 30
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 19.71830985915483 51
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 19.71830985915483 64
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 7.0422535211267245 13
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 17.60563380281681 31
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 20.4225352112675 52
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 20.4225352112675 65
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7de48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 15.492957746478794 26
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 18.309859154929484 32
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 21.126760563380174 53
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 21.126760563380174 66
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d5f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867df98> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96978> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 16.197183098591466 27
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 19.014084507042156 33
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 21.830985915492846 54
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 21.830985915492846 67
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d7f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 19.71830985915483 34
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 22.53521126760552 55
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 22.53521126760552 68
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d405f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 17.60563380281681 29
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 20.4225352112675 35
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 23.23943661971819 56
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 23.23943661971819 69
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d7f0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 17.60563380281681 30
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 20.4225352112675 36
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 23.23943661971819 57
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 23.23943661971819 70
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40198> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d5f8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867df98> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96978> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 9.859154929577414 19
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 17.60563380281681 31
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 20.4225352112675 37
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 23.23943661971819 58
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 23.23943661971819 71
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d7f0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 10.563380281690087 20
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 18.309859154929484 32
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 21.126760563380174 38
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 23.943661971830863 59
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 23.943661971830863 72
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba9b0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b080> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3869eeb8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 11.26760563380276 21
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 19.014084507042156 33
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 21.830985915492846 39
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 24.647887323943536 60
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 24.647887323943536 73
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->6->19->8->16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 19.71830985915483 34
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 22.53521126760552 40
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 25.35211267605621 61
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 25.35211267605621 74
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d1d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665f60> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387558d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 20.4225352112675 35
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 23.23943661971819 41
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 26.05633802816888 62
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 26.05633802816888 75
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 13.380281690140777 24
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 21.126760563380174 36
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 23.943661971830863 42
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 26.760563380281553 63
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 26.760563380281553 76
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f048> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3869eeb8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 13.380281690140777 25
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 21.126760563380174 37
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 23.943661971830863 43
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 26.760563380281553 64
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 26.760563380281553 77
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b4a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0f28> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 14.084507042253449 26
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 21.830985915492846 38
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 24.647887323943536 44
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 27.464788732394226 65
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 27.464788732394226 78
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 14.788732394366122 27
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 22.53521126760552 39
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 25.35211267605621 45
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 28.169014084506898 66
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 28.169014084506898 79
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b4a8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0f28> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 14.788732394366122 28
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 22.53521126760552 40
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 25.35211267605621 46
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 28.169014084506898 67
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 28.169014084506898 80
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 15.492957746478794 29
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 23.23943661971819 41
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 26.05633802816888 47
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 28.87323943661957 68
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 28.87323943661957 81
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b4a8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0f28> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 16.197183098591466 30
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 23.943661971830863 42
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 26.760563380281553 48
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 29.577464788732243 69
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 29.577464788732243 82
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719400> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 16.90140845070414 31
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 24.647887323943536 43
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 27.464788732394226 49
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 30.281690140844916 70
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 30.281690140844916 83
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4ba58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40908> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 17.60563380281681 32
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 25.35211267605621 44
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 28.169014084506898 50
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 30.985915492957588 71
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 30.985915492957588 84
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be10> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 17.60563380281681 33
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 25.35211267605621 45
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 28.169014084506898 51
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 30.985915492957588 72
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 30.985915492957588 85
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0d68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c676a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4ba58> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40908> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 18.309859154929484 34
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 26.05633802816888 46
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 28.87323943661957 52
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 31.69014084507026 73
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 31.69014084507026 86
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->6->19->8->16->3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719400> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 19.014084507042156 35
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 26.760563380281553 47
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 29.577464788732243 53
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 32.39436619718293 74
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 32.39436619718293 87
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 16.197183098591466 28
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 19.71830985915483 36
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 27.464788732394226 48
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 30.281690140844916 54
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 33.098591549295605 75
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 33.098591549295605 88
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67e48> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719400> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 16.197183098591466 29
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 19.71830985915483 37
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 27.464788732394226 49
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 30.281690140844916 55
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 33.098591549295605 76
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 33.098591549295605 89
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 16.90140845070414 30
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 20.4225352112675 38
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 28.169014084506898 50
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 30.985915492957588 56
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 33.80281690140828 77
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 33.80281690140828 90
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d405f8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 17.60563380281681 31
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 21.126760563380174 39
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 28.87323943661957 51
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 31.69014084507026 57
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 34.50704225352095 78
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 34.50704225352095 91
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c679e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 18.309859154929484 32
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 29.577464788732243 52
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 32.39436619718293 58
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 35.21126760563362 79
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 35.21126760563362 92
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c674e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c679e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 19.014084507042156 33
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 22.53521126760552 41
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 30.281690140844916 53
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 33.098591549295605 59
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 35.915492957746295 80
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 35.915492957746295 93
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c37b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c34a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b70> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38719400> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 19.71830985915483 34
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 23.23943661971819 42
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 30.985915492957588 54
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 33.80281690140828 60
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 36.61971830985897 81
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 36.61971830985897 94
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c34a8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b70> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38719400> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 19.71830985915483 35
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 23.23943661971819 43
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 30.985915492957588 55
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 33.80281690140828 61
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 36.61971830985897 82
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 36.61971830985897 95
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3320> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 20.4225352112675 36
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 23.943661971830863 44
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 31.69014084507026 56
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 34.50704225352095 62
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 37.32394366197164 83
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 37.32394366197164 96
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 20.4225352112675 37
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 23.943661971830863 45
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 31.69014084507026 57
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 34.50704225352095 63
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 37.32394366197164 84
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 37.32394366197164 97
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcda0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3320> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 21.126760563380174 38
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 24.647887323943536 46
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 32.39436619718293 58
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 35.21126760563362 64
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 38.02816901408431 85
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 38.02816901408431 98
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->6->19->8->16->3->15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 21.830985915492846 39
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 25.35211267605621 47
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 33.098591549295605 59
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 35.915492957746295 65
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 38.732394366196985 86
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 38.732394366196985 99
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 22.53521126760552 40
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 26.05633802816888 48
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 33.80281690140828 60
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 36.61971830985897 66
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 39.43661971830966 87
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 39.43661971830966 100
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
coverage_call_count 2400
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bc50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb00> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b00> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d405f8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 23.23943661971819 41
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 26.760563380281553 49
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 34.50704225352095 61
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 37.32394366197164 67
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 40.14084507042233 88
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 40.14084507042233 101
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3c50> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 23.23943661971819 42
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 26.760563380281553 50
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 34.50704225352095 62
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 37.32394366197164 68
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 40.14084507042233 89
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 40.14084507042233 102
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3c50> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 11.971830985915432 23
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 23.23943661971819 43
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 26.760563380281553 51
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 34.50704225352095 63
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 37.32394366197164 69
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 40.14084507042233 90
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 40.14084507042233 103
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3320> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 23.943661971830863 44
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 27.464788732394226 52
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 35.21126760563362 64
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 38.02816901408431 70
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 40.845070422535 91
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 40.845070422535 104
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 13.380281690140777 25
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 24.647887323943536 45
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 28.169014084506898 53
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 35.915492957746295 65
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 38.732394366196985 71
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 41.549295774647675 92
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 41.549295774647675 105
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5898> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc240> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3320> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 24.647887323943536 46
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 28.169014084506898 54
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 35.915492957746295 66
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 38.732394366196985 72
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 41.549295774647675 93
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 41.549295774647675 106
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c674e0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c679e8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 14.084507042253449 27
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 25.35211267605621 47
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 28.87323943661957 55
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 36.61971830985897 67
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 39.43661971830966 73
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 42.25352112676035 94
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 42.25352112676035 107
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->6->19->8->16->3->15->1
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 10.563380281690087 20
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 14.084507042253449 28
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 25.35211267605621 48
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 28.87323943661957 56
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 36.61971830985897 68
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 39.43661971830966 74
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 42.25352112676035 95
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 42.25352112676035 108
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e55c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 11.26760563380276 21
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 14.788732394366122 29
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 26.05633802816888 49
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 29.577464788732243 57
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 37.32394366197164 69
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 40.14084507042233 75
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 42.95774647887302 96
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 42.95774647887302 109
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e55c0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 15.492957746478794 30
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 26.760563380281553 50
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 30.281690140844916 58
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 38.02816901408431 70
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 40.845070422535 76
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 43.66197183098569 97
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 43.66197183098569 110
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d405f8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 16.197183098591466 31
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 27.464788732394226 51
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 30.985915492957588 59
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 38.732394366196985 71
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 41.549295774647675 77
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 44.366197183098365 98
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 44.366197183098365 111
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e55c0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 16.197183098591466 32
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 27.464788732394226 52
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 30.985915492957588 60
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 38.732394366196985 72
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 41.549295774647675 78
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 44.366197183098365 99
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 44.366197183098365 112
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 12.676056338028104 25
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 16.197183098591466 33
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 27.464788732394226 53
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 30.985915492957588 61
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 38.732394366196985 73
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 41.549295774647675 79
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 44.366197183098365 100
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 44.366197183098365 113
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 16.90140845070414 34
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 28.169014084506898 54
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 31.69014084507026 62
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 39.43661971830966 74
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 42.25352112676035 80
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 45.07042253521104 101
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 45.07042253521104 114
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f62b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40588> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c18> 14.084507042253449 27
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0240> 17.60563380281681 35
backprop <src.mcts.MCTS_Node object at 0x7f3f3867de80> 28.87323943661957 55
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d5f8> 32.39436619718293 63
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9a20> 40.14084507042233 75
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9de80> 42.95774647887302 81
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6588> 45.77464788732371 102
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 45.77464788732371 115
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->6->19->8->16->3->15->1->14
Best Reward: 0.7042253521126725
iteration: 78
found coverage increase 0.7042253521126725
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6c88> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba2b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba2b0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f1d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30195f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30265f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30268d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30265f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30195f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30192e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026828> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f710> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff60> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b801d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30949e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2baceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30262e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac240> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b711d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b711d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b711d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b711d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b7b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c4a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c676a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c676a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b710f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b710f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90faa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90faa0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc18> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3f387190f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d045c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30267f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303df60> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90efb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90efb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4470eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38755668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446654e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d58d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d58d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387652b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44665518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f93267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 3200
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446914e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446914e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446914e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387815f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6954e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfeb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446492e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446492e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446492e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387815f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387815f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 12
Completed Iteration #10
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44723ef0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 6
Completed Iteration #8
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38744128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f446e90f0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d613c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f2b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f68021e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 3500
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f68021e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f68021e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d527b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d527b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc91d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc91d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1eef0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9deb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b909b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b909b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6952b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30197b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30197b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30197b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 3700
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b800b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cfd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b164a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 23
Completed Iteration #24
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac7f0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47486a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47734e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47734e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47734e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47735f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47734e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47734e0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773208> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc080> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 3900
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47343c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47343c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47343c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47343c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47343c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47343c8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47340b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47345f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47345f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47345f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47340b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773630> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47732b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac710> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c47f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bace48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 4000
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8908> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47260f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47260f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 4100
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca4a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fba90> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7912b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7912b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7912b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7912b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7807f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7807f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca0b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca9e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f68021e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 4300
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4479cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7910f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7910f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e0f0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6696d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44723208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f93267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748550> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc09e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447df400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90efb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 4600
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90efb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f38765898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f68021e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6854a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6854a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc92e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c671d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387acd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387acb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c671d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba5f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 70.4225352112676
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebac8> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d403c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b000b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d400b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d400b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46963c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46963c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46965f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46967b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 4900
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcc88> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47730f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387192e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387192e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc18> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b167b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b167b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16390> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f90eebb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b164e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b164e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47269b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47269b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387558d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387558d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b160f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee47737f0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e150b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e153c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e152b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d401d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e152b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d401d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d401d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e156a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fbe0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46700f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47264e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67847b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47731d0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67599b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdc88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fda90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bef0> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46704e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 5600
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67595c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67595c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67595c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd5f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66697b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66697b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66697b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66697b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 70.4225352112676
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66112b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66112b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66117f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66117f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfe10> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 5800
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 5900
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b400> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61085c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61089b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619ba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61369b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61089e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61369b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61361d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61083c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61089b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61089b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61089b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61089b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61572e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bb00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60892e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089668> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f28> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67597b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e62e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67846d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e159b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f588> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 6200
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3867d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef305c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47268d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb671feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46700b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3867dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46709b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 12
Completed Iteration #11
Best Reward: 0
coverage_call_count 6300
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47266a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b71a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f4478a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c02c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46966d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb671f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d83c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4696128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46706d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bacda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46706d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46706d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a83c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef308c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b000f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef303dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef307f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c96cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef308cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef303d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b000f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3872c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4478add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46960f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386baa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386baa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f4470e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46960f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d80f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 6500
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38765668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446d62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ac470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d041d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d4b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c01d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44765ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2baceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38719a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386badd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65cd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc79ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38765e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f446c4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c671d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c671d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f447233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44723908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38719f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c670b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0b38> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38781cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d522e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d522e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef305cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3f0f669be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446fa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d7d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f93267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f93267240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f44691400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44691400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38755f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f44723780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef304bd68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2baceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4670b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3f387817b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44665b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d04b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387817b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cc9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f90efb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30f61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2baceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fbe10> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30194a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30194a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ecf8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b00da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c07d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f65c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44649eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f64c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d407f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d52390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3fdf53f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3869ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4773c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6f6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef30946a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46a8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef304ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef3094438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60894a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7809b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60894a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60894a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60894a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c05f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7caef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee46c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6cf0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f695278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46d8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0e48> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3026a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef3019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d1ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6759ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef30e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cac50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f93267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee46fb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66a16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672eeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 18
Completed Iteration #19
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aac18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c03d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f44691400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67426a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f446c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d9dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee475f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee47484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f38781470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61369b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f446a4518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b80a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb67428d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0c0d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f0f6bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f93267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4734438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c9f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66116a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2b16a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67425c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f38755588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67425c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f3868b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67425c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fdf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebf60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61577b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6c67358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb61571d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6e7f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4748320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f93267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f3868bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3f0f685358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6672588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659eb8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb672e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668bcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6611fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee4726a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61080b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61080b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6ce3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f386e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc7ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6120588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6089240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb619b2b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d6f6d8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528aa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ee6d27a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60971d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f208> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f387444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097d68> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6157da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb52486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529aa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb527ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fcc0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f93267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52480f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6108ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52480f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6659908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52480f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb528a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb60972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb618bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb60973c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb67d85f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb525abe0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb52173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6668> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb66c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb52173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb52176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb670a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef304b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb52174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dede80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ecc780be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248b00> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5248048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d565f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3f93267240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3ef2bf2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb61cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb663fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb528af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb52177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb52170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db42e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb619bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03e80> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb52177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb52170f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb670af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dedc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb525af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6145860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 70.4225352112676
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b208> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb529af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb5217ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb668b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb527efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dc6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc0b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ded198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d44b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d034e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db4208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb525a5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 7800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb663f828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d032b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4db41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d032b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d032b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4748> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fe80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dd3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c63a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb526ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6136a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d03f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c8d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4dede48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d2a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d1b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cfc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c53828> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c9fc18> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb6097908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4ce1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d56f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c7ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4c2bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3eb4cd4cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3eb4d9ecc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 70.4225352112676
initial coverage: 69.0141
time passed (minutes): 60.0657
iterations: 293
number of new inputs: 128
final coverage: 70.4225
total coverage increase: 1.40845
