Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fe1f5b28f28>, tc2=<function tc2 at 0x7fe1f5b39048>, tc3=<function tc3 at 0x7fe1f5b39158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 69.0141
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2898> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a012efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0164d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00817b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00817b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00817b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c23c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00812b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00197b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00197b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00197b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00190f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00190f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0164e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00694e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00694e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 200
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0164cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf822b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf822b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a012efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d63c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00692e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00692e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00692e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf274a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf274a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0164cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf195f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00487f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00487f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce866d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce920f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeeda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8c88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce929b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce929b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce929b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce929b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1c1de7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0794f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0192390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce929b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce929b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1c4086198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a01923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce924e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a01923c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1c1de71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdffd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048208> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce861d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00489b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00480f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00699b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce865c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce865c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 17
Completed Iteration #24
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf821d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf827f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 900
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeeeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec50> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf277f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf277f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf196a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf196a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00eca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe2e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0770b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0995f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0995f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a6d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a630> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440324e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440328d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00192b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440324e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00192b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440324e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1440324e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440324e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440326a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d095f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d099e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d095f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d099e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d099e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09780> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eabe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eabe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0992e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eabe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe144032550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 1300
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cce6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c607f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d094e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c95da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70d68> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 1400
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c709e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c077400> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 14
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 15
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 16
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 17
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 18
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 19
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 20
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.7042253521126725 7
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 21
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.7042253521126725 8
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 22
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.7042253521126725 9
backprop <src.mcts.MCTS_Node object at 0x7fe123c95438> 0.7042253521126725 23
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->1->27
Best Reward: 0.7042253521126725
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0.7042253521126725
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207825f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207914e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207914e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c950f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb89b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb89b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079de80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c950f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c950f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c600b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf276d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00196d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00196d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a01505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce866d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce866d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce866d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a160> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1c1de7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1c1de7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce921d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc0fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc0faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1c1de7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92470> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c313c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c313c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf587f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c705f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440320b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c705f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c70ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfcf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 0.7042253521126725 3
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfcf8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 0.7042253521126725 4
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 0.7042253521126725 5
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 0.7042253521126725 6
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 1.408450704225345 7
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 1.408450704225345 8
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 1.408450704225345 9
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 2.1126760563380174 10
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 2.1126760563380174 11
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 2.1126760563380174 12
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 2.81690140845069 13
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 2.81690140845069 14
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 2.81690140845069 15
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01daf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 2.81690140845069 16
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 2.81690140845069 17
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 3.5211267605633623 18
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 3.5211267605633623 19
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 3.5211267605633623 20
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1a00481d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 4.225352112676035 21
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ac8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 4.225352112676035 22
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00481d0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 4.225352112676035 12
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 4.225352112676035 23
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c706a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00481d0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 4.929577464788707 24
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 4.929577464788707 14
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 4.929577464788707 25
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe144032b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf7b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3860> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c706a0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00481d0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 5.63380281690138 15
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 5.63380281690138 26
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c077780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 6.338028169014052 16
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 6.338028169014052 27
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 6.338028169014052 17
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 6.338028169014052 28
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 6.338028169014052 18
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 6.338028169014052 29
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c706a0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00481d0> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 6.338028169014052 19
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 6.338028169014052 30
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfcf8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 7.0422535211267245 20
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 7.0422535211267245 31
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 7.0422535211267245 21
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 7.0422535211267245 32
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea358> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 7.0422535211267245 22
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 7.0422535211267245 33
Completed Iteration #18
Best Reward: 0.7042253521126725
coverage_call_count 2100
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 7.0422535211267245 23
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 7.0422535211267245 34
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82f60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4588> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 7.746478873239397 24
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 7.746478873239397 35
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 7.746478873239397 25
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 7.746478873239397 36
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe144032b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 8.45070422535207 26
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 8.45070422535207 37
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14cf827b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf5f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032b38> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 9.154929577464742 27
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 9.154929577464742 38
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 9.859154929577414 28
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 9.859154929577414 39
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 9.859154929577414 29
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 9.859154929577414 40
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82f60> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4588> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 10.563380281690087 30
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 10.563380281690087 41
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c0994a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4cc0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82f60> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4588> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 5.63380281690138 11
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 11.26760563380276 31
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 11.26760563380276 42
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 11.26760563380276 32
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 11.26760563380276 43
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123d090b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 11.971830985915432 33
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 11.971830985915432 44
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123d09ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d090b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 12.676056338028104 34
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 12.676056338028104 45
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123d09ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 7.746478873239397 15
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 13.380281690140777 35
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 13.380281690140777 46
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 8.45070422535207 16
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 14.084507042253449 36
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 14.084507042253449 47
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->8->19
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1207914a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 9.154929577464742 17
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 14.788732394366122 37
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 14.788732394366122 48
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bf28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207914a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 15.492957746478794 38
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 15.492957746478794 49
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123cdff98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09ba8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e48> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d090b8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 16.197183098591466 39
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 16.197183098591466 50
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 16.90140845070414 40
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 16.90140845070414 51
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c099e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf906a0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09ac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 11.26760563380276 17
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 17.60563380281681 41
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 17.60563380281681 52
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf827b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf5f8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe144032b38> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 17.60563380281681 42
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 17.60563380281681 53
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09ba8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e48> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d090b8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 11.971830985915432 23
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 17.60563380281681 43
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 17.60563380281681 54
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ae48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf906a0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09ac8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 18.309859154929484 44
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 18.309859154929484 55
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bf28> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069f60> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe1207914a8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 11.971830985915432 21
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 12.676056338028104 25
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 18.309859154929484 45
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 18.309859154929484 56
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 19.014084507042156 46
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 19.014084507042156 57
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a198> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 14.084507042253449 27
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 19.71830985915483 47
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 19.71830985915483 58
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->8->19->6
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe144032d68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcf8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a198> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 14.788732394366122 28
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 20.4225352112675 48
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 20.4225352112675 59
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 14.788732394366122 25
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 15.492957746478794 29
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 21.126760563380174 49
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 21.126760563380174 60
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 15.492957746478794 26
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 16.197183098591466 30
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 21.830985915492846 50
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 21.830985915492846 61
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 16.197183098591466 27
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 16.90140845070414 31
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 22.53521126760552 51
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 22.53521126760552 62
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14cf908d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3d30> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 16.90140845070414 28
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 17.60563380281681 32
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 23.23943661971819 52
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 23.23943661971819 63
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 17.60563380281681 29
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 18.309859154929484 33
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 23.943661971830863 53
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 23.943661971830863 64
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123c57438> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 18.309859154929484 30
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 19.014084507042156 34
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 24.647887323943536 54
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 24.647887323943536 65
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fa90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 19.014084507042156 31
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 19.71830985915483 35
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 25.35211267605621 55
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 25.35211267605621 66
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 19.71830985915483 32
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 20.4225352112675 36
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 26.05633802816888 56
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 26.05633802816888 67
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebc50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fa90> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 10.563380281690087 16
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 20.4225352112675 33
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 21.126760563380174 37
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 26.760563380281553 57
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 26.760563380281553 68
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb630> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 20.4225352112675 34
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 21.126760563380174 38
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 26.760563380281553 58
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 26.760563380281553 69
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123d09978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 9.859154929577414 15
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 21.126760563380174 35
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 21.830985915492846 39
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 27.464788732394226 59
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 27.464788732394226 70
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a860> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a898> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 21.126760563380174 36
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 27.464788732394226 60
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 27.464788732394226 71
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->8->19->6->11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a3c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a898> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09128> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 21.830985915492846 37
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 22.53521126760552 41
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 28.169014084506898 61
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 28.169014084506898 72
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123c57ac8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 12.676056338028104 21
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 22.53521126760552 38
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 23.23943661971819 42
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 28.87323943661957 62
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 28.87323943661957 73
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 13.380281690140777 22
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 23.23943661971819 39
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 23.943661971830863 43
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 29.577464788732243 63
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 29.577464788732243 74
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1207821d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207820b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 14.084507042253449 23
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 23.943661971830863 40
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 24.647887323943536 44
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 30.281690140844916 64
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 30.281690140844916 75
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1207823c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 13.380281690140777 21
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 14.788732394366122 24
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 24.647887323943536 41
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 25.35211267605621 45
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 30.985915492957588 65
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 30.985915492957588 76
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1249820f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782358> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb240> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 14.084507042253449 22
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 15.492957746478794 25
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 25.35211267605621 42
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 26.05633802816888 46
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 31.69014084507026 66
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 31.69014084507026 77
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe124982978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249827b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 14.788732394366122 23
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 16.197183098591466 26
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 26.05633802816888 43
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 26.760563380281553 47
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 32.39436619718293 67
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 32.39436619718293 78
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c0995c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782358> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb240> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 15.492957746478794 24
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 16.90140845070414 27
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 26.760563380281553 44
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 27.464788732394226 48
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 33.098591549295605 68
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 33.098591549295605 79
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
coverage_call_count 2200
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebb70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57ac8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 16.197183098591466 25
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 17.60563380281681 28
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 27.464788732394226 45
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 28.169014084506898 49
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 33.80281690140828 69
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 33.80281690140828 80
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe120782dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 16.90140845070414 26
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 18.309859154929484 29
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 28.169014084506898 46
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 28.87323943661957 50
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 34.50704225352095 70
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 34.50704225352095 81
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe120782550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782dd8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 17.60563380281681 27
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 19.014084507042156 30
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 28.87323943661957 47
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 29.577464788732243 51
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 35.21126760563362 71
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 35.21126760563362 82
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe120782f98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fa90> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 18.309859154929484 28
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 19.71830985915483 31
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 29.577464788732243 48
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 30.281690140844916 52
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 35.915492957746295 72
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 35.915492957746295 83
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->8->19->6->11->6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe124982710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a470> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fa90> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 19.014084507042156 29
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 20.4225352112675 32
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 30.281690140844916 49
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 30.985915492957588 53
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 36.61971830985897 73
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 36.61971830985897 84
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 19.71830985915483 30
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 21.126760563380174 33
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 30.985915492957588 50
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 31.69014084507026 54
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 37.32394366197164 74
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 37.32394366197164 85
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe12438f828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f5f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 20.4225352112675 31
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 21.830985915492846 34
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 31.69014084507026 51
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 32.39436619718293 55
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 38.02816901408431 75
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 38.02816901408431 86
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1249f39e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207820b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 21.126760563380174 32
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 22.53521126760552 35
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 32.39436619718293 52
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 33.098591549295605 56
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 38.732394366196985 76
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 38.732394366196985 87
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 21.126760563380174 33
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 22.53521126760552 36
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 32.39436619718293 53
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 33.098591549295605 57
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 38.732394366196985 77
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 38.732394366196985 88
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe120782518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 21.830985915492846 34
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 23.23943661971819 37
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 33.098591549295605 54
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 33.80281690140828 58
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 39.43661971830966 78
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 39.43661971830966 89
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe124982e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb198> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 22.53521126760552 35
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 23.943661971830863 38
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 33.80281690140828 55
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 34.50704225352095 59
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 40.14084507042233 79
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 40.14084507042233 90
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe12438f860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249827b8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 23.23943661971819 36
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 24.647887323943536 39
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 34.50704225352095 56
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 35.21126760563362 60
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 40.845070422535 80
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 40.845070422535 91
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe12438f470> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 9.859154929577414 16
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 11.971830985915432 19
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 23.943661971830863 37
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 25.35211267605621 40
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 35.21126760563362 57
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 35.915492957746295 61
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 41.549295774647675 81
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 41.549295774647675 92
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f5f8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0b8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 10.563380281690087 17
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 12.676056338028104 20
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 24.647887323943536 38
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 26.05633802816888 41
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 35.915492957746295 58
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 36.61971830985897 62
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 42.25352112676035 82
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 42.25352112676035 93
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a86d8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f470> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 11.26760563380276 18
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 13.380281690140777 21
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 25.35211267605621 39
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 26.760563380281553 42
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 36.61971830985897 59
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 37.32394366197164 63
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 42.95774647887302 83
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 42.95774647887302 94
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982978> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249827b8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 14.084507042253449 22
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 26.05633802816888 40
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 27.464788732394226 43
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 37.32394366197164 60
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 38.02816901408431 64
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 43.66197183098569 84
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 43.66197183098569 95
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->8->19->6->11->6->19
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 14.084507042253449 23
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 26.05633802816888 41
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 27.464788732394226 44
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 37.32394366197164 61
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 38.02816901408431 65
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 43.66197183098569 85
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 43.66197183098569 96
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f470> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 14.084507042253449 24
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 26.05633802816888 42
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 27.464788732394226 45
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 37.32394366197164 62
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 38.02816901408431 66
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 43.66197183098569 86
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 43.66197183098569 97
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb198> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 11.26760563380276 21
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 26.05633802816888 43
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 27.464788732394226 46
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 37.32394366197164 63
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 38.02816901408431 67
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 43.66197183098569 87
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 43.66197183098569 98
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebe10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57080> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 26.760563380281553 44
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 28.169014084506898 47
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 38.02816901408431 64
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 38.732394366196985 68
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 44.366197183098365 88
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 44.366197183098365 99
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe124982748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a86d8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438f470> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 27.464788732394226 45
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 28.87323943661957 48
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 38.732394366196985 65
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 39.43661971830966 69
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 45.07042253521104 89
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 45.07042253521104 100
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438f470> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 12.676056338028104 24
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 15.492957746478794 28
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 27.464788732394226 46
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 28.87323943661957 49
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 38.732394366196985 66
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 39.43661971830966 70
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 45.07042253521104 90
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 45.07042253521104 101
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1243b29b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8898> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a86d8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438f470> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 13.380281690140777 25
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 16.197183098591466 29
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 28.169014084506898 47
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 29.577464788732243 50
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 39.43661971830966 67
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 40.14084507042233 71
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 45.77464788732371 91
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 45.77464788732371 102
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f470> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 16.197183098591466 30
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 28.169014084506898 48
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 29.577464788732243 51
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 39.43661971830966 68
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 40.14084507042233 72
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 45.77464788732371 92
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 45.77464788732371 103
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe12434dbe0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438f5f8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0b8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 14.084507042253449 27
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 16.90140845070414 31
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 28.87323943661957 49
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 30.281690140844916 52
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 40.14084507042233 69
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 40.845070422535 73
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 46.47887323943638 93
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 46.47887323943638 104
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dbe0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d898> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438f5f8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0b8> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 14.084507042253449 28
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 16.90140845070414 32
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 28.87323943661957 50
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 30.281690140844916 53
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 40.14084507042233 70
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 40.845070422535 74
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 46.47887323943638 94
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 46.47887323943638 105
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 14.084507042253449 29
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 16.90140845070414 33
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 28.87323943661957 51
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 30.281690140844916 54
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 40.14084507042233 71
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 40.845070422535 75
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 46.47887323943638 95
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 46.47887323943638 106
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1243a80b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fa90> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 5.63380281690138 10
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 14.788732394366122 30
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 17.60563380281681 34
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 29.577464788732243 52
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 30.985915492957588 55
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 40.845070422535 72
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 41.549295774647675 76
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 47.183098591549054 96
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 47.183098591549054 107
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe124982a90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a80f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebc50> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fa90> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 15.492957746478794 31
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 18.309859154929484 35
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 30.281690140844916 53
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 31.69014084507026 56
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 41.549295774647675 73
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 42.25352112676035 77
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 47.88732394366173 97
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 47.88732394366173 108
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->8->19->6->11->6->19->2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f39e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe1207820b8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 16.197183098591466 32
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 19.014084507042156 36
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 30.985915492957588 54
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 32.39436619718293 57
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 42.25352112676035 74
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 42.95774647887302 78
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 48.5915492957744 98
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 48.5915492957744 109
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe14c099710> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2978> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249f39e8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe1207820b8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 16.90140845070414 33
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 19.71830985915483 37
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 31.69014084507026 55
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 33.098591549295605 58
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 42.95774647887302 75
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 43.66197183098569 79
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 49.29577464788707 99
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 49.29577464788707 110
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe123c570b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2978> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249f39e8> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe1207820b8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 17.60563380281681 34
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 20.4225352112675 38
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 32.39436619718293 56
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 33.80281690140828 59
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 43.66197183098569 76
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 44.366197183098365 80
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 49.999999999999744 100
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 49.999999999999744 111
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe124365128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebe10> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c57080> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 18.309859154929484 35
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 21.126760563380174 39
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 33.098591549295605 57
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 34.50704225352095 60
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 44.366197183098365 77
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 45.07042253521104 81
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 50.70422535211242 101
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 50.70422535211242 112
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8f98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207820b8> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 19.014084507042156 36
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 21.830985915492846 40
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 33.80281690140828 58
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 35.21126760563362 61
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 45.07042253521104 78
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 45.77464788732371 82
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 51.40845070422509 102
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 51.40845070422509 113
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe12438fd30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57080> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 7.746478873239397 12
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 19.71830985915483 37
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 22.53521126760552 41
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 34.50704225352095 59
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 35.915492957746295 62
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 45.77464788732371 79
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 46.47887323943638 83
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 52.11267605633776 103
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 52.11267605633776 114
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebbe0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f3c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57438> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c57080> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 8.45070422535207 13
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 20.4225352112675 38
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 23.23943661971819 42
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 35.21126760563362 60
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 36.61971830985897 63
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 46.47887323943638 80
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 47.183098591549054 84
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 52.816901408450434 104
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 52.816901408450434 115
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe12434d390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57080> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 9.154929577464742 14
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 21.126760563380174 39
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 23.943661971830863 43
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 35.915492957746295 61
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 37.32394366197164 64
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 47.183098591549054 81
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 47.88732394366173 85
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 53.52112676056311 105
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 53.52112676056311 116
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207821d0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fe1207820b8> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 21.126760563380174 40
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 23.943661971830863 44
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 35.915492957746295 62
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 37.32394366197164 65
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 47.183098591549054 82
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 47.88732394366173 86
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 53.52112676056311 106
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 53.52112676056311 117
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207821d0> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fe1207820b8> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 21.126760563380174 41
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 23.943661971830863 45
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 35.915492957746295 63
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 37.32394366197164 66
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 47.183098591549054 83
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 47.88732394366173 87
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 53.52112676056311 107
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 53.52112676056311 118
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2978> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fe1249f39e8> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fe1207820b8> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 21.830985915492846 42
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 24.647887323943536 46
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 36.61971830985897 64
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 38.02816901408431 67
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 47.88732394366173 84
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 48.5915492957744 88
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 54.22535211267578 108
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 54.22535211267578 119
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe1243720f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365c88> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebbe0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438f3c8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c57438> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c57080> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 22.53521126760552 43
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 25.35211267605621 47
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 37.32394366197164 65
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 38.732394366196985 68
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 48.5915492957744 85
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 49.29577464788707 89
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 54.92957746478845 109
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 54.92957746478845 120
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fe12434df98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57080> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 23.23943661971819 44
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08240> 26.05633802816888 48
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 38.02816901408431 66
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf470> 39.43661971830966 69
backprop <src.mcts.MCTS_Node object at 0x7fe14c0778d0> 49.29577464788707 86
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 49.999999999999744 90
backprop <src.mcts.MCTS_Node object at 0x7fe123cb84a8> 55.633802816901124 110
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 55.633802816901124 121
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->8->19->6->11->6->19->2->0
Best Reward: 0.7042253521126725
iteration: 78
found coverage increase 0.7042253521126725
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243728d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249821d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2400
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1c50> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243658d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242867f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242867f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243726a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242f96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a15c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242090b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d080> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124246ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124224f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124224ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfeba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef60> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe20dc7ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243654a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243654a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe20dc7ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243650f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243650f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243650f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c573c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243650f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d090b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d092b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf905c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c708d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c708d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf908d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf908d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf908d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c57ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1c4086198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb83c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb83c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb83c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440325c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440325c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1440325c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc0fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe120791e48> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d091d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440320b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce921d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1440325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce925c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce925c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf825c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf191d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bfd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0995c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0995c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc0faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0995c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c954a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c954a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c954a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92080> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 70.4225352112676
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cced68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c319b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c959b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c959b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf900b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf900b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf900b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf900b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243726d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc0faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242465c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242465c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 3400
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242099e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242099e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242099e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242099e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c95c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123ccea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242099e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427af98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 3500
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dfed30> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ada0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12079d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120782048> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 14
Completed Iteration #20
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12430e828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242249e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f54a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f58d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d67780> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd9e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 3800
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242093c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12430e518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109041d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109041d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109048d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109049b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108879e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d67e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b23c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108622b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108620f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 4100
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b400> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108338d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103de5f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242240b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103dec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c828> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f50f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d35c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12433e8d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc0fa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242099b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124286e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243725c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123ccecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cced68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cced68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfa90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf191d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf191d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce921d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08b00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12438f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249dff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced82e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf821d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c077278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea390> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe144032b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0192390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0192390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56f60> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe20dc0b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 13
Completed Iteration #11
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b22b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124365710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8e48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c06b320> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 4800
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095ba20> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427a048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243722b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242463c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8240> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 4
Completed Iteration #5
Best Reward: 0
coverage_call_count 4900
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0772e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0772e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108776d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108776d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5198> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109827f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5000
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120782a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a21d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103ece80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a585c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a062e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a065c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a061d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a679b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a061d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a671d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa91d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a334a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a334a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 5300
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef2e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035efbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035efbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035effd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035efbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035efbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 17
Completed Iteration #18
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b65f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035efd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035062b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035066a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035069e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035067b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035069e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035067b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035069e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035065f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10352b4e0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035706a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035707b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035706a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a58da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034edf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ede10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fce48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034edcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034edcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034edcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10352b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035065c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034995f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034999e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034999e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034995f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034995f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103570eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034996d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10345a1d0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035efef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035a07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345aeb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034296a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034392e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 10
Completed Iteration #15
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034291d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103429080> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034999b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f995f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f995f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f995f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f995f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102faeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102faec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fae7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 5900
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034999b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fae4e0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103439c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b8d0> 0.0 11
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f07e10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035063c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035066a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035060f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f07550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a330f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12434d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cebe978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cebeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12434deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a33d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035c1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31898> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 6100
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103506ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c31a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094cd68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11094c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfe9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11094c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11094c7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dfef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103506ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a674a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f1cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035062e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ceb4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a67320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe12431dcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12430ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11095b978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12427af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe12427af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0eacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0ead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103aa9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdcf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c3ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce868d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0019a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de44a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a33198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035062e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035062e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035157b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124246630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035157b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035062e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035157b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035157b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe103515d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120782630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0007d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207911d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123db2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe120791860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103515668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe120791438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d569e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00483c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d569e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d569e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207914a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103515e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf4b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d566a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dd60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a90048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d67748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124246048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243b24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a67080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12427a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdeb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c57e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124982908> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf82978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a016c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d09710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a01507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0069320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124982710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ced88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d09f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0774a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe144032908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c06bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0774a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf27400> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110862470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12430ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f07f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cf40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110862da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf40f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf40f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a90048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c70c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c57400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c703c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14ce92be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c077da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf190f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12079d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf084a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123de4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12079d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124372c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c0992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc0faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249f37f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a009e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124372358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a002f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12438f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123ccefd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a19e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c04a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d67588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cdfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe12433ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249df080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cce2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123d56550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12431deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1249df0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1a015a1d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00c2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109822e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1109822e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cb8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 6600
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c08af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110982f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c05cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0150668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a82b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a82b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a82b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a82b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1bc168f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c08a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c05c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110982390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14ce86b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a00b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103aa90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11095beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cf4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123de4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c956d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123db26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00d6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a58128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110833080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108334a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe110877dd8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c70198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1a00ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124286f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242097f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242097f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207ebda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14c0996d8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124365160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11091aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108a2048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123cceba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034291d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103decf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11091aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034398d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124224550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103429cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123d56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034398d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe12433eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103429e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfeea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110833cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108771d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf58278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfdf160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf581d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1a0081b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123c60048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14c099978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1207eb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108771d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103de400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1249f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe14cf089b0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034394e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034394e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14c099908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034396d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034394e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 6800
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8550> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034edf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108b29e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe124286588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf08908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe120791d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108b2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124286c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b6d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103470828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fbf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103470828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034703c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe124209d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 16
Completed Iteration #15
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034995c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034995c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6390> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cfee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035dea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035de3c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe1035deeb8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034493c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10341a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1108f80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103499160> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f07b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103439d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110877198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1103dee10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe95f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110904550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124209860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110904518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1242a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10345a080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a062e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a065c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a065c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103429358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103499128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123c60978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10345a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102faeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102faecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102faef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123cce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10345a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe103546358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103499c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103439240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe110887470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11080b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a062e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fe92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f993c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102faefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f994e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f994e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f993c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2aeb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035700f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f99278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 7200
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020da080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020c04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11092b6d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1109046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fd5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103470048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f994e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a062e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102faef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a060f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a060f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f994e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f994e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a060f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a060f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a4a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110887470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020da978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103a06400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102fae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10352b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1243a8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020dacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034496a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102099470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102099278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102099b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020da160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102099dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103546b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020da860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103449cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1108f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102099208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1243a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102099748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10352b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fe9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102099828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe110877198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11080b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103449518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a06cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe103570710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020da7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020da7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102faee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f998d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f998d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe102063a20> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 7400
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1103ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1035707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe123dbdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103a060f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe11083fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe124224a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe102063048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe14cf199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f7b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102089cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102fae3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020daf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102099d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020daf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d36d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10203f518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101980748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034fc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103546160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a550> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101980b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f99940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101980b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020630f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101980630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10341a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020630f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f2a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101980b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101955240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101955390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101955eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101955f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101955cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101955278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101955128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102f994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102f99e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101955da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019555f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200bf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200bf98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10212b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10200b9b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102faef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10206f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019551d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101980ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201aac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10212bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019ebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10200bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019d39b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019424a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019424a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1034e1668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10192e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 7800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe101890400> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018aeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10200b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10201a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5dd8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10186a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10186a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae6a0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10201acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10186af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10186af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018053c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10186aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10186aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018aeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10203f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10186a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10186aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10186a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe102063358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101805e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10192e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018aeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101967470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018162e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011db128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011db5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011db2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011db0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011db780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018167b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011db828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0588> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011dba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011db9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011db278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011db7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011db518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011db518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1034494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018167b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1020da828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 8000
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101980ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018167b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018efa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101890cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101816860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe101816358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10192e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1019d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe103570860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018aeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102089b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011cf898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1018051d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011cfa20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101144390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101144518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101144748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101144240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101144550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe102063390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0470> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 304
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10185c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10206fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10186a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10191f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10191f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe10185cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101805cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101816b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe101967278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1018e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1019b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe101942400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe1011f0630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe1011dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe10203f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe1011b0438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 305
found coverage increase 0
Current Total Coverage 70.4225352112676
initial coverage: 69.0141
time passed (minutes): 60.1979
iterations: 306
number of new inputs: 128
final coverage: 70.4225
total coverage increase: 1.40845
