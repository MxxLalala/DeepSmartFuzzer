Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fd93ad94f28>, tc2=<function tc2 at 0x7fd93ada5048>, tc3=<function tc3 at 0x7fd93ada5158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 7.82443
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01474a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01080f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01729b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01472e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01081d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01081d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01472e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015de48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01246a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01389b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01389b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01389b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01476a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01476a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01476a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01476a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f29b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b015def0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00426a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add68> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00426d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a59e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890061048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 400
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a55f8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90926fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b069e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd9093142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90926fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd9093147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90926fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900612b0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900297b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900297b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b069e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900297b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900615f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900615f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900612e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ded68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ded68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd906f93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01083c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01080f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd906f93400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89004d4e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8900295f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ade48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00add30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00588d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900610f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01386d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 7.8244274809160315
coverage_call_count 800
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00426a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac18> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601427b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601427b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601425c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601425c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89003a4e0> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601536a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860142438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01720b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01471d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601132b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601133c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601130f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601130f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 1000
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01088d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b53c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b50f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601137f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601134e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601134e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccbe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601139e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600811d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600813c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600813c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dbe0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600342e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600342e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600818d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 1200
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86006d320> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601425f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601133c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600810b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6358> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587752e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587757f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587619b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 1400
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587616a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587611d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587611d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d29e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586e77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601132b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601132b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601132b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860113d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00588d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b51d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01475c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01084a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01084a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01084a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd90935df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900292e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900292e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900292e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900292e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601130b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 1700
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd90926fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd906f932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd90931f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5b00> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601132b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 7.8244274809160315
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b064aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01725f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a60b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860081e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd906f932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00427b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd89001ac18> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc7b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3ef0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b064ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 2000
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860034eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ada90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e05f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601135f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce668> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600343c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587610f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587610f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 11
Completed Iteration #16
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587610f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870fa58> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858775860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587612e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601680f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601680f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587612e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 2200
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d05f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900619b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761438> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391400b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 2300
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391562b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587615f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587615f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391debe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391afe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391afe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839140c50> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83911c390> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600813c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 2400
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391561d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391561d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910dda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd839156f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391afc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391afc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391afc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390ded68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390ded68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390ded68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390492b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890061518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 2600
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390190f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390199e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838bd23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd23c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd23c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f93240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd23c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839035ac8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2e10> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 2700
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd90931f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391dee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391dedd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860034cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860034390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0138d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b064a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd90931f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86011d748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587616d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b068af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd90926ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838bd25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587e09e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f80f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd906f80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd909314a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd909314710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89001a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00425f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860081a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89001aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0042320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00422e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838bd2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391deb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391deb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86008d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858775b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 2900
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172080> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb978> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0058128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001ff60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89004d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a02b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860153588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858761198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd890029c18> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890029e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 12
Completed Iteration #19
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd860153748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390254e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390197f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86008d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390259b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83912bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390254e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390197f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390259b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390259b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390250b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86011d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0124f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83919cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860153eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860113dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b000ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586e70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00de9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839025cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390946a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd858792f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900b9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587920f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89003a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839094cc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860113dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391d09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8390940b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858775390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b067f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391de438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd89004d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839019860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8586d2518> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b000c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0172c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b015d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8391af0f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839019c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b06b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83919c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890029470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83912ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8586e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858761c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391af208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860142b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839094f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839140f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839025a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86006dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd89003a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601681d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8601681d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860168358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839057828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd858792a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390fb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd860168c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd860168c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839025f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910da90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ceeb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0108320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8900a5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83910dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390deef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839140b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83910d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391560b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839057550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391560b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587d34a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83911cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85870f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867aa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd860142550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86005ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390497f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390497f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd839049dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86005ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839094a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 3500
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 8
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b001f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0fd0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83906f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83910d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839140da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831ecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838be0f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8900614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd890061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839057518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7668> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b00adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8390de320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83906f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839156cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83831ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83831eb70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382f77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85867a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382f75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2470> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838240780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838240b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838240cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838240710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382408d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382408d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382408d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838240f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839156cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240320> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838240cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b002db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85871f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85870f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382e25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd839049f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838240278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838250a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838250198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838250dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 10
Completed Iteration #8
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d08d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83830ec18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838250630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838230390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce48> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838230dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838230470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838250780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85871f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390deef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83830e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8587e0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838240ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83827c1d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83911cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85867add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838230cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 3800
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382504a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838230b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8382aa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821db70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83818a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83818a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838230b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83818a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86006d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd85873bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838230940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8391f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838240fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c25f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c25f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c25f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83831efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd890061e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838250dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b0147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83831ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2668> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83818aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83818a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83818a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838250780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83818aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83821de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838230400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83818a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381484a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381484a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381484a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381481d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838170470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838170668> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83821de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83820cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8390e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838be0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838250e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b69b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd839049908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838170828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838170dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838126780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83820cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838126160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838126cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83827c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838126e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838126a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838159978> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838126e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381325f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838170c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381325f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380c62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381326a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8600b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838159470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838148e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83818ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381325f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838170748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838132160> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8b01cea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8601683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838250e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838148518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381b6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd85873bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381f8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381c2d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838170438> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838126080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8382f7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86006d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83827c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838132e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8381266a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd838126208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838085748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838085c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838085fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838085198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838094320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838085e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838094390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838094588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838085550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838132048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838085940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838085748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380852b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8380948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838085e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838094b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838085e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838094fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838085e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838094438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd838126278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd838094208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8380d7d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 7.8244274809160315
initial coverage: 7.82443
time passed (minutes): 60.0625
iterations: 160
number of new inputs: 0
final coverage: 7.82443
total coverage increase: 0
