Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fdefadbdf28>, tc2=<function tc2 at 0x7fdefadcc048>, tc3=<function tc3 at 0x7fdefadcc158>, tfc_threshold=3300000, time_period=3600, verbose=True)
initial coverage: 67.1756
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707dfba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.3816793893129784 11
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906b22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.3816793893129784 12
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906b22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.3816793893129784 13
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.3816793893129784 14
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707aecf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.7633587786259568 15
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.7633587786259568 16
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.7633587786259568 17
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.7633587786259568 18
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 0.7633587786259568 8
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.7633587786259568 19
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7079b5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 1.1450381679389352 9
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 1.1450381679389352 20
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 1.5267175572519136 10
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 1.5267175572519136 21
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 1.908396946564892 11
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 1.908396946564892 22
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707eed30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 2.2900763358778704 23
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 2.2900763358778704 13
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 2.2900763358778704 24
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70785eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b5c0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 2.671755725190849 25
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707ee0f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 3.053435114503827 26
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 3.053435114503827 27
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7074d080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707aee10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785eb8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785e48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b5c0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 3.4351145038168056 28
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70759630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 3.816793893129784 29
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707ee908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b5c0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 4.198473282442762 30
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707ee710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae5c0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707dfba8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 4.580152671755741 20
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 4.580152671755741 31
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707aebe0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bb70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee0f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 4.961832061068719 21
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 4.961832061068719 32
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 4.961832061068719 22
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 4.961832061068719 33
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7079b080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 5.343511450381698 23
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 5.343511450381698 34
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7074d438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee588> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 5.725190839694676 24
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 5.725190839694676 35
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 6.106870229007654 25
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 6.106870229007654 36
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70759be0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 6.488549618320633 26
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 6.488549618320633 37
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 6.870229007633611 27
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 6.870229007633611 38
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7074dbe0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759550> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 7.25190839694659 28
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 7.25190839694659 39
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7076bb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee588> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 7.633587786259568 29
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 7.633587786259568 40
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7076bba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759550> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 8.015267175572546 30
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 8.015267175572546 41
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7076b048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 8.396946564885525 31
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 8.396946564885525 42
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee588> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 5.725190839694676 17
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 8.778625954198503 32
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 8.778625954198503 43
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
coverage_call_count 100
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->5->17
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70785860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 6.106870229007654 18
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 9.160305343511482 33
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 9.160305343511482 44
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707ae4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee0f0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 6.488549618320633 19
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 9.54198473282446 34
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 9.54198473282446 45
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70759a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 9.923664122137438 35
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 9.923664122137438 46
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70759048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 10.305343511450417 36
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 10.305343511450417 47
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707ae550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759a90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 10.687022900763395 37
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 10.687022900763395 48
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee9e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 11.068702290076374 38
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 11.068702290076374 49
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7076b390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076bc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 8.396946564885525 24
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 11.450381679389352 39
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 11.450381679389352 50
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70702748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076bfd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 11.83206106870233 40
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 11.83206106870233 51
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70702f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b080> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 12.213740458015309 41
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 12.213740458015309 52
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->5->17->3
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70722c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076bc50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 9.54198473282446 27
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 12.595419847328287 42
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 12.595419847328287 53
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70722fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 12.977099236641266 43
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 12.977099236641266 54
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70722da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 10.305343511450417 29
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 13.358778625954244 44
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 13.358778625954244 55
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707aed68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074dfd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722c18> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076bc50> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 10.687022900763395 30
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 13.740458015267222 45
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 13.740458015267222 56
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b390> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076bc50> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 10.687022900763395 31
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 13.740458015267222 46
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 13.740458015267222 57
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7076b278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 11.068702290076374 32
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 14.1221374045802 47
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 14.1221374045802 58
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70702eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074dfd0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70722c18> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde7076bc50> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 11.450381679389352 33
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 14.50381679389318 48
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 14.50381679389318 59
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70722f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 8.396946564885525 24
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 11.83206106870233 34
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 14.885496183206158 49
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 14.885496183206158 60
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70702358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722f28> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70722dd8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 12.213740458015309 35
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 15.267175572519136 50
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 15.267175572519136 61
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->5->17->3->14
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 12.595419847328287 36
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 15.648854961832114 51
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 15.648854961832114 62
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722da0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 9.160305343511482 27
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 12.595419847328287 37
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 15.648854961832114 52
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 15.648854961832114 63
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706d0550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707023c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722fd0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 9.54198473282446 28
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 12.977099236641266 38
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 16.030534351145093 53
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 16.030534351145093 64
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706d09b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707023c8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70722fd0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 9.923664122137438 29
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 13.358778625954244 39
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 16.41221374045807 54
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 16.41221374045807 65
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 10.305343511450417 30
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 13.740458015267222 40
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 16.79389312977105 55
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 16.79389312977105 66
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707855f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d09b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707023c8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde70722fd0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 10.687022900763395 31
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 14.1221374045802 41
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 17.175572519084028 56
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 17.175572519084028 67
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7072fef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 11.068702290076374 32
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 14.50381679389318 42
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 17.557251908397006 57
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 17.557251908397006 68
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707225c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707855f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ae7b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d09b0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707023c8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde70722fd0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 11.450381679389352 33
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 14.885496183206158 43
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 17.938931297709985 58
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 17.938931297709985 69
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706d0a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 11.83206106870233 34
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 15.267175572519136 44
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 18.320610687022963 59
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 18.320610687022963 70
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722fd0> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 11.83206106870233 35
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 15.267175572519136 45
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 18.320610687022963 60
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 18.320610687022963 71
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706de438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722fd0> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 15.648854961832114 46
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 18.70229007633594 61
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 18.70229007633594 72
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->5->17->3->14->3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de0b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0a90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 12.595419847328287 37
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 16.030534351145093 47
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 19.08396946564892 62
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 19.08396946564892 73
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706dee48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0a90> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 8.396946564885525 26
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 12.977099236641266 38
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 16.41221374045807 48
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 19.4656488549619 63
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 19.4656488549619 74
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70722278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775240> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 8.778625954198503 27
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 13.358778625954244 39
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 16.79389312977105 49
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 19.847328244274877 64
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 19.847328244274877 75
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706d0dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775240> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 9.160305343511482 28
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 13.740458015267222 40
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 17.175572519084028 50
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 20.229007633587855 65
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 20.229007633587855 76
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706ded30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 9.54198473282446 29
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 14.1221374045802 41
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 17.557251908397006 51
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 20.610687022900834 66
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 20.610687022900834 77
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706f3438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 14.50381679389318 42
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 17.938931297709985 52
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 20.992366412213812 67
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 20.992366412213812 78
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706f38d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de0b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d0a90> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 7.633587786259568 23
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 14.885496183206158 43
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 18.320610687022963 53
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 21.37404580152679 68
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 21.37404580152679 79
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706f3e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 8.015267175572546 24
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 10.687022900763395 32
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 15.267175572519136 44
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 18.70229007633594 54
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 21.75572519083977 69
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 21.75572519083977 80
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706f3ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0a90> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 8.396946564885525 25
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 11.068702290076374 33
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 15.648854961832114 45
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 19.08396946564892 55
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 22.137404580152747 70
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 22.137404580152747 81
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 8.778625954198503 26
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 11.450381679389352 34
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 16.030534351145093 46
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 19.4656488549619 56
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 22.519083969465726 71
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 22.519083969465726 82
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7067ab70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de4e0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 9.160305343511482 27
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 11.83206106870233 35
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 16.41221374045807 47
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 19.847328244274877 57
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 22.900763358778704 72
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 22.900763358778704 83
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70722588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 9.54198473282446 28
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 16.79389312977105 48
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 20.229007633587855 58
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 23.282442748091682 73
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 23.282442748091682 84
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->5->17->3->14->3->15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706d04e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3438> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 9.923664122137438 29
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 12.595419847328287 37
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 17.175572519084028 49
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 20.610687022900834 59
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 23.66412213740466 74
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 23.66412213740466 85
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
coverage_call_count 200
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706f3cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722278> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70775240> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 10.305343511450417 30
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 12.977099236641266 38
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 17.557251908397006 50
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 20.992366412213812 60
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 24.04580152671764 75
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 24.04580152671764 86
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706decc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fb00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 10.687022900763395 31
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 13.358778625954244 39
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 17.938931297709985 51
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 21.37404580152679 61
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 24.427480916030618 76
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 24.427480916030618 87
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7067aac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 11.068702290076374 32
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 13.740458015267222 40
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 18.320610687022963 52
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 21.75572519083977 62
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 24.809160305343596 77
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 24.809160305343596 88
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7067af98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0860> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde706f3438> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 11.450381679389352 33
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 14.1221374045802 41
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 18.70229007633594 53
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 22.137404580152747 63
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 25.190839694656574 78
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 25.190839694656574 89
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706904a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 11.83206106870233 34
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 14.50381679389318 42
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 19.08396946564892 54
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 22.519083969465726 64
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 25.572519083969553 79
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 25.572519083969553 90
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7067af60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 12.213740458015309 35
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 14.885496183206158 43
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 19.4656488549619 55
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 22.900763358778704 65
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 25.95419847328253 80
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 25.95419847328253 91
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70690b38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0860> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde706f3438> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 12.595419847328287 36
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 15.267175572519136 44
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 19.847328244274877 56
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 23.282442748091682 66
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 26.33587786259551 81
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 26.33587786259551 92
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7067a128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067add8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 12.977099236641266 37
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 15.648854961832114 45
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 20.229007633587855 57
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 23.66412213740466 67
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 26.717557251908488 82
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 26.717557251908488 93
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7067ae48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a128> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7067add8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 13.358778625954244 38
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 16.030534351145093 46
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 20.610687022900834 58
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 24.04580152671764 68
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 27.099236641221466 83
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 27.099236641221466 94
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3ef0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde706f3d68> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d0a90> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 13.358778625954244 39
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 16.030534351145093 47
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 20.610687022900834 59
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 24.04580152671764 69
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 27.099236641221466 84
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 27.099236641221466 95
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70690978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067add8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 10.305343511450417 29
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 13.740458015267222 40
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 16.41221374045807 48
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 20.992366412213812 60
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 24.427480916030618 70
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 27.480916030534445 85
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 27.480916030534445 96
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->5->17->3->14->3->15->1
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70690f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775240> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 9.54198473282446 27
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 10.687022900763395 30
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 14.1221374045802 41
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 16.79389312977105 49
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 21.37404580152679 61
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 24.809160305343596 71
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 27.862595419847423 86
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 27.862595419847423 97
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706defd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775240> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 11.068702290076374 31
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 14.50381679389318 42
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 17.175572519084028 50
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 21.75572519083977 62
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 25.190839694656574 72
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 28.2442748091604 87
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 28.2442748091604 98
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706b59e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690f60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70775240> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 10.305343511450417 29
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 11.450381679389352 32
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 14.885496183206158 43
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 17.557251908397006 51
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 22.137404580152747 63
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 25.572519083969553 73
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 28.62595419847338 88
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 28.62595419847338 99
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7067a198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067ab38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722278> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde70775240> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 10.687022900763395 30
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 11.83206106870233 33
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 15.267175572519136 44
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 17.938931297709985 52
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 22.519083969465726 64
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 25.95419847328253 74
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 29.00763358778636 89
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 29.00763358778636 100
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7067a358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775240> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 11.068702290076374 31
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 12.213740458015309 34
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 15.648854961832114 45
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 18.320610687022963 53
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 22.900763358778704 65
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 26.33587786259551 75
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 29.389312977099337 90
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 29.389312977099337 101
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fef0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072fb00> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 11.068702290076374 32
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 12.213740458015309 35
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 15.648854961832114 46
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 18.320610687022963 54
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 22.900763358778704 66
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 26.33587786259551 76
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 29.389312977099337 91
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 29.389312977099337 102
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70690cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 11.450381679389352 33
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 12.595419847328287 36
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 16.030534351145093 47
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 18.70229007633594 55
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 23.282442748091682 67
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5f8> 26.717557251908488 77
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 29.770992366412315 92
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 29.770992366412315 103
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->5->17->3->14->3->15->1->1
Best Reward: 0.3816793893129784
iteration: 1
found coverage increase 0.3816793893129784
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706aa940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aae10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706909b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706f33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066ff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c35f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a20> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706b5fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a12e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a12e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a19b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597469b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706525c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706525c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706525c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597159b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597156d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf15628fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeb80b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a5f8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707757b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707750f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906b5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906b5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707759b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707759b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde7072f668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707857f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde707750b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707df9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707aed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707aed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079b6d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 0.3816793893129784 4
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde59746cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 0.7633587786259568 5
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707750f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.1450381679389352 6
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.1450381679389352 7
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a668> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.1450381679389352 8
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.5267175572519136 9
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a668> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.5267175572519136 10
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a668> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.5267175572519136 11
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.5267175572519136 12
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.5267175572519136 13
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.5267175572519136 14
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.5267175572519136 15
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707759e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe80> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.908396946564892 16
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746cc0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 1.908396946564892 10
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 1.908396946564892 17
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 2.2900763358778704 18
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 2.2900763358778704 19
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 2.2900763358778704 13
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 2.2900763358778704 20
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde9068f5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 2.671755725190849 21
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 2.671755725190849 15
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 2.671755725190849 22
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70652588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 3.053435114503827 23
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70652208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707759e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe80> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 3.4351145038168056 24
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 3.4351145038168056 18
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 3.4351145038168056 25
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde596fdda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 3.816793893129784 26
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 3.816793893129784 27
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe80> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 3.816793893129784 21
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 3.816793893129784 28
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 3.816793893129784 22
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 3.816793893129784 29
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 3.816793893129784 23
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 3.816793893129784 30
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde5976f2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 4.198473282442762 24
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 4.198473282442762 31
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f2b0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd5c0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 4.198473282442762 25
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 4.198473282442762 32
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde597c3f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 4.580152671755741 26
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 4.580152671755741 33
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7074dc18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3f60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 4.961832061068719 27
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 4.961832061068719 34
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd5c0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 4.961832061068719 28
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 4.961832061068719 35
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f5c0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 4.961832061068719 29
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 4.961832061068719 36
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde9068fb38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 5.343511450381698 30
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 5.343511450381698 37
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 5.343511450381698 31
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 5.343511450381698 38
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70652b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3f60> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 5.725190839694676 32
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 5.725190839694676 39
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 5.725190839694676 33
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 5.725190839694676 40
Completed Iteration #16
Best Reward: 0.3816793893129784
coverage_call_count 800
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde9068f5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 6.106870229007654 34
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 6.106870229007654 41
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde707224e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 3.4351145038168056 15
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 6.488549618320633 42
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 6.488549618320633 36
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 6.488549618320633 43
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde5976fe10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f7b8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 3.816793893129784 17
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 6.870229007633611 44
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652e10> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde597c3f60> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 1.908396946564892 10
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 6.870229007633611 45
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->8->12
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fb38> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 6.870229007633611 39
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 6.870229007633611 46
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70759ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde707594a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fb38> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 7.25190839694659 40
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 7.25190839694659 47
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 7.25190839694659 41
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 7.25190839694659 48
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 7.25190839694659 42
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 7.25190839694659 49
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 7.633587786259568 43
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 7.633587786259568 50
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde597460f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 8.015267175572546 44
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 8.015267175572546 51
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707594a8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fb38> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 8.015267175572546 45
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 8.015267175572546 52
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 1.5267175572519136 10
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 4.961832061068719 26
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 8.015267175572546 46
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 8.015267175572546 53
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 1.5267175572519136 11
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 4.961832061068719 27
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 8.015267175572546 47
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 8.015267175572546 54
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 1.5267175572519136 12
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 4.961832061068719 28
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 8.015267175572546 48
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 8.015267175572546 55
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 1.908396946564892 13
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 5.343511450381698 29
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 8.396946564885525 49
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 8.396946564885525 56
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde5976f3c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 2.2900763358778704 14
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 5.725190839694676 30
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 8.778625954198503 50
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 8.778625954198503 57
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->8->12->5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7076b630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 2.671755725190849 15
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 9.160305343511482 51
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 9.160305343511482 58
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7076b4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 6.488549618320633 32
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 9.54198473282446 52
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 9.54198473282446 59
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 3.053435114503827 17
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 6.488549618320633 33
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 9.54198473282446 53
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 9.54198473282446 60
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 3.053435114503827 18
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 6.488549618320633 34
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 9.54198473282446 54
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 9.54198473282446 61
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690da0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 3.053435114503827 19
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 9.54198473282446 55
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 9.54198473282446 62
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 3.053435114503827 20
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 6.488549618320633 36
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 9.54198473282446 56
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 9.54198473282446 63
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70652fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f3c8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70690da0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 3.4351145038168056 21
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 9.923664122137438 57
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 9.923664122137438 64
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 3.4351145038168056 22
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 9.923664122137438 58
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 9.923664122137438 65
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde7076b208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b2b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde5976f3c8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde70690da0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 3.816793893129784 23
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 7.25190839694659 39
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 10.305343511450417 59
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 10.305343511450417 66
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690da0> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 3.816793893129784 24
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 7.25190839694659 40
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 10.305343511450417 60
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 10.305343511450417 67
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70690e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 4.198473282442762 25
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 7.633587786259568 41
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 10.687022900763395 61
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 10.687022900763395 68
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706f3a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690240> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 4.580152671755741 26
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 8.015267175572546 42
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 11.068702290076374 62
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 11.068702290076374 69
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b208> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076b2b0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde5976f3c8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde70690da0> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 4.580152671755741 27
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 11.068702290076374 63
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 11.068702290076374 70
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b4e0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 4.580152671755741 28
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 8.015267175572546 44
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 11.068702290076374 64
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 11.068702290076374 71
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706aa2e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b2b0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde5976f3c8> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fde70690da0> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 4.961832061068719 29
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 11.450381679389352 65
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 11.450381679389352 72
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->8->12->5->1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 4.580152671755741 22
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 5.343511450381698 30
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 8.778625954198503 46
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 11.83206106870233 66
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 11.83206106870233 73
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597460f0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 5.343511450381698 31
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 8.778625954198503 47
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 11.83206106870233 67
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 11.83206106870233 74
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 4.580152671755741 24
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 5.343511450381698 32
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 8.778625954198503 48
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 11.83206106870233 68
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 11.83206106870233 75
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706aa6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 5.725190839694676 33
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 9.160305343511482 49
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 12.213740458015309 69
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 12.213740458015309 76
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706d00f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 5.343511450381698 26
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 6.106870229007654 34
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 9.54198473282446 50
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 12.595419847328287 70
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 12.595419847328287 77
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3a20> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde70690240> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076b630> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 5.343511450381698 27
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 6.106870229007654 35
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 9.54198473282446 51
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 12.595419847328287 71
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 12.595419847328287 78
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde597f53c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d00b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 5.725190839694676 28
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 6.488549618320633 36
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 9.923664122137438 52
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 12.977099236641266 72
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 12.977099236641266 79
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde597f59e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b4e0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.106870229007654 29
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 10.305343511450417 53
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 13.358778625954244 73
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 13.358778625954244 80
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.106870229007654 30
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 10.305343511450417 54
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 13.358778625954244 74
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 13.358778625954244 81
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690e80> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 6.870229007633611 39
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 10.305343511450417 55
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 13.358778625954244 75
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 13.358778625954244 82
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690240> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fde7076b630> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.106870229007654 32
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 6.870229007633611 40
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 10.305343511450417 56
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 13.358778625954244 76
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 13.358778625954244 83
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706f3e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f59e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076b4e0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.488549618320633 33
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 7.25190839694659 41
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 10.687022900763395 57
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 13.740458015267222 77
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 13.740458015267222 84
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->8->12->5->1->4
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d00b8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.580152671755741 24
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.488549618320633 34
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 7.25190839694659 42
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 10.687022900763395 58
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 13.740458015267222 78
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 13.740458015267222 85
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d00b8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.580152671755741 25
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 7.25190839694659 43
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 10.687022900763395 59
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 13.740458015267222 79
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 13.740458015267222 86
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde597d46d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.961832061068719 26
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.870229007633611 36
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 7.633587786259568 44
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 11.068702290076374 60
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 14.1221374045802 80
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 14.1221374045802 87
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.961832061068719 27
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 7.633587786259568 45
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 11.068702290076374 61
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 14.1221374045802 81
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 14.1221374045802 88
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 1.1450381679389352 8
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 4.961832061068719 28
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 7.633587786259568 46
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 11.068702290076374 62
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 14.1221374045802 82
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 14.1221374045802 89
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 5.343511450381698 29
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 7.25190839694659 39
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 8.015267175572546 47
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 11.450381679389352 63
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 14.50381679389318 83
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 14.50381679389318 90
Completed Iteration #18
Best Reward: 0.3816793893129784
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d46d8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 1.5267175572519136 10
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 5.343511450381698 30
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 7.25190839694659 40
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 8.015267175572546 48
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 11.450381679389352 64
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 14.50381679389318 84
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 14.50381679389318 91
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 1.5267175572519136 11
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 5.343511450381698 31
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 7.25190839694659 41
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 8.015267175572546 49
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 11.450381679389352 65
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 14.50381679389318 85
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 14.50381679389318 92
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 1.5267175572519136 12
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 5.343511450381698 32
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 7.25190839694659 42
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 8.015267175572546 50
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 11.450381679389352 66
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 14.50381679389318 86
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 14.50381679389318 93
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->8->12->5->1->4->4
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706aab00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 1.908396946564892 13
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 5.725190839694676 33
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 7.633587786259568 43
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 8.396946564885525 51
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 11.83206106870233 67
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 14.885496183206158 87
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 14.885496183206158 94
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 1.908396946564892 14
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 5.725190839694676 34
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 7.633587786259568 44
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 8.396946564885525 52
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 11.83206106870233 68
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 14.885496183206158 88
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 14.885496183206158 95
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde597d4c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 2.2900763358778704 15
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 6.106870229007654 35
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 8.015267175572546 45
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 8.778625954198503 53
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 12.213740458015309 69
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 15.267175572519136 89
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 15.267175572519136 96
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d46d8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 2.2900763358778704 16
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 6.106870229007654 36
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 8.015267175572546 46
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 8.778625954198503 54
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 12.213740458015309 70
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 15.267175572519136 90
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 15.267175572519136 97
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706de780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 2.671755725190849 17
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 6.488549618320633 37
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 8.396946564885525 47
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 9.160305343511482 55
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 12.595419847328287 71
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 15.648854961832114 91
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 15.648854961832114 98
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706ded30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 3.053435114503827 18
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 8.778625954198503 48
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 9.54198473282446 56
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 12.977099236641266 72
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 16.030534351145093 92
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 16.030534351145093 99
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 3.053435114503827 19
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 6.870229007633611 39
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 8.778625954198503 49
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 9.54198473282446 57
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 12.977099236641266 73
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 16.030534351145093 93
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 16.030534351145093 100
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706b53c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706ded30> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 3.4351145038168056 20
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 7.25190839694659 40
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 9.160305343511482 50
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 9.923664122137438 58
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 13.358778625954244 74
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 16.41221374045807 94
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 16.41221374045807 101
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de780> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 3.4351145038168056 21
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 7.25190839694659 41
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 9.160305343511482 51
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 9.923664122137438 59
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 13.358778625954244 75
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 16.41221374045807 95
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 16.41221374045807 102
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->8->12->5->1->4->4->7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1828> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 3.816793893129784 22
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 7.633587786259568 42
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 9.54198473282446 52
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 10.305343511450417 60
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 13.740458015267222 76
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 16.79389312977105 96
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 16.79389312977105 103
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706b5b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 3.4351145038168056 15
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 4.198473282442762 23
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 9.923664122137438 53
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 10.687022900763395 61
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 14.1221374045802 77
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 17.175572519084028 97
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 17.175572519084028 104
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1828> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 4.198473282442762 24
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 8.015267175572546 44
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 9.923664122137438 54
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 10.687022900763395 62
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 14.1221374045802 78
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 17.175572519084028 98
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 17.175572519084028 105
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1828> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 4.198473282442762 25
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 8.015267175572546 45
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 9.923664122137438 55
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 10.687022900763395 63
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 14.1221374045802 79
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 17.175572519084028 99
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 17.175572519084028 106
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 3.4351145038168056 18
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 4.198473282442762 26
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 8.015267175572546 46
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 9.923664122137438 56
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 10.687022900763395 64
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 14.1221374045802 80
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 17.175572519084028 100
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 17.175572519084028 107
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5390> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 4.580152671755741 27
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 8.396946564885525 47
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 10.305343511450417 57
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 11.068702290076374 65
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 14.50381679389318 81
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 17.557251908397006 101
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 17.557251908397006 108
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde70759da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa8d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 4.961832061068719 28
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 8.778625954198503 48
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 10.687022900763395 58
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 11.450381679389352 66
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 14.885496183206158 82
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 17.938931297709985 102
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 17.938931297709985 109
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde597d4160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1828> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 4.580152671755741 21
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 5.343511450381698 29
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 9.160305343511482 49
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 11.068702290076374 59
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 11.83206106870233 67
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 15.267175572519136 83
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 18.320610687022963 103
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 18.320610687022963 110
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706defd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde706def60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4160> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1828> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 4.961832061068719 22
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 5.725190839694676 30
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 9.54198473282446 50
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 11.450381679389352 60
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 12.213740458015309 68
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 15.648854961832114 84
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 18.70229007633594 104
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 18.70229007633594 111
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde706de198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 5.343511450381698 23
backprop <src.mcts.MCTS_Node object at 0x7fde596fdd30> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 9.923664122137438 51
backprop <src.mcts.MCTS_Node object at 0x7fde9068fa20> 11.83206106870233 61
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 12.595419847328287 69
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 16.030534351145093 85
backprop <src.mcts.MCTS_Node object at 0x7fde597150b8> 19.08396946564892 105
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 19.08396946564892 112
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->8->12->5->1->4->4->7->1
Best Reward: 0.3816793893129784
iteration: 21
found coverage increase 0.3816793893129784
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707022b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597360b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707026d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707026d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde580aac50> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580680b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580686a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580680b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580686a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde58054b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580796a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580543c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580543c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580682b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580796a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580543c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580543c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580796a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.3816793893129642 5
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.3816793893129642 6
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.3816793893129642 7
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.3816793893129642 8
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.3816793893129642 9
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.7633587786259284 10
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.7633587786259284 11
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.7633587786259284 6
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.7633587786259284 12
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.7633587786259284 13
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.7633587786259284 7
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.7633587786259284 14
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 0.7633587786259284 15
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde400467b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 1.1450381679388926 8
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.1450381679388926 16
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.1450381679388926 17
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.1450381679388926 18
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 1.1450381679388926 9
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.1450381679388926 19
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde40051470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde400467b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 1.5267175572518568 10
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.5267175572518568 20
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 1.5267175572518568 11
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.5267175572518568 21
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde40051eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051390> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051470> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046860> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde400467b8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 1.908396946564821 12
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.908396946564821 22
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 1.908396946564821 13
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.908396946564821 23
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 1.908396946564821 14
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.908396946564821 24
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 1.908396946564821 15
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 1.908396946564821 25
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde59736198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 2.290076335877785 16
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 2.290076335877785 26
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 2.290076335877785 17
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 2.290076335877785 27
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde40046ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 2.6717557251907493 18
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 2.6717557251907493 28
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736198> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde5800c518> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 2.6717557251907493 19
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 2.6717557251907493 29
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 3.0534351145037135 20
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 3.0534351145037135 30
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde400617f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 3.4351145038166777 21
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 3.4351145038166777 31
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 3.4351145038166777 22
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 3.4351145038166777 32
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde40051828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 3.816793893129642 23
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 3.816793893129642 33
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29460400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 4.198473282442606 24
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 4.198473282442606 34
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046860> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde400467b8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 4.198473282442606 25
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 4.198473282442606 35
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde400616d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e240> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 4.58015267175557 16
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 4.58015267175557 26
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 4.58015267175557 36
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29460550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde294608d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 4.9618320610685345 27
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 4.9618320610685345 37
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde706d09e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c518> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.343511450381499 28
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.343511450381499 38
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400617f0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.343511450381499 19
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.343511450381499 29
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.343511450381499 39
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046ba8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.343511450381499 20
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.343511450381499 30
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.343511450381499 40
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736198> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7fde5800c518> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.343511450381499 21
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.343511450381499 31
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.343511450381499 41
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29460dd8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.725190839694463 22
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.725190839694463 32
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.725190839694463 42
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->5->18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460dd8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 4.198473282442606 16
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.725190839694463 23
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.725190839694463 33
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.725190839694463 43
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400467b8> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 4.198473282442606 17
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.725190839694463 24
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.725190839694463 34
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.725190839694463 44
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 4.198473282442606 18
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.725190839694463 25
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.725190839694463 35
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.725190839694463 45
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046860> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7fde400467b8> 1.1450381679388926 7
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 4.198473282442606 19
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.725190839694463 26
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.725190839694463 36
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.725190839694463 46
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046ba8> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 4.198473282442606 20
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 5.725190839694463 27
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 5.725190839694463 37
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 5.725190839694463 47
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29460978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051828> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 4.58015267175557 21
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 6.106870229007427 28
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 6.106870229007427 38
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 6.106870229007427 48
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046ba8> 0.3816793893129642 5
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 4.58015267175557 22
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 6.106870229007427 29
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 6.106870229007427 39
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 6.106870229007427 49
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde58054048> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 4.9618320610685345 23
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 6.488549618320391 30
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 6.488549618320391 40
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 6.488549618320391 50
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde580548d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 5.343511450381499 24
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 6.870229007633355 31
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 6.870229007633355 41
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 6.870229007633355 51
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde2946eb00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046ba8> 0.7633587786259284 6
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 5.725190839694463 25
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 7.25190839694632 32
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 7.25190839694632 42
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 7.25190839694632 52
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde400619b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 6.106870229007427 26
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 7.633587786259284 33
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 7.633587786259284 43
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 7.633587786259284 53
Completed Iteration #18
Best Reward: 0.3816793893129642
coverage_call_count 1200
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde40051780> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460dd8> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 6.488549618320391 27
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 8.015267175572248 34
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 8.015267175572248 44
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 8.015267175572248 54
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460400> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 6.488549618320391 28
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 8.015267175572248 35
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 8.015267175572248 45
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 8.015267175572248 55
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29460518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051b38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde400617f0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 6.870229007633355 29
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 8.396946564885212 36
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 8.396946564885212 46
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 8.396946564885212 56
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde580542e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde580548d0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 7.25190839694632 30
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 8.778625954198176 37
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 8.778625954198176 47
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 8.778625954198176 57
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde580685c0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460400> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 7.633587786259284 31
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 9.16030534351114 38
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 9.16030534351114 48
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 9.16030534351114 58
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->5->18->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 7.633587786259284 32
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 9.16030534351114 39
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 9.16030534351114 49
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 9.16030534351114 59
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 1.5267175572518568 7
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 7.633587786259284 33
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 9.16030534351114 40
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 9.16030534351114 50
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 9.16030534351114 60
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde5801ba90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e240> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 8.015267175572248 34
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 9.541984732824105 41
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 9.541984732824105 51
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 9.541984732824105 61
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde2948ca90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 8.396946564885212 35
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 9.923664122137069 42
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 9.923664122137069 52
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 9.923664122137069 62
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 2.290076335877785 10
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 8.396946564885212 36
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 9.923664122137069 43
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 9.923664122137069 53
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 9.923664122137069 63
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400616d8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e240> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 2.290076335877785 11
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 8.396946564885212 37
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 9.923664122137069 44
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 9.923664122137069 54
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 9.923664122137069 64
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde40051860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 2.6717557251907493 12
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 8.778625954198176 38
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 10.305343511450033 45
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 10.305343511450033 55
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 10.305343511450033 65
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde40061710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051860> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 3.0534351145037135 13
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 9.16030534351114 39
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 10.687022900762997 46
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 10.687022900762997 56
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 10.687022900762997 66
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde58068ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 3.4351145038166777 14
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 9.541984732824105 40
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 11.068702290075962 47
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 11.068702290075962 57
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 11.068702290075962 67
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400616d8> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7fde2946e240> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 3.4351145038166777 15
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 9.541984732824105 41
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 11.068702290075962 48
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 11.068702290075962 58
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 11.068702290075962 68
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801ba90> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e240> 0.7633587786259284 6
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 3.4351145038166777 16
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 9.541984732824105 42
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 11.068702290075962 49
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 11.068702290075962 59
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 11.068702290075962 69
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->5->18->0->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 3.816793893129642 17
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 9.923664122137069 43
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 11.450381679388926 50
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 11.450381679388926 60
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 11.450381679388926 70
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29490dd8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 4.198473282442606 18
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 10.305343511450033 44
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 11.83206106870189 51
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 11.83206106870189 61
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 11.83206106870189 71
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29422588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948ca90> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 4.58015267175557 19
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 10.687022900762997 45
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 12.213740458014854 52
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 12.213740458014854 62
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 12.213740458014854 72
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29422898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 4.9618320610685345 20
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 11.068702290075962 46
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 12.595419847327818 53
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 12.595419847327818 63
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 12.595419847327818 73
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde5801bac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068ac8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 5.343511450381499 21
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 11.450381679388926 47
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 12.977099236640782 54
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 12.977099236640782 64
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 12.977099236640782 74
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 5.343511450381499 22
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 11.450381679388926 48
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 12.977099236640782 55
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 12.977099236640782 65
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 12.977099236640782 75
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 5.343511450381499 23
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 11.450381679388926 49
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 12.977099236640782 56
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 12.977099236640782 66
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 12.977099236640782 76
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde40061f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 4.58015267175557 16
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 5.725190839694463 24
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 11.83206106870189 50
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 13.358778625953747 57
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 13.358778625953747 67
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 13.358778625953747 77
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde2948cf28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bac8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde29422668> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde58068ac8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 6.106870229007427 25
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 12.213740458014854 51
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 13.74045801526671 58
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 13.74045801526671 68
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 13.74045801526671 78
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde294226d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422eb8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 6.488549618320391 26
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 12.595419847327818 52
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 14.122137404579675 59
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 14.122137404579675 69
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 14.122137404579675 79
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde2946ea20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948ca90> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 5.725190839694463 19
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 6.870229007633355 27
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 12.977099236640782 53
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 14.50381679389264 60
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 14.50381679389264 70
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 14.50381679389264 80
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 5.725190839694463 20
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 6.870229007633355 28
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 12.977099236640782 54
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 14.50381679389264 61
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 14.50381679389264 71
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 14.50381679389264 81
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->5->18->0->0->6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 5.725190839694463 21
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 6.870229007633355 29
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 12.977099236640782 55
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 14.50381679389264 62
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 14.50381679389264 72
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 14.50381679389264 82
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422898> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde29422eb8> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 5.725190839694463 22
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 6.870229007633355 30
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 12.977099236640782 56
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 14.50381679389264 63
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 14.50381679389264 73
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 14.50381679389264 83
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29453c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422eb8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 1.5267175572518568 7
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 6.106870229007427 23
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 7.25190839694632 31
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 13.358778625953747 57
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 14.885496183205603 64
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 14.885496183205603 74
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 14.885496183205603 84
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29453d68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 6.488549618320391 24
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 7.633587786259284 32
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 13.74045801526671 58
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 15.267175572518568 65
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 15.267175572518568 75
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 15.267175572518568 85
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29453d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c33c8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 6.870229007633355 25
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 8.015267175572248 33
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 14.122137404579675 59
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 15.648854961831532 66
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 15.648854961831532 76
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 15.648854961831532 86
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 7.25190839694632 26
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 8.396946564885212 34
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 14.50381679389264 60
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 16.030534351144496 67
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 16.030534351144496 77
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 16.030534351144496 87
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29453fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c33c8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 7.633587786259284 27
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 8.778625954198176 35
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 14.885496183205603 61
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 16.41221374045746 68
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 16.41221374045746 78
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 16.41221374045746 88
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422eb8> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 3.0534351145037135 12
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 7.633587786259284 28
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 8.778625954198176 36
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 14.885496183205603 62
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 16.41221374045746 69
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 16.41221374045746 79
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 16.41221374045746 89
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422c18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453d30> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c33c8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 8.015267175572248 29
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 9.16030534351114 37
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 15.267175572518568 63
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 16.793893129770424 70
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 16.793893129770424 80
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 16.793893129770424 90
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29422208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d9e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 8.396946564885212 30
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 9.541984732824105 38
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 15.648854961831532 64
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 17.17557251908339 71
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 17.17557251908339 81
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 17.17557251908339 91
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde59736dd8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 9.923664122137069 39
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 16.030534351144496 65
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 17.557251908396353 72
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 17.557251908396353 82
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 17.557251908396353 92
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde2946e748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 4.58015267175557 16
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 10.305343511450033 40
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 16.41221374045746 66
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 17.938931297709317 73
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 17.938931297709317 83
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 17.938931297709317 93
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->5->18->0->0->6->4
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde289c3b70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e748> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 9.541984732824105 33
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 10.687022900762997 41
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 16.793893129770424 67
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 18.32061068702228 74
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 18.32061068702228 84
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 18.32061068702228 94
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde289d9a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 9.923664122137069 34
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 11.068702290075962 42
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 17.17557251908339 68
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 18.702290076335245 75
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 18.702290076335245 85
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 18.702290076335245 95
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29460f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d9e8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 5.725190839694463 19
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 10.305343511450033 35
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 11.450381679388926 43
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 17.557251908396353 69
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 19.08396946564821 76
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 19.08396946564821 86
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 19.08396946564821 96
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde2943d860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 6.106870229007427 20
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 10.687022900762997 36
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 11.83206106870189 44
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 17.938931297709317 70
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 19.465648854961174 77
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 19.465648854961174 87
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 19.465648854961174 97
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453d68> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 6.106870229007427 21
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 10.687022900762997 37
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 11.83206106870189 45
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 17.938931297709317 71
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 19.465648854961174 78
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 19.465648854961174 88
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 19.465648854961174 98
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde289c30f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 6.488549618320391 22
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 11.068702290075962 38
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 12.213740458014854 46
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 18.32061068702228 72
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 19.847328244274138 79
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 19.847328244274138 89
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 19.847328244274138 99
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
coverage_call_count 1300
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453d68> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 6.488549618320391 23
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 11.068702290075962 39
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 12.213740458014854 47
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 18.32061068702228 73
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 19.847328244274138 80
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 19.847328244274138 90
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 19.847328244274138 100
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->5->18->0->0->6->4->1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde289ee6a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee0f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422208> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d9e8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 6.870229007633355 24
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 11.450381679388926 40
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 12.595419847327818 48
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 18.702290076335245 74
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 20.229007633587102 81
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 20.229007633587102 91
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 20.229007633587102 101
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 6.870229007633355 25
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 11.450381679388926 41
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 12.595419847327818 49
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 18.702290076335245 75
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 20.229007633587102 82
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 20.229007633587102 92
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 20.229007633587102 102
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde289eee10> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d9e8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 4.58015267175557 16
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 7.25190839694632 26
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 11.83206106870189 42
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 12.977099236640782 50
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 19.08396946564821 76
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 20.610687022900066 83
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 20.610687022900066 93
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 20.610687022900066 103
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29422198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee0f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde29422208> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943d9e8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 7.633587786259284 27
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 12.213740458014854 43
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 13.358778625953747 51
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 19.465648854961174 77
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 20.99236641221303 84
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 20.99236641221303 94
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 20.99236641221303 104
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29453710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee668> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 8.015267175572248 28
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 12.595419847327818 44
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 13.74045801526671 52
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 19.847328244274138 78
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 21.374045801525995 85
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 21.374045801525995 95
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 21.374045801525995 105
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde29490d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d98d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 5.725190839694463 19
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 8.396946564885212 29
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 12.977099236640782 45
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 14.122137404579675 53
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 20.229007633587102 79
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 21.75572519083896 86
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 21.75572519083896 96
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 21.75572519083896 106
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde289eeb38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde294531d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 6.106870229007427 20
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 8.778625954198176 30
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 13.358778625953747 46
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 14.50381679389264 54
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 20.610687022900066 80
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 22.137404580151923 87
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 22.137404580151923 97
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 22.137404580151923 107
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490d30> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d98d0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 6.106870229007427 21
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 13.358778625953747 47
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 14.50381679389264 55
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 20.610687022900066 81
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 22.137404580151923 88
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 22.137404580151923 98
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 22.137404580151923 108
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde289f5940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d98d0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde29453ef0> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7fde29453978> 6.488549618320391 22
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7fde400614a8> 13.74045801526671 48
backprop <src.mcts.MCTS_Node object at 0x7fde4003f7f0> 14.885496183205603 56
backprop <src.mcts.MCTS_Node object at 0x7fde4003f208> 20.99236641221303 82
backprop <src.mcts.MCTS_Node object at 0x7fde580546d8> 22.519083969464887 89
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 22.519083969464887 99
backprop <src.mcts.MCTS_Node object at 0x7fde580aacf8> 22.519083969464887 109
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->5->18->0->0->6->4->1->19
Best Reward: 0.3816793893129642
iteration: 28
found coverage increase 0.3816793893129642
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289945c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994048> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294220f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289576d8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289778d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289778d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289230f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289230f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e7f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 1500
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923668> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fde289c3630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288891d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288891d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288890b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288891d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288890b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7978> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294604e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580549b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400614e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde400468d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 7
Completed Iteration #10
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa128> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706defd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 1800
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde706d0898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400466d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400466d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706dee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706dee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706dee80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f5f60> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580544a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400463c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400463c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707596d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c36a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c36a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdf98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707aecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde9068f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70775a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fde707753c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046d30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf15628fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeb80b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597368d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597368d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de9b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59728780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597285f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 2300
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c37f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c37f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dfa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597154a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580794e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580794e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580791d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58079048> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bcc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c128> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289bc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294538d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294531d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294531d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294531d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453c88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289770f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289777f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289777f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400510f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400517b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289944a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400517b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28994ac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289942b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28994da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289576a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294226a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289577f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289576a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288d9320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294224a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294224a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2896a5c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ec50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2946e048> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde180702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde180703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde1805b470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288895c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288895c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288895c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde180706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2b0> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9208> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff57b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580791d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294906d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580791d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580791d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580791d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289c3780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597369e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597155f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289575f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec932afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde59746da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 2900
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294224a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294908d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70652128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294903c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597159e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597159e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706dee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706dee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de908> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294604a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294604a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 21
Completed Iteration #23
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400611d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400611d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec9293ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400611d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580682b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c30f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b470> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580540f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7074d908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906bf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706de630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 16
Completed Iteration #18
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906bf748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943def0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400516a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289bc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde400513c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580685c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eeef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bda0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906f4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40051ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde180702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde180703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde180702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde180700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597a1d30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948cac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde180700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe70b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706f3f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058810f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058810f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a588> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29453128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058940f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70785978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058940f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058501d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058501d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058501d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058501d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058501d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde05866940> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058754a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058754a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583dc50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946ea90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053b1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058754a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058754a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053734e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053734e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ce10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccc0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde058752b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2946e358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058752b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05344c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05373630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052cef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344ef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529ae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aac8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052bec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052bec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f1d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde052be5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4200
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052160b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262f98> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0523b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b470> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde580aa1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28923be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289237b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05226550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707593c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294602b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294602b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294537f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294602b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0583d908> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597f50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805bc88> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde580aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec933e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706f3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943d470> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec9293ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906b53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906f4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289c3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9400> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801ba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294908d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde9068f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294908d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58054588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58054908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597d47b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d0128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7066f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5976fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70759b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707aeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707aeda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706901d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2890e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707aeda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706901d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706901d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289f5f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec92bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1400> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde70702b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fe71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06fc39b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052167f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052167f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052165f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052165f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b080> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde596fd978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597a1978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289d9898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 4800
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7067ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28957320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29422208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058500b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058500b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052627b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05262a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053440b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a5f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288895f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0538a4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058507b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70722278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400465f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde400465f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058940b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d45f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde053d46d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ceda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58079a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0539c748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.3816793893129926 15
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.3816793893129926 16
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.3816793893129926 6
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.3816793893129926 17
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.3816793893129926 7
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.3816793893129926 18
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.3816793893129926 19
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.3816793893129926 20
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.3816793893129926 8
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.3816793893129926 21
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde180703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.3816793893129926 9
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.3816793893129926 22
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.3816793893129926 10
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.3816793893129926 23
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a9e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 0.7633587786259852 11
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 0.7633587786259852 24
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde05866390> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866160> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a9e8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 1.1450381679389778 12
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 1.1450381679389778 25
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58079780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 1.1450381679389778 13
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 1.1450381679389778 26
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 1.1450381679389778 14
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 1.1450381679389778 27
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180703c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 1.1450381679389778 15
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 1.1450381679389778 28
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde05262048> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690d68> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a9e8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 1.5267175572519704 16
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 1.5267175572519704 29
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 1.5267175572519704 17
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 1.5267175572519704 30
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 1.5267175572519704 18
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 1.5267175572519704 31
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 1.908396946564963 19
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 1.908396946564963 32
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 2.2900763358779557 20
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 2.2900763358779557 33
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #1
root->3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0530cc18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bdd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 2.6717557251909483 21
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 2.6717557251909483 34
Completed Iteration #0
Best Reward: 0.3816793893129926
coverage_call_count 5100
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 3.053435114503941 22
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 3.053435114503941 35
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde05373358> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 3.4351145038169335 23
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 3.4351145038169335 36
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde053b1320> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 3.816793893129926 24
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 3.816793893129926 37
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bdd8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 3.816793893129926 25
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 3.816793893129926 38
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde052f1cf8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bdd8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 4.198473282442919 26
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 4.198473282442919 39
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bdd8> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 4.198473282442919 27
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 4.198473282442919 40
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 4.198473282442919 28
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 4.198473282442919 41
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde05842d30> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 4.580152671755911 29
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 4.580152671755911 42
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 4.580152671755911 30
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 4.580152671755911 43
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde05373d68> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bdd8> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 3.816793893129926 15
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 4.961832061068904 31
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 4.961832061068904 44
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #2
root->3->26
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde053b1ac8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 4.198473282442919 16
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 5.343511450381897 32
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 5.343511450381897 45
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0529aa58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 4.580152671755911 17
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 5.725190839694889 33
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 5.725190839694889 46
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1d30> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262c88> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 4.961832061068904 18
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 6.106870229007882 34
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 6.106870229007882 47
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde052aa860> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 5.343511450381897 19
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 6.488549618320874 35
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 6.488549618320874 48
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 4.198473282442919 13
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 5.725190839694889 20
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 6.870229007633867 36
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 6.870229007633867 49
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde052aa5f8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 6.106870229007882 21
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 7.25190839694686 37
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 7.25190839694686 50
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #3
root->3->26->0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde28889eb8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1470> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529aa58> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 4.961832061068904 15
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 6.488549618320874 22
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 7.633587786259852 38
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 7.633587786259852 51
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde05866cf8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 5.343511450381897 16
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 6.870229007633867 23
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 8.015267175572845 39
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 8.015267175572845 52
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccf8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 5.725190839694889 17
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 7.25190839694686 24
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 8.396946564885837 40
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 8.396946564885837 53
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde052beeb8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 6.106870229007882 18
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 7.633587786259852 25
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 8.77862595419883 41
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 8.77862595419883 54
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1470> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fde0529aa58> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 3.4351145038169335 12
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 6.106870229007882 19
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 7.633587786259852 26
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 8.77862595419883 42
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 8.77862595419883 55
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde053734a8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde596fdef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 3.816793893129926 13
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 6.488549618320874 20
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 8.015267175572845 27
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 9.160305343511823 43
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 9.160305343511823 56
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde05875b38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 4.198473282442919 14
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 6.870229007633867 21
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 8.396946564885837 28
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 9.541984732824815 44
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 9.541984732824815 57
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #4
root->3->26->0->7
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b00> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6518> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875b38> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 4.580152671755911 15
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 7.25190839694686 22
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 8.77862595419883 29
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 9.923664122137808 45
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 9.923664122137808 58
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042cc9e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 4.198473282442919 13
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 4.961832061068904 16
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 7.633587786259852 23
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 9.160305343511823 30
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 10.3053435114508 46
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 10.3053435114508 59
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde05373c88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 5.343511450381897 17
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 8.015267175572845 24
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 9.541984732824815 31
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 10.687022900763793 47
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 10.687022900763793 60
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde053b15f8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 4.961832061068904 15
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 5.725190839694889 18
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 8.396946564885837 25
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 9.923664122137808 32
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 11.068702290076786 48
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 11.068702290076786 61
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0524f160> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373c88> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 5.343511450381897 16
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 6.106870229007882 19
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 8.77862595419883 26
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 10.3053435114508 33
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 11.450381679389778 49
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 11.450381679389778 62
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #5
root->3->26->0->7->0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0530cbe0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be7b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 5.725190839694889 17
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 6.488549618320874 20
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 9.160305343511823 27
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 10.687022900763793 34
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 11.832061068702771 50
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 11.832061068702771 63
Completed Iteration #0
Best Reward: 0.3816793893129926
coverage_call_count 5200
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cbe0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fde052be7b8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 5.725190839694889 18
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 6.488549618320874 21
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 9.160305343511823 28
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 10.687022900763793 35
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 11.832061068702771 51
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 11.832061068702771 64
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042d7ba8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 6.106870229007882 19
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 6.870229007633867 22
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 9.541984732824815 29
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 11.068702290076786 36
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 12.213740458015764 52
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 12.213740458015764 65
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be7b8> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 6.106870229007882 20
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 6.870229007633867 23
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 9.541984732824815 30
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 11.068702290076786 37
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 12.213740458015764 53
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 12.213740458015764 66
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 1.908396946564963 9
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 6.106870229007882 21
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 6.870229007633867 24
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 9.541984732824815 31
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 11.068702290076786 38
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 12.213740458015764 54
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 12.213740458015764 67
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042f7f98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 6.488549618320874 22
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 7.25190839694686 25
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 9.923664122137808 32
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 11.450381679389778 39
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 12.595419847328756 55
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 12.595419847328756 68
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042804a8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7ef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccf8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 2.6717557251909483 11
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 6.870229007633867 23
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 7.633587786259852 26
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 10.3053435114508 33
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 11.832061068702771 40
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 12.977099236641749 56
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 12.977099236641749 69
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #6
root->3->26->0->7->0->3
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042d7d68> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7ef0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccf8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 7.25190839694686 24
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 8.015267175572845 27
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 10.687022900763793 34
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 12.213740458015764 41
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 13.358778625954741 57
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 13.358778625954741 70
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042cc6a0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 7.633587786259852 25
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 8.396946564885837 28
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 11.068702290076786 35
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 12.595419847328756 42
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 13.740458015267734 58
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 13.740458015267734 71
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042cc0f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 3.816793893129926 14
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 8.015267175572845 26
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 8.77862595419883 29
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 11.450381679389778 36
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 12.977099236641749 43
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 14.122137404580727 59
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 14.122137404580727 72
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042f7978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 4.198473282442919 15
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 8.396946564885837 27
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 9.160305343511823 30
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 11.832061068702771 37
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 13.358778625954741 44
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 14.50381679389372 60
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 14.50381679389372 73
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde04280828> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 4.580152671755911 16
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 8.77862595419883 28
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 9.541984732824815 31
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 12.213740458015764 38
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 13.740458015267734 45
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 14.885496183206712 61
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 14.885496183206712 74
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0523b400> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 4.961832061068904 17
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 9.160305343511823 29
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 9.923664122137808 32
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 12.595419847328756 39
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 14.122137404580727 46
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 15.267175572519704 62
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 15.267175572519704 75
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0429f7b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f358> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7f98> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 4.580152671755911 13
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 5.343511450381897 18
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 9.541984732824815 30
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 10.3053435114508 33
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 12.977099236641749 40
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 14.50381679389372 47
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 15.648854961832697 63
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 15.648854961832697 76
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0429f940> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 4.961832061068904 14
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 5.725190839694889 19
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 9.923664122137808 31
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 10.687022900763793 34
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 13.358778625954741 41
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 14.885496183206712 48
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 16.03053435114569 64
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 16.03053435114569 77
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde042d7f98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 5.343511450381897 15
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 6.106870229007882 20
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 10.3053435114508 32
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 11.068702290076786 35
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 13.740458015267734 42
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 15.267175572519704 49
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 16.412213740458682 65
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 16.412213740458682 78
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #7
root->3->26->0->7->0->3->0
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde04280f98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7ef0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccf8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 5.725190839694889 16
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 6.488549618320874 21
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 10.687022900763793 33
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 11.450381679389778 36
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 14.122137404580727 43
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 15.648854961832697 50
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 16.793893129771675 66
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 16.793893129771675 79
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fde0429fe80> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7ef0> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fde0530ccf8> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 6.106870229007882 17
backprop <src.mcts.MCTS_Node object at 0x7fde052aa470> 6.870229007633867 22
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 11.068702290076786 34
backprop <src.mcts.MCTS_Node object at 0x7fde0530c048> 11.832061068702771 37
backprop <src.mcts.MCTS_Node object at 0x7fde058817b8> 14.50381679389372 44
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a438> 16.03053435114569 51
backprop <src.mcts.MCTS_Node object at 0x7fde180709b0> 17.175572519084668 67
backprop <src.mcts.MCTS_Node object at 0x7fde05881fd0> 17.175572519084668 80
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #8
root->3->26->0->7->0->3->0->5
Best Reward: 0.3816793893129926
iteration: 174
found coverage increase 0.3816793893129926
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04247898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc4a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04263668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042474e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042474e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 19
Completed Iteration #20
Best Reward: 0
coverage_call_count 5400
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde04220208> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd2e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d812b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d812b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d816d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded7b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042477b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3deda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042634e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042477b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042634e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042634e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 11
Completed Iteration #17
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d457f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d535f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d535f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3deda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7470> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dede80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d251d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d251d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d378d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d251d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d251d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04247b70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d458d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d458d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d377f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d377f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d140b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d538d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d538d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d538d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd908> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c593c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c590f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c594a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59ef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.3816793893129642 15
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.3816793893129642 16
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.3816793893129642 17
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.3816793893129642 18
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.3816793893129642 19
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.3816793893129642 20
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 0.3816793893129642 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.3816793893129642 21
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 0.3816793893129642 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.3816793893129642 22
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 0.3816793893129642 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.3816793893129642 23
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59ef0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 0.7633587786259284 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 0.7633587786259284 24
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 1.1450381679388926 9
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 1.1450381679388926 25
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dc50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 1.5267175572518568 10
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 1.5267175572518568 26
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 1.908396946564821 11
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 1.908396946564821 27
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 2.290076335877785 12
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 2.290076335877785 28
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dc50> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 2.290076335877785 13
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 2.290076335877785 29
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14630> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 2.290076335877785 14
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 2.290076335877785 30
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7ef60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 2.6717557251907493 15
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 2.6717557251907493 31
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 3.0534351145037135 16
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 3.0534351145037135 32
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21be0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 3.4351145038166777 17
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 3.4351145038166777 33
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e978> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 3.816793893129642 18
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 3.816793893129642 34
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c295c0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 4.198473282442606 19
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 4.198473282442606 35
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7eac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e978> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 4.58015267175557 20
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 4.58015267175557 36
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c295c0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 4.9618320610685345 21
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 4.9618320610685345 37
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29a20> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c295c0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 4.9618320610685345 22
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 4.9618320610685345 38
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 5.343511450381499 23
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 5.343511450381499 39
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->4->3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 5.725190839694463 24
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 5.725190839694463 40
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7ee48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 6.106870229007427 25
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 6.106870229007427 41
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 6.488549618320391 26
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 6.488549618320391 42
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21b38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21b70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21be0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 6.870229007633355 27
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 6.870229007633355 43
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 7.25190839694632 28
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 7.25190839694632 44
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e8d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29080> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21b38> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21b70> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21be0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 7.633587786259284 29
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 7.633587786259284 45
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 8.015267175572248 30
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 8.015267175572248 46
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3ad68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29fd0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 8.396946564885212 31
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 8.396946564885212 47
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3aa58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21c50> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 8.778625954198176 32
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 8.778625954198176 48
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37dd588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3ae80> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29da0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 9.16030534351114 33
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 9.16030534351114 49
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37dd9e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37dd1d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21be0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 9.541984732824105 34
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 9.541984732824105 50
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->4->3->3
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 9.541984732824105 35
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 9.541984732824105 51
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37e56d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31b00> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 9.923664122137069 36
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 9.923664122137069 52
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31b00> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 8.396946564885212 26
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 9.923664122137069 37
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 9.923664122137069 53
Completed Iteration #10
Best Reward: 0.3816793893129642
coverage_call_count 5900
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7ee48> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31b00> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 8.778625954198176 27
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 10.305343511450033 38
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 10.305343511450033 54
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dc88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31b00> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 9.16030534351114 28
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 10.687022900762997 39
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 10.687022900762997 55
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31b00> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 9.541984732824105 29
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 11.068702290075962 40
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 11.068702290075962 56
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37dd2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a470> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31b00> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 9.923664122137069 30
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 11.450381679388926 41
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 11.450381679388926 57
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37e56a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21c50> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 10.305343511450033 31
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 11.83206106870189 42
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 11.83206106870189 58
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5be0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 4.58015267175557 15
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 10.687022900762997 32
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 12.213740458014854 43
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 12.213740458014854 59
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->4->3->3->17
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5f98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 8.778625954198176 26
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 12.595419847327818 44
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 12.595419847327818 60
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37dd828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29940> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21c50> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 5.343511450381499 17
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 11.450381679388926 34
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 12.977099236640782 45
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 12.977099236640782 61
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37fea90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3aa58> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21c50> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 9.541984732824105 28
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 11.83206106870189 35
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 13.358778625953747 46
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 13.358778625953747 62
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29940> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21c50> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 9.923664122137069 29
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 12.213740458014854 36
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 13.74045801526671 47
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 13.74045801526671 63
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37dd828> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29940> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21c50> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 6.106870229007427 20
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 9.923664122137069 30
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 12.213740458014854 37
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 13.74045801526671 48
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 13.74045801526671 64
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 6.488549618320391 21
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 10.305343511450033 31
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 12.595419847327818 38
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 14.122137404579675 49
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 14.122137404579675 65
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5ef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 6.870229007633355 22
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 10.687022900762997 32
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 12.977099236640782 39
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 14.50381679389264 50
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 14.50381679389264 66
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31240> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 7.25190839694632 23
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 13.358778625953747 40
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 14.885496183205603 51
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 14.885496183205603 67
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3aa58> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21c50> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 7.633587786259284 24
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 11.450381679388926 34
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 13.74045801526671 41
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 15.267175572518568 52
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 15.267175572518568 68
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37feb38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a780> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 8.015267175572248 25
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 11.83206106870189 35
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 14.122137404579675 42
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 15.648854961831532 53
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 15.648854961831532 69
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 8.396946564885212 26
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 12.213740458014854 36
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 14.50381679389264 43
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 16.030534351144496 54
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 16.030534351144496 70
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37ddb00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5eb8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5f98> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 8.778625954198176 27
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 12.595419847327818 37
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 14.885496183205603 44
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 16.41221374045746 55
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 16.41221374045746 71
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde378cc18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5f98> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 9.16030534351114 28
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 12.977099236640782 38
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 15.267175572518568 45
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 16.793893129770424 56
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 16.793893129770424 72
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->4->3->3->17->1
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3aef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5f98> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 9.541984732824105 29
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 13.358778625953747 39
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 15.648854961831532 46
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 17.17557251908339 57
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 17.17557251908339 73
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a780> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 9.923664122137069 30
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 13.74045801526671 40
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 16.030534351144496 47
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 17.557251908396353 58
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 17.557251908396353 74
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37e52e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 10.305343511450033 31
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 14.122137404579675 41
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 16.41221374045746 48
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 17.938931297709317 59
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 17.938931297709317 75
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde378cb70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378c0b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe940> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a780> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 10.687022900762997 32
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 14.50381679389264 42
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 16.793893129770424 49
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 18.32061068702228 60
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 18.32061068702228 76
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a780> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 14.885496183205603 43
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 17.17557251908339 50
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 18.702290076335245 61
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 18.702290076335245 77
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6f28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3aef0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5f98> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 11.450381679388926 34
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 15.267175572518568 44
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 17.557251908396353 51
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 19.08396946564821 62
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 19.08396946564821 78
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 8.778625954198176 25
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 11.83206106870189 35
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 15.648854961831532 45
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 17.938931297709317 52
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 19.465648854961174 63
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 19.465648854961174 79
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37fea58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 9.16030534351114 26
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 12.213740458014854 36
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 16.030534351144496 46
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 18.32061068702228 53
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 19.847328244274138 64
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 19.847328244274138 80
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe438> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5eb8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5f98> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 6.488549618320391 18
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 9.541984732824105 27
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 12.595419847327818 37
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 16.41221374045746 47
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 18.702290076335245 54
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 20.229007633587102 65
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 20.229007633587102 81
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6ac8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3aef0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5f98> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 9.541984732824105 28
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 12.595419847327818 38
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 16.41221374045746 48
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 18.702290076335245 55
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 20.229007633587102 66
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 20.229007633587102 82
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->4->3->3->17->1->1
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e52e8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 9.541984732824105 29
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 12.595419847327818 39
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 16.41221374045746 49
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 18.702290076335245 56
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 20.229007633587102 67
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 20.229007633587102 83
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 9.923664122137069 30
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 12.977099236640782 40
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 16.793893129770424 50
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 19.08396946564821 57
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 20.610687022900066 68
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 20.610687022900066 84
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37feeb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 10.305343511450033 31
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 13.358778625953747 41
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 17.17557251908339 51
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 19.465648854961174 58
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 20.99236641221303 69
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 20.99236641221303 85
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31e80> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 10.687022900762997 32
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 13.74045801526671 42
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 17.557251908396353 52
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 19.847328244274138 59
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 21.374045801525995 70
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 21.374045801525995 86
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3e48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3cf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fea58> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 14.122137404579675 43
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 17.938931297709317 53
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 20.229007633587102 60
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 21.75572519083896 71
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 21.75572519083896 87
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde374dd68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 11.450381679388926 34
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 14.50381679389264 44
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 18.32061068702228 54
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 20.610687022900066 61
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 22.137404580151923 72
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 22.137404580151923 88
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde374d320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374dcc0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31e80> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 8.778625954198176 26
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 11.83206106870189 35
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 14.885496183205603 45
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 18.702290076335245 55
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 20.99236641221303 62
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 22.519083969464887 73
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 22.519083969464887 89
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6c18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a9b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374dd68> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 12.213740458014854 36
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 15.267175572518568 46
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 19.08396946564821 56
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 21.374045801525995 63
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 22.90076335877785 74
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 22.90076335877785 90
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde374d668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 9.541984732824105 28
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 12.595419847327818 37
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 15.648854961831532 47
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 19.465648854961174 57
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 21.75572519083896 64
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 23.282442748090816 75
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 23.282442748090816 91
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->4->3->3->17->1->1->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 9.923664122137069 29
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 12.977099236640782 38
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 16.030534351144496 48
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 19.847328244274138 58
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 22.137404580151923 65
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 23.66412213740378 76
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 23.66412213740378 92
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 10.305343511450033 30
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 13.358778625953747 39
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 16.41221374045746 49
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 20.229007633587102 59
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 22.519083969464887 66
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 24.045801526716744 77
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 24.045801526716744 93
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 10.687022900762997 31
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 13.74045801526671 40
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 16.793893129770424 50
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 20.610687022900066 60
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 22.90076335877785 67
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 24.427480916029708 78
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 24.427480916029708 94
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37fee48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d2b0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 11.068702290075962 32
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 14.122137404579675 41
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 17.17557251908339 51
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 20.99236641221303 61
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 23.282442748090816 68
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 24.809160305342672 79
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 24.809160305342672 95
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3757c18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37577b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d2b0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 11.450381679388926 33
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 14.50381679389264 42
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 17.557251908396353 52
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 21.374045801525995 62
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 23.66412213740378 69
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 25.190839694655637 80
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 25.190839694655637 96
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5f28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3cf8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37fea58> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 11.83206106870189 34
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 14.885496183205603 43
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 17.938931297709317 53
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 21.75572519083896 63
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 24.045801526716744 70
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 25.5725190839686 81
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 25.5725190839686 97
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
coverage_call_count 6000
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde597a1198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37feeb8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe400> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 12.213740458014854 35
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 15.267175572518568 44
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 18.32061068702228 54
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 22.137404580151923 64
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 24.427480916029708 71
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 25.954198473281565 82
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 25.954198473281565 98
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3cf8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdde37fea58> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 12.595419847327818 36
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 15.648854961831532 45
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 18.702290076335245 55
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 22.519083969464887 65
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 24.809160305342672 72
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 26.33587786259453 83
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 26.33587786259453 99
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29d68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cac8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d2b0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6048> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fdde37fef98> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9df60> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a668> 12.977099236640782 37
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ac8> 16.030534351144496 46
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59320> 19.08396946564821 56
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25c50> 22.90076335877785 66
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0390> 25.190839694655637 73
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64ba8> 26.717557251907493 84
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25fd0> 26.717557251907493 100
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->4->3->3->17->1->1->0->0
Best Reward: 0.3816793893129642
iteration: 195
found coverage increase 0.3816793893129642
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c317f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c595c0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04fd0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c64208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d252b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9ddd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d535f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c317f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3deda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dedeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c290f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c59898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c290f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424fa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04247e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042471d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0424f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04263f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d14e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde04247780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0420e908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d818d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c3ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d04978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0424f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3c219b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042801d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042cc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042801d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde3d453c8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04247c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c29320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042f7cc0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d25ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d53b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042aa438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ded470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde042cc710> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04263d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cd09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042804a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d37780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042477f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04220f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052bef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052bef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7067ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde294229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906dca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b15c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052bee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05373278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3db7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29422e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05373400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042d7c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0420e048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0429ffd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053b16a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40051278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0530cfd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f9ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0529a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0530cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0530cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05881ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04280e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052be748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0529a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05881b38> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 69.08396946564885
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05881828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29453cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde042c6e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d45a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d41d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d4320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28977ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05866b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2946e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3dc73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde294532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde04280048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3ddd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05894400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d42b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde906a0630> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f9a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0429fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042d7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052f19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 6700
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052aa860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2896afd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28889d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde28889550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde052628d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ce908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05881828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde596fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052ced68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde04220ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05262748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05842240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40046a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05344978> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05373940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05875b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05866a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05850588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05894b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289774e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289774e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3cfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289774e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 18
Completed Iteration #19
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2946e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde05850588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531bcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053fbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053fb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042c6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fc3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde053fbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde289573c8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05850588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28977550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29453f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06fe74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0420e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28957e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042f70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde058759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3d81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05842a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05262eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538ac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0582d198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59728c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde400516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ae9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052e1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0539c630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70775898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5801ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074dba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59746438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29460e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707ee978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7066fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70702eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707dff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5800cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29460e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5800ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70702c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59746438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3c7e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70652a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706aa518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde597b1f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf1562e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707aea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7072f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde18070b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70690cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05344048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0539c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0524fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7074d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde053d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289eee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef98> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde9068f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05344940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7076b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40046c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06f8ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0531b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde058759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707ee278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde042f74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0531be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde5976f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7072feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde707eef60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2943d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec9293eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 7000
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70759c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289d9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde706d05f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70785eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec933e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde707594a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec9293ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde58068128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4003fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec9293ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c21630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06ff5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707025c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0582def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4003fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde70785438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4003fc18> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3c645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052629b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70722048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde580aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2896a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28889ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052629b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde06fe7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289ee748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05866da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0524feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0539c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05875e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde29490c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde597d4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70690a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde289bca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde706b5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28994f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0523b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde5801b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2943dfd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0523b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0523bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0523bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde28923f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0523b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde707ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0583de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0523b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde906f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde706b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec6f8a4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0523b908> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde7079b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde40051710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde70775c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde58068828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59736710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0523bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde1805bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde1805b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0424f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde042ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde289bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7076beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde597f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0429fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0523ba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde18070b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0523b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde28994208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde2948c4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde7079b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2890ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2948c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde40061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde7079b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde29490da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0583d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2943d320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde288e74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3757438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2890e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3757c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0538a518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3757940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3757d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde374df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde374d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde052260b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3757be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde59715cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3757d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05216470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3757d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3757be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3757550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde05216160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde374de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3757d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde378c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde378ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3757be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde37570b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde378cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde374d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37fea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37fee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37b34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde3757eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37b36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37b3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde378c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde374d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde378c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde374d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde05226208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde3757c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde378c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde052265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde37e5780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdde37fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde288e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdde374d978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdde378cf98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 69.08396946564885
initial coverage: 67.1756
time passed (minutes): 60.0515
iterations: 243
number of new inputs: 320
final coverage: 69.084
total coverage increase: 1.9084
